2023-09-05 12:23:30,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:23:30,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:23:30,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:23:30,274:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 12:23:30,880:INFO:PyCaret ClassificationExperiment
2023-09-05 12:23:30,880:INFO:Logging name: clf-default-name
2023-09-05 12:23:30,881:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 12:23:30,881:INFO:version 3.0.4
2023-09-05 12:23:30,881:INFO:Initializing setup()
2023-09-05 12:23:30,881:INFO:self.USI: 0b24
2023-09-05 12:23:30,881:INFO:self._variable_keys: {'_available_plots', 'exp_name_log', 'n_jobs_param', 'gpu_n_jobs_param', 'y_test', 'exp_id', 'X_test', 'target_param', 'log_plots_param', 'fix_imbalance', 'memory', 'idx', 'y', 'fold_groups_param', 'fold_shuffle_param', 'html_param', 'X', 'is_multiclass', '_ml_usecase', 'X_train', 'fold_generator', 'pipeline', 'data', 'seed', 'gpu_param', 'logging_param', 'y_train', 'USI'}
2023-09-05 12:23:30,881:INFO:Checking environment
2023-09-05 12:23:30,881:INFO:python_version: 3.8.8
2023-09-05 12:23:30,881:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 12:23:30,881:INFO:machine: AMD64
2023-09-05 12:23:30,881:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 12:23:30,884:INFO:Memory: svmem(total=16822788096, available=6363508736, percent=62.2, used=10459279360, free=6363508736)
2023-09-05 12:23:30,884:INFO:Physical Core: 8
2023-09-05 12:23:30,884:INFO:Logical Core: 16
2023-09-05 12:23:30,884:INFO:Checking libraries
2023-09-05 12:23:30,884:INFO:System:
2023-09-05 12:23:30,884:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 12:23:30,884:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 12:23:30,884:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 12:23:30,884:INFO:PyCaret required dependencies:
2023-09-05 12:23:30,911:INFO:                 pip: 22.3.1
2023-09-05 12:23:30,911:INFO:          setuptools: 65.5.1
2023-09-05 12:23:30,911:INFO:             pycaret: 3.0.4
2023-09-05 12:23:30,911:INFO:             IPython: 8.12.2
2023-09-05 12:23:30,911:INFO:          ipywidgets: 8.0.7
2023-09-05 12:23:30,911:INFO:                tqdm: 4.66.1
2023-09-05 12:23:30,911:INFO:               numpy: 1.23.5
2023-09-05 12:23:30,911:INFO:              pandas: 1.5.3
2023-09-05 12:23:30,911:INFO:              jinja2: 3.1.2
2023-09-05 12:23:30,911:INFO:               scipy: 1.10.1
2023-09-05 12:23:30,912:INFO:              joblib: 1.3.2
2023-09-05 12:23:30,912:INFO:             sklearn: 1.2.2
2023-09-05 12:23:30,912:INFO:                pyod: 1.1.0
2023-09-05 12:23:30,912:INFO:            imblearn: 0.11.0
2023-09-05 12:23:30,912:INFO:   category_encoders: 2.6.2
2023-09-05 12:23:30,912:INFO:            lightgbm: 4.0.0
2023-09-05 12:23:30,912:INFO:               numba: 0.57.1
2023-09-05 12:23:30,912:INFO:            requests: 2.31.0
2023-09-05 12:23:30,912:INFO:          matplotlib: 3.7.2
2023-09-05 12:23:30,912:INFO:          scikitplot: 0.3.7
2023-09-05 12:23:30,912:INFO:         yellowbrick: 1.5
2023-09-05 12:23:30,912:INFO:              plotly: 5.15.0
2023-09-05 12:23:30,912:INFO:    plotly-resampler: Not installed
2023-09-05 12:23:30,912:INFO:             kaleido: 0.2.1
2023-09-05 12:23:30,912:INFO:           schemdraw: 0.15
2023-09-05 12:23:30,912:INFO:         statsmodels: 0.14.0
2023-09-05 12:23:30,912:INFO:              sktime: 0.22.0
2023-09-05 12:23:30,912:INFO:               tbats: 1.1.3
2023-09-05 12:23:30,912:INFO:            pmdarima: 2.0.3
2023-09-05 12:23:30,912:INFO:              psutil: 5.9.5
2023-09-05 12:23:30,912:INFO:          markupsafe: 2.1.3
2023-09-05 12:23:30,912:INFO:             pickle5: Not installed
2023-09-05 12:23:30,912:INFO:         cloudpickle: 2.2.1
2023-09-05 12:23:30,912:INFO:         deprecation: 2.1.0
2023-09-05 12:23:30,912:INFO:              xxhash: 3.3.0
2023-09-05 12:23:30,912:INFO:           wurlitzer: Not installed
2023-09-05 12:23:30,912:INFO:PyCaret optional dependencies:
2023-09-05 12:23:32,343:INFO:                shap: Not installed
2023-09-05 12:23:32,343:INFO:           interpret: Not installed
2023-09-05 12:23:32,343:INFO:                umap: Not installed
2023-09-05 12:23:32,343:INFO:    pandas_profiling: Not installed
2023-09-05 12:23:32,343:INFO:  explainerdashboard: Not installed
2023-09-05 12:23:32,343:INFO:             autoviz: Not installed
2023-09-05 12:23:32,343:INFO:           fairlearn: Not installed
2023-09-05 12:23:32,343:INFO:          deepchecks: Not installed
2023-09-05 12:23:32,343:INFO:             xgboost: 1.7.6
2023-09-05 12:23:32,343:INFO:            catboost: 1.2.1
2023-09-05 12:23:32,343:INFO:              kmodes: Not installed
2023-09-05 12:23:32,343:INFO:             mlxtend: Not installed
2023-09-05 12:23:32,343:INFO:       statsforecast: Not installed
2023-09-05 12:23:32,343:INFO:        tune_sklearn: 0.4.6
2023-09-05 12:23:32,343:INFO:                 ray: 2.6.3
2023-09-05 12:23:32,343:INFO:            hyperopt: Not installed
2023-09-05 12:23:32,343:INFO:              optuna: 3.3.0
2023-09-05 12:23:32,343:INFO:               skopt: 0.9.0
2023-09-05 12:23:32,343:INFO:              mlflow: Not installed
2023-09-05 12:23:32,343:INFO:              gradio: 3.42.0
2023-09-05 12:23:32,343:INFO:             fastapi: 0.103.1
2023-09-05 12:23:32,343:INFO:             uvicorn: 0.23.2
2023-09-05 12:23:32,343:INFO:              m2cgen: Not installed
2023-09-05 12:23:32,343:INFO:           evidently: Not installed
2023-09-05 12:23:32,343:INFO:               fugue: Not installed
2023-09-05 12:23:32,343:INFO:           streamlit: Not installed
2023-09-05 12:23:32,343:INFO:             prophet: Not installed
2023-09-05 12:23:32,343:INFO:None
2023-09-05 12:23:32,343:INFO:Set up data.
2023-09-05 12:23:32,348:INFO:Set up train/test split.
2023-09-05 12:23:32,351:INFO:Set up index.
2023-09-05 12:23:32,351:INFO:Set up folding strategy.
2023-09-05 12:23:32,351:INFO:Assigning column types.
2023-09-05 12:23:32,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 12:23:32,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,386:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,412:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,447:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,516:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,518:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,519:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 12:23:32,548:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,566:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,568:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 12:23:32,618:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,620:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,620:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 12:23:32,673:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,675:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,729:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,732:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,735:INFO:Preparing preprocessing pipeline...
2023-09-05 12:23:32,736:INFO:Set up simple imputation.
2023-09-05 12:23:32,749:INFO:Finished creating preprocessing pipeline.
2023-09-05 12:23:32,753:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 12:23:32,754:INFO:Creating final display dataframe.
2023-09-05 12:23:32,787:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0b24
2023-09-05 12:23:32,847:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,849:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,898:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,900:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:32,900:INFO:setup() successfully completed in 2.02s...............
2023-09-05 12:23:32,911:INFO:gpu_param set to False
2023-09-05 12:23:32,966:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:32,968:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:33,020:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:33,022:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:33,034:INFO:gpu_param set to False
2023-09-05 12:23:33,093:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:33,095:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:33,150:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 12:23:33,152:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 12:23:33,203:INFO:Initializing compare_models()
2023-09-05 12:23:33,203:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 12:23:33,204:INFO:Checking exceptions
2023-09-05 12:23:33,207:INFO:Preparing display monitor
2023-09-05 12:23:33,224:INFO:Initializing Logistic Regression
2023-09-05 12:23:33,224:INFO:Total runtime is 0.0 minutes
2023-09-05 12:23:33,228:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:33,228:INFO:Initializing create_model()
2023-09-05 12:23:33,228:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:33,228:INFO:Checking exceptions
2023-09-05 12:23:33,228:INFO:Importing libraries
2023-09-05 12:23:33,229:INFO:Copying training dataset
2023-09-05 12:23:33,233:INFO:Defining folds
2023-09-05 12:23:33,233:INFO:Declaring metric variables
2023-09-05 12:23:33,237:INFO:Importing untrained model
2023-09-05 12:23:33,240:INFO:Logistic Regression Imported successfully
2023-09-05 12:23:33,244:INFO:Starting cross validation
2023-09-05 12:23:33,245:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:35,549:INFO:Calculating mean and std
2023-09-05 12:23:35,550:INFO:Creating metrics dataframe
2023-09-05 12:23:35,554:INFO:Uploading results into container
2023-09-05 12:23:35,555:INFO:Uploading model into container now
2023-09-05 12:23:35,555:INFO:_master_model_container: 1
2023-09-05 12:23:35,555:INFO:_display_container: 2
2023-09-05 12:23:35,555:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 12:23:35,555:INFO:create_model() successfully completed......................................
2023-09-05 12:23:35,638:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:35,638:INFO:Creating metrics dataframe
2023-09-05 12:23:35,644:INFO:Initializing K Neighbors Classifier
2023-09-05 12:23:35,644:INFO:Total runtime is 0.04032909472783407 minutes
2023-09-05 12:23:35,646:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:35,646:INFO:Initializing create_model()
2023-09-05 12:23:35,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:35,646:INFO:Checking exceptions
2023-09-05 12:23:35,646:INFO:Importing libraries
2023-09-05 12:23:35,646:INFO:Copying training dataset
2023-09-05 12:23:35,649:INFO:Defining folds
2023-09-05 12:23:35,649:INFO:Declaring metric variables
2023-09-05 12:23:35,652:INFO:Importing untrained model
2023-09-05 12:23:35,654:INFO:K Neighbors Classifier Imported successfully
2023-09-05 12:23:35,658:INFO:Starting cross validation
2023-09-05 12:23:35,658:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:37,454:INFO:Calculating mean and std
2023-09-05 12:23:37,455:INFO:Creating metrics dataframe
2023-09-05 12:23:37,459:INFO:Uploading results into container
2023-09-05 12:23:37,460:INFO:Uploading model into container now
2023-09-05 12:23:37,460:INFO:_master_model_container: 2
2023-09-05 12:23:37,460:INFO:_display_container: 2
2023-09-05 12:23:37,460:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 12:23:37,460:INFO:create_model() successfully completed......................................
2023-09-05 12:23:37,542:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:37,542:INFO:Creating metrics dataframe
2023-09-05 12:23:37,549:INFO:Initializing Naive Bayes
2023-09-05 12:23:37,549:INFO:Total runtime is 0.07207882404327393 minutes
2023-09-05 12:23:37,552:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:37,552:INFO:Initializing create_model()
2023-09-05 12:23:37,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:37,552:INFO:Checking exceptions
2023-09-05 12:23:37,552:INFO:Importing libraries
2023-09-05 12:23:37,552:INFO:Copying training dataset
2023-09-05 12:23:37,557:INFO:Defining folds
2023-09-05 12:23:37,557:INFO:Declaring metric variables
2023-09-05 12:23:37,559:INFO:Importing untrained model
2023-09-05 12:23:37,562:INFO:Naive Bayes Imported successfully
2023-09-05 12:23:37,566:INFO:Starting cross validation
2023-09-05 12:23:37,567:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:39,309:INFO:Calculating mean and std
2023-09-05 12:23:39,311:INFO:Creating metrics dataframe
2023-09-05 12:23:39,319:INFO:Uploading results into container
2023-09-05 12:23:39,320:INFO:Uploading model into container now
2023-09-05 12:23:39,320:INFO:_master_model_container: 3
2023-09-05 12:23:39,320:INFO:_display_container: 2
2023-09-05 12:23:39,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 12:23:39,321:INFO:create_model() successfully completed......................................
2023-09-05 12:23:39,416:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:39,416:INFO:Creating metrics dataframe
2023-09-05 12:23:39,422:INFO:Initializing Decision Tree Classifier
2023-09-05 12:23:39,422:INFO:Total runtime is 0.1033010999361674 minutes
2023-09-05 12:23:39,425:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:39,425:INFO:Initializing create_model()
2023-09-05 12:23:39,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:39,425:INFO:Checking exceptions
2023-09-05 12:23:39,425:INFO:Importing libraries
2023-09-05 12:23:39,425:INFO:Copying training dataset
2023-09-05 12:23:39,428:INFO:Defining folds
2023-09-05 12:23:39,428:INFO:Declaring metric variables
2023-09-05 12:23:39,431:INFO:Importing untrained model
2023-09-05 12:23:39,433:INFO:Decision Tree Classifier Imported successfully
2023-09-05 12:23:39,438:INFO:Starting cross validation
2023-09-05 12:23:39,439:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:41,119:INFO:Calculating mean and std
2023-09-05 12:23:41,121:INFO:Creating metrics dataframe
2023-09-05 12:23:41,125:INFO:Uploading results into container
2023-09-05 12:23:41,126:INFO:Uploading model into container now
2023-09-05 12:23:41,127:INFO:_master_model_container: 4
2023-09-05 12:23:41,127:INFO:_display_container: 2
2023-09-05 12:23:41,127:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 12:23:41,127:INFO:create_model() successfully completed......................................
2023-09-05 12:23:41,225:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:41,226:INFO:Creating metrics dataframe
2023-09-05 12:23:41,233:INFO:Initializing SVM - Linear Kernel
2023-09-05 12:23:41,233:INFO:Total runtime is 0.13348169326782228 minutes
2023-09-05 12:23:41,235:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:41,235:INFO:Initializing create_model()
2023-09-05 12:23:41,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:41,235:INFO:Checking exceptions
2023-09-05 12:23:41,235:INFO:Importing libraries
2023-09-05 12:23:41,235:INFO:Copying training dataset
2023-09-05 12:23:41,238:INFO:Defining folds
2023-09-05 12:23:41,238:INFO:Declaring metric variables
2023-09-05 12:23:41,241:INFO:Importing untrained model
2023-09-05 12:23:41,243:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 12:23:41,249:INFO:Starting cross validation
2023-09-05 12:23:41,250:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:42,924:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:23:42,929:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:23:42,929:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 12:23:42,937:INFO:Calculating mean and std
2023-09-05 12:23:42,939:INFO:Creating metrics dataframe
2023-09-05 12:23:42,943:INFO:Uploading results into container
2023-09-05 12:23:42,944:INFO:Uploading model into container now
2023-09-05 12:23:42,944:INFO:_master_model_container: 5
2023-09-05 12:23:42,944:INFO:_display_container: 2
2023-09-05 12:23:42,945:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 12:23:42,945:INFO:create_model() successfully completed......................................
2023-09-05 12:23:43,024:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:43,024:INFO:Creating metrics dataframe
2023-09-05 12:23:43,033:INFO:Initializing Ridge Classifier
2023-09-05 12:23:43,033:INFO:Total runtime is 0.16348358790079753 minutes
2023-09-05 12:23:43,036:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:43,036:INFO:Initializing create_model()
2023-09-05 12:23:43,036:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:43,036:INFO:Checking exceptions
2023-09-05 12:23:43,036:INFO:Importing libraries
2023-09-05 12:23:43,036:INFO:Copying training dataset
2023-09-05 12:23:43,039:INFO:Defining folds
2023-09-05 12:23:43,039:INFO:Declaring metric variables
2023-09-05 12:23:43,042:INFO:Importing untrained model
2023-09-05 12:23:43,044:INFO:Ridge Classifier Imported successfully
2023-09-05 12:23:43,049:INFO:Starting cross validation
2023-09-05 12:23:43,049:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:43,102:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:23:44,544:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 12:23:44,553:INFO:Calculating mean and std
2023-09-05 12:23:44,554:INFO:Creating metrics dataframe
2023-09-05 12:23:44,557:INFO:Uploading results into container
2023-09-05 12:23:44,558:INFO:Uploading model into container now
2023-09-05 12:23:44,558:INFO:_master_model_container: 6
2023-09-05 12:23:44,558:INFO:_display_container: 2
2023-09-05 12:23:44,558:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 12:23:44,558:INFO:create_model() successfully completed......................................
2023-09-05 12:23:44,626:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:44,627:INFO:Creating metrics dataframe
2023-09-05 12:23:44,635:INFO:Initializing Random Forest Classifier
2023-09-05 12:23:44,635:INFO:Total runtime is 0.19018697341283164 minutes
2023-09-05 12:23:44,638:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:44,639:INFO:Initializing create_model()
2023-09-05 12:23:44,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:44,639:INFO:Checking exceptions
2023-09-05 12:23:44,639:INFO:Importing libraries
2023-09-05 12:23:44,639:INFO:Copying training dataset
2023-09-05 12:23:44,641:INFO:Defining folds
2023-09-05 12:23:44,641:INFO:Declaring metric variables
2023-09-05 12:23:44,644:INFO:Importing untrained model
2023-09-05 12:23:44,646:INFO:Random Forest Classifier Imported successfully
2023-09-05 12:23:44,651:INFO:Starting cross validation
2023-09-05 12:23:44,652:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:45,038:INFO:Calculating mean and std
2023-09-05 12:23:45,039:INFO:Creating metrics dataframe
2023-09-05 12:23:45,045:INFO:Uploading results into container
2023-09-05 12:23:45,045:INFO:Uploading model into container now
2023-09-05 12:23:45,046:INFO:_master_model_container: 7
2023-09-05 12:23:45,046:INFO:_display_container: 2
2023-09-05 12:23:45,046:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:23:45,046:INFO:create_model() successfully completed......................................
2023-09-05 12:23:45,123:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:45,124:INFO:Creating metrics dataframe
2023-09-05 12:23:45,130:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 12:23:45,131:INFO:Total runtime is 0.19844797849655152 minutes
2023-09-05 12:23:45,134:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:45,134:INFO:Initializing create_model()
2023-09-05 12:23:45,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:45,134:INFO:Checking exceptions
2023-09-05 12:23:45,134:INFO:Importing libraries
2023-09-05 12:23:45,134:INFO:Copying training dataset
2023-09-05 12:23:45,137:INFO:Defining folds
2023-09-05 12:23:45,137:INFO:Declaring metric variables
2023-09-05 12:23:45,140:INFO:Importing untrained model
2023-09-05 12:23:45,143:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 12:23:45,150:INFO:Starting cross validation
2023-09-05 12:23:45,150:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:45,242:INFO:Calculating mean and std
2023-09-05 12:23:45,242:INFO:Creating metrics dataframe
2023-09-05 12:23:45,247:INFO:Uploading results into container
2023-09-05 12:23:45,248:INFO:Uploading model into container now
2023-09-05 12:23:45,248:INFO:_master_model_container: 8
2023-09-05 12:23:45,248:INFO:_display_container: 2
2023-09-05 12:23:45,249:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 12:23:45,249:INFO:create_model() successfully completed......................................
2023-09-05 12:23:45,326:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:45,326:INFO:Creating metrics dataframe
2023-09-05 12:23:45,333:INFO:Initializing Ada Boost Classifier
2023-09-05 12:23:45,333:INFO:Total runtime is 0.20180843273798627 minutes
2023-09-05 12:23:45,335:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:45,336:INFO:Initializing create_model()
2023-09-05 12:23:45,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:45,336:INFO:Checking exceptions
2023-09-05 12:23:45,336:INFO:Importing libraries
2023-09-05 12:23:45,336:INFO:Copying training dataset
2023-09-05 12:23:45,339:INFO:Defining folds
2023-09-05 12:23:45,339:INFO:Declaring metric variables
2023-09-05 12:23:45,341:INFO:Importing untrained model
2023-09-05 12:23:45,343:INFO:Ada Boost Classifier Imported successfully
2023-09-05 12:23:45,347:INFO:Starting cross validation
2023-09-05 12:23:45,348:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:45,495:INFO:Calculating mean and std
2023-09-05 12:23:45,496:INFO:Creating metrics dataframe
2023-09-05 12:23:45,501:INFO:Uploading results into container
2023-09-05 12:23:45,501:INFO:Uploading model into container now
2023-09-05 12:23:45,502:INFO:_master_model_container: 9
2023-09-05 12:23:45,502:INFO:_display_container: 2
2023-09-05 12:23:45,502:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 12:23:45,502:INFO:create_model() successfully completed......................................
2023-09-05 12:23:45,572:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:45,572:INFO:Creating metrics dataframe
2023-09-05 12:23:45,580:INFO:Initializing Gradient Boosting Classifier
2023-09-05 12:23:45,580:INFO:Total runtime is 0.2059290925661723 minutes
2023-09-05 12:23:45,582:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:45,582:INFO:Initializing create_model()
2023-09-05 12:23:45,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:45,582:INFO:Checking exceptions
2023-09-05 12:23:45,582:INFO:Importing libraries
2023-09-05 12:23:45,582:INFO:Copying training dataset
2023-09-05 12:23:45,584:INFO:Defining folds
2023-09-05 12:23:45,584:INFO:Declaring metric variables
2023-09-05 12:23:45,587:INFO:Importing untrained model
2023-09-05 12:23:45,589:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 12:23:45,596:INFO:Starting cross validation
2023-09-05 12:23:45,597:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:45,766:INFO:Calculating mean and std
2023-09-05 12:23:45,767:INFO:Creating metrics dataframe
2023-09-05 12:23:45,770:INFO:Uploading results into container
2023-09-05 12:23:45,771:INFO:Uploading model into container now
2023-09-05 12:23:45,771:INFO:_master_model_container: 10
2023-09-05 12:23:45,771:INFO:_display_container: 2
2023-09-05 12:23:45,771:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 12:23:45,771:INFO:create_model() successfully completed......................................
2023-09-05 12:23:45,838:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:45,838:INFO:Creating metrics dataframe
2023-09-05 12:23:45,845:INFO:Initializing Linear Discriminant Analysis
2023-09-05 12:23:45,846:INFO:Total runtime is 0.21035657723744713 minutes
2023-09-05 12:23:45,848:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:45,848:INFO:Initializing create_model()
2023-09-05 12:23:45,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:45,848:INFO:Checking exceptions
2023-09-05 12:23:45,848:INFO:Importing libraries
2023-09-05 12:23:45,850:INFO:Copying training dataset
2023-09-05 12:23:45,852:INFO:Defining folds
2023-09-05 12:23:45,852:INFO:Declaring metric variables
2023-09-05 12:23:45,854:INFO:Importing untrained model
2023-09-05 12:23:45,856:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 12:23:45,863:INFO:Starting cross validation
2023-09-05 12:23:45,863:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:45,936:INFO:Calculating mean and std
2023-09-05 12:23:45,937:INFO:Creating metrics dataframe
2023-09-05 12:23:45,942:INFO:Uploading results into container
2023-09-05 12:23:45,943:INFO:Uploading model into container now
2023-09-05 12:23:45,944:INFO:_master_model_container: 11
2023-09-05 12:23:45,944:INFO:_display_container: 2
2023-09-05 12:23:45,944:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 12:23:45,944:INFO:create_model() successfully completed......................................
2023-09-05 12:23:46,011:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:46,011:INFO:Creating metrics dataframe
2023-09-05 12:23:46,018:INFO:Initializing Extra Trees Classifier
2023-09-05 12:23:46,018:INFO:Total runtime is 0.21322962840398155 minutes
2023-09-05 12:23:46,020:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:46,020:INFO:Initializing create_model()
2023-09-05 12:23:46,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:46,020:INFO:Checking exceptions
2023-09-05 12:23:46,021:INFO:Importing libraries
2023-09-05 12:23:46,021:INFO:Copying training dataset
2023-09-05 12:23:46,023:INFO:Defining folds
2023-09-05 12:23:46,023:INFO:Declaring metric variables
2023-09-05 12:23:46,025:INFO:Importing untrained model
2023-09-05 12:23:46,027:INFO:Extra Trees Classifier Imported successfully
2023-09-05 12:23:46,032:INFO:Starting cross validation
2023-09-05 12:23:46,033:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:46,372:INFO:Calculating mean and std
2023-09-05 12:23:46,373:INFO:Creating metrics dataframe
2023-09-05 12:23:46,377:INFO:Uploading results into container
2023-09-05 12:23:46,378:INFO:Uploading model into container now
2023-09-05 12:23:46,378:INFO:_master_model_container: 12
2023-09-05 12:23:46,378:INFO:_display_container: 2
2023-09-05 12:23:46,378:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 12:23:46,378:INFO:create_model() successfully completed......................................
2023-09-05 12:23:46,447:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:46,448:INFO:Creating metrics dataframe
2023-09-05 12:23:46,455:INFO:Initializing Extreme Gradient Boosting
2023-09-05 12:23:46,455:INFO:Total runtime is 0.22051614125569663 minutes
2023-09-05 12:23:46,457:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:46,457:INFO:Initializing create_model()
2023-09-05 12:23:46,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:46,457:INFO:Checking exceptions
2023-09-05 12:23:46,457:INFO:Importing libraries
2023-09-05 12:23:46,457:INFO:Copying training dataset
2023-09-05 12:23:46,459:INFO:Defining folds
2023-09-05 12:23:46,459:INFO:Declaring metric variables
2023-09-05 12:23:46,461:INFO:Importing untrained model
2023-09-05 12:23:46,464:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 12:23:46,468:INFO:Starting cross validation
2023-09-05 12:23:46,469:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:46,590:INFO:Calculating mean and std
2023-09-05 12:23:46,591:INFO:Creating metrics dataframe
2023-09-05 12:23:46,595:INFO:Uploading results into container
2023-09-05 12:23:46,595:INFO:Uploading model into container now
2023-09-05 12:23:46,595:INFO:_master_model_container: 13
2023-09-05 12:23:46,596:INFO:_display_container: 2
2023-09-05 12:23:46,596:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 12:23:46,596:INFO:create_model() successfully completed......................................
2023-09-05 12:23:46,666:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:46,666:INFO:Creating metrics dataframe
2023-09-05 12:23:46,675:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 12:23:46,675:INFO:Total runtime is 0.22417376438776654 minutes
2023-09-05 12:23:46,676:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:46,676:INFO:Initializing create_model()
2023-09-05 12:23:46,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:46,676:INFO:Checking exceptions
2023-09-05 12:23:46,677:INFO:Importing libraries
2023-09-05 12:23:46,677:INFO:Copying training dataset
2023-09-05 12:23:46,679:INFO:Defining folds
2023-09-05 12:23:46,679:INFO:Declaring metric variables
2023-09-05 12:23:46,681:INFO:Importing untrained model
2023-09-05 12:23:46,683:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 12:23:46,688:INFO:Starting cross validation
2023-09-05 12:23:46,689:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:46,932:INFO:Calculating mean and std
2023-09-05 12:23:46,933:INFO:Creating metrics dataframe
2023-09-05 12:23:46,940:INFO:Uploading results into container
2023-09-05 12:23:46,941:INFO:Uploading model into container now
2023-09-05 12:23:46,941:INFO:_master_model_container: 14
2023-09-05 12:23:46,941:INFO:_display_container: 2
2023-09-05 12:23:46,942:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:23:46,942:INFO:create_model() successfully completed......................................
2023-09-05 12:23:47,029:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:47,029:INFO:Creating metrics dataframe
2023-09-05 12:23:47,037:INFO:Initializing Dummy Classifier
2023-09-05 12:23:47,037:INFO:Total runtime is 0.23021329243977867 minutes
2023-09-05 12:23:47,039:INFO:SubProcess create_model() called ==================================
2023-09-05 12:23:47,039:INFO:Initializing create_model()
2023-09-05 12:23:47,039:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EDF69D4F70>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:47,039:INFO:Checking exceptions
2023-09-05 12:23:47,039:INFO:Importing libraries
2023-09-05 12:23:47,039:INFO:Copying training dataset
2023-09-05 12:23:47,042:INFO:Defining folds
2023-09-05 12:23:47,042:INFO:Declaring metric variables
2023-09-05 12:23:47,045:INFO:Importing untrained model
2023-09-05 12:23:47,048:INFO:Dummy Classifier Imported successfully
2023-09-05 12:23:47,054:INFO:Starting cross validation
2023-09-05 12:23:47,055:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 12:23:47,106:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:23:47,117:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:23:47,122:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 12:23:47,136:INFO:Calculating mean and std
2023-09-05 12:23:47,136:INFO:Creating metrics dataframe
2023-09-05 12:23:47,142:INFO:Uploading results into container
2023-09-05 12:23:47,143:INFO:Uploading model into container now
2023-09-05 12:23:47,143:INFO:_master_model_container: 15
2023-09-05 12:23:47,143:INFO:_display_container: 2
2023-09-05 12:23:47,143:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 12:23:47,143:INFO:create_model() successfully completed......................................
2023-09-05 12:23:47,209:INFO:SubProcess create_model() end ==================================
2023-09-05 12:23:47,209:INFO:Creating metrics dataframe
2023-09-05 12:23:47,226:INFO:Initializing create_model()
2023-09-05 12:23:47,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EDD2642130>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 12:23:47,226:INFO:Checking exceptions
2023-09-05 12:23:47,227:INFO:Importing libraries
2023-09-05 12:23:47,227:INFO:Copying training dataset
2023-09-05 12:23:47,229:INFO:Defining folds
2023-09-05 12:23:47,229:INFO:Declaring metric variables
2023-09-05 12:23:47,229:INFO:Importing untrained model
2023-09-05 12:23:47,229:INFO:Declaring custom model
2023-09-05 12:23:47,229:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 12:23:47,230:INFO:Cross validation set to False
2023-09-05 12:23:47,230:INFO:Fitting Model
2023-09-05 12:23:47,255:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-05 12:23:47,255:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.
2023-09-05 12:23:47,255:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-05 12:23:47,255:INFO:[LightGBM] [Info] Total Bins 274
2023-09-05 12:23:47,256:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-05 12:23:47,256:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-05 12:23:47,256:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-05 12:23:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,268:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 12:23:47,294:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:23:47,294:INFO:create_model() successfully completed......................................
2023-09-05 12:23:47,405:INFO:_master_model_container: 15
2023-09-05 12:23:47,405:INFO:_display_container: 2
2023-09-05 12:23:47,406:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 12:23:47,406:INFO:compare_models() successfully completed......................................
2023-09-05 16:10:55,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 16:10:55,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 16:10:55,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 16:10:55,185:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 16:15:02,068:INFO:PyCaret RegressionExperiment
2023-09-05 16:15:02,068:INFO:Logging name: reg-default-name
2023-09-05 16:15:02,068:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-05 16:15:02,068:INFO:version 3.0.4
2023-09-05 16:15:02,068:INFO:Initializing setup()
2023-09-05 16:15:02,068:INFO:self.USI: 5771
2023-09-05 16:15:02,068:INFO:self._variable_keys: {'exp_name_log', 'transform_target_param', 'logging_param', 'n_jobs_param', 'X_train', '_available_plots', 'data', 'y', 'idx', 'seed', 'memory', 'X_test', 'fold_shuffle_param', 'X', 'gpu_param', 'pipeline', 'y_test', 'log_plots_param', 'gpu_n_jobs_param', 'target_param', 'exp_id', 'fold_groups_param', '_ml_usecase', 'y_train', 'html_param', 'fold_generator', 'USI'}
2023-09-05 16:15:02,068:INFO:Checking environment
2023-09-05 16:15:02,068:INFO:python_version: 3.8.8
2023-09-05 16:15:02,068:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 16:15:02,068:INFO:machine: AMD64
2023-09-05 16:15:02,068:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 16:15:02,071:INFO:Memory: svmem(total=16822788096, available=6651637760, percent=60.5, used=10171150336, free=6651637760)
2023-09-05 16:15:02,071:INFO:Physical Core: 8
2023-09-05 16:15:02,071:INFO:Logical Core: 16
2023-09-05 16:15:02,071:INFO:Checking libraries
2023-09-05 16:15:02,071:INFO:System:
2023-09-05 16:15:02,071:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 16:15:02,071:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 16:15:02,071:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 16:15:02,071:INFO:PyCaret required dependencies:
2023-09-05 16:15:02,105:INFO:                 pip: 22.3.1
2023-09-05 16:15:02,105:INFO:          setuptools: 65.5.1
2023-09-05 16:15:02,105:INFO:             pycaret: 3.0.4
2023-09-05 16:15:02,105:INFO:             IPython: 8.12.2
2023-09-05 16:15:02,105:INFO:          ipywidgets: 8.0.7
2023-09-05 16:15:02,105:INFO:                tqdm: 4.66.1
2023-09-05 16:15:02,105:INFO:               numpy: 1.23.5
2023-09-05 16:15:02,105:INFO:              pandas: 1.5.3
2023-09-05 16:15:02,105:INFO:              jinja2: 3.1.2
2023-09-05 16:15:02,105:INFO:               scipy: 1.10.1
2023-09-05 16:15:02,105:INFO:              joblib: 1.3.2
2023-09-05 16:15:02,105:INFO:             sklearn: 1.2.2
2023-09-05 16:15:02,105:INFO:                pyod: 1.1.0
2023-09-05 16:15:02,105:INFO:            imblearn: 0.11.0
2023-09-05 16:15:02,105:INFO:   category_encoders: 2.6.2
2023-09-05 16:15:02,105:INFO:            lightgbm: 4.0.0
2023-09-05 16:15:02,105:INFO:               numba: 0.57.1
2023-09-05 16:15:02,105:INFO:            requests: 2.31.0
2023-09-05 16:15:02,105:INFO:          matplotlib: 3.7.2
2023-09-05 16:15:02,105:INFO:          scikitplot: 0.3.7
2023-09-05 16:15:02,105:INFO:         yellowbrick: 1.5
2023-09-05 16:15:02,105:INFO:              plotly: 5.15.0
2023-09-05 16:15:02,105:INFO:    plotly-resampler: Not installed
2023-09-05 16:15:02,105:INFO:             kaleido: 0.2.1
2023-09-05 16:15:02,105:INFO:           schemdraw: 0.15
2023-09-05 16:15:02,105:INFO:         statsmodels: 0.14.0
2023-09-05 16:15:02,105:INFO:              sktime: 0.22.0
2023-09-05 16:15:02,105:INFO:               tbats: 1.1.3
2023-09-05 16:15:02,105:INFO:            pmdarima: 2.0.3
2023-09-05 16:15:02,105:INFO:              psutil: 5.9.5
2023-09-05 16:15:02,105:INFO:          markupsafe: 2.1.3
2023-09-05 16:15:02,105:INFO:             pickle5: Not installed
2023-09-05 16:15:02,105:INFO:         cloudpickle: 2.2.1
2023-09-05 16:15:02,105:INFO:         deprecation: 2.1.0
2023-09-05 16:15:02,105:INFO:              xxhash: 3.3.0
2023-09-05 16:15:02,105:INFO:           wurlitzer: Not installed
2023-09-05 16:15:02,106:INFO:PyCaret optional dependencies:
2023-09-05 16:15:03,259:INFO:                shap: Not installed
2023-09-05 16:15:03,259:INFO:           interpret: Not installed
2023-09-05 16:15:03,259:INFO:                umap: Not installed
2023-09-05 16:15:03,259:INFO:    pandas_profiling: Not installed
2023-09-05 16:15:03,259:INFO:  explainerdashboard: Not installed
2023-09-05 16:15:03,259:INFO:             autoviz: Not installed
2023-09-05 16:15:03,259:INFO:           fairlearn: Not installed
2023-09-05 16:15:03,259:INFO:          deepchecks: Not installed
2023-09-05 16:15:03,259:INFO:             xgboost: 1.7.6
2023-09-05 16:15:03,259:INFO:            catboost: 1.2.1
2023-09-05 16:15:03,259:INFO:              kmodes: Not installed
2023-09-05 16:15:03,259:INFO:             mlxtend: Not installed
2023-09-05 16:15:03,259:INFO:       statsforecast: Not installed
2023-09-05 16:15:03,259:INFO:        tune_sklearn: 0.4.6
2023-09-05 16:15:03,259:INFO:                 ray: 2.6.3
2023-09-05 16:15:03,259:INFO:            hyperopt: Not installed
2023-09-05 16:15:03,259:INFO:              optuna: 3.3.0
2023-09-05 16:15:03,259:INFO:               skopt: 0.9.0
2023-09-05 16:15:03,259:INFO:              mlflow: Not installed
2023-09-05 16:15:03,259:INFO:              gradio: 3.42.0
2023-09-05 16:15:03,259:INFO:             fastapi: 0.103.1
2023-09-05 16:15:03,259:INFO:             uvicorn: 0.23.2
2023-09-05 16:15:03,259:INFO:              m2cgen: Not installed
2023-09-05 16:15:03,259:INFO:           evidently: Not installed
2023-09-05 16:15:03,259:INFO:               fugue: Not installed
2023-09-05 16:15:03,259:INFO:           streamlit: Not installed
2023-09-05 16:15:03,259:INFO:             prophet: Not installed
2023-09-05 16:15:03,259:INFO:None
2023-09-05 16:15:03,259:INFO:Set up data.
2023-09-05 16:15:03,263:INFO:Set up train/test split.
2023-09-05 16:15:03,266:INFO:Set up index.
2023-09-05 16:15:03,266:INFO:Set up folding strategy.
2023-09-05 16:15:03,266:INFO:Assigning column types.
2023-09-05 16:15:03,267:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 16:15:03,268:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,271:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,314:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,345:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,345:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,448:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,487:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,490:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,493:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,533:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,562:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,565:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,565:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-05 16:15:03,568:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,638:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,639:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,641:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,644:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,647:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,684:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,714:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,715:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,716:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,717:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-05 16:15:03,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,760:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,789:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,791:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,797:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,835:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,864:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,865:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,866:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-05 16:15:03,912:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:03,942:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:03,943:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:03,988:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:04,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 16:15:04,017:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,018:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,019:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 16:15:04,064:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:04,094:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,095:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,139:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 16:15:04,170:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,172:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,172:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-05 16:15:04,245:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,247:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,321:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,322:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,324:INFO:Preparing preprocessing pipeline...
2023-09-05 16:15:04,324:INFO:Set up simple imputation.
2023-09-05 16:15:04,326:INFO:Set up encoding of ordinal features.
2023-09-05 16:15:04,328:INFO:Set up encoding of categorical features.
2023-09-05 16:15:04,377:INFO:Finished creating preprocessing pipeline.
2023-09-05 16:15:04,405:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-09-05 16:15:04,405:INFO:Creating final display dataframe.
2023-09-05 16:15:04,532:INFO:Setup _display_container:                     Description             Value
0                    Session id              8397
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              5771
2023-09-05 16:15:04,537:ERROR:Data Failed with exception:
 No module named 'pandas_profiling'
No output to show, continue with modeling.
2023-09-05 16:15:04,613:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,614:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,687:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 16:15:04,689:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 16:15:04,690:INFO:setup() successfully completed in 2.63s...............
2023-09-05 16:15:24,937:INFO:Initializing compare_models()
2023-09-05 16:15:24,938:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, include=['lr', 'rf'], fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, 'include': ['lr', 'rf'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 16:15:24,938:INFO:Checking exceptions
2023-09-05 16:15:24,940:INFO:Preparing display monitor
2023-09-05 16:15:24,959:INFO:Initializing Linear Regression
2023-09-05 16:15:24,960:INFO:Total runtime is 1.659393310546875e-05 minutes
2023-09-05 16:15:24,963:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:24,963:INFO:Initializing create_model()
2023-09-05 16:15:24,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F8C4820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:24,963:INFO:Checking exceptions
2023-09-05 16:15:24,963:INFO:Importing libraries
2023-09-05 16:15:24,963:INFO:Copying training dataset
2023-09-05 16:15:24,966:INFO:Defining folds
2023-09-05 16:15:24,966:INFO:Declaring metric variables
2023-09-05 16:15:24,968:INFO:Importing untrained model
2023-09-05 16:15:24,970:INFO:Linear Regression Imported successfully
2023-09-05 16:15:24,976:INFO:Starting cross validation
2023-09-05 16:15:24,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:28,250:INFO:Calculating mean and std
2023-09-05 16:15:28,252:INFO:Creating metrics dataframe
2023-09-05 16:15:28,263:INFO:Uploading results into container
2023-09-05 16:15:28,264:INFO:Uploading model into container now
2023-09-05 16:15:28,264:INFO:_master_model_container: 1
2023-09-05 16:15:28,264:INFO:_display_container: 2
2023-09-05 16:15:28,265:INFO:LinearRegression(n_jobs=-1)
2023-09-05 16:15:28,265:INFO:create_model() successfully completed......................................
2023-09-05 16:15:28,370:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:28,371:INFO:Creating metrics dataframe
2023-09-05 16:15:28,376:INFO:Initializing Random Forest Regressor
2023-09-05 16:15:28,376:INFO:Total runtime is 0.0569546898206075 minutes
2023-09-05 16:15:28,378:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:28,378:INFO:Initializing create_model()
2023-09-05 16:15:28,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F8C4820>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:28,378:INFO:Checking exceptions
2023-09-05 16:15:28,378:INFO:Importing libraries
2023-09-05 16:15:28,378:INFO:Copying training dataset
2023-09-05 16:15:28,381:INFO:Defining folds
2023-09-05 16:15:28,382:INFO:Declaring metric variables
2023-09-05 16:15:28,384:INFO:Importing untrained model
2023-09-05 16:15:28,386:INFO:Random Forest Regressor Imported successfully
2023-09-05 16:15:28,391:INFO:Starting cross validation
2023-09-05 16:15:28,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:31,278:INFO:Calculating mean and std
2023-09-05 16:15:31,280:INFO:Creating metrics dataframe
2023-09-05 16:15:31,294:INFO:Uploading results into container
2023-09-05 16:15:31,296:INFO:Uploading model into container now
2023-09-05 16:15:31,297:INFO:_master_model_container: 2
2023-09-05 16:15:31,297:INFO:_display_container: 2
2023-09-05 16:15:31,298:INFO:RandomForestRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:31,298:INFO:create_model() successfully completed......................................
2023-09-05 16:15:31,380:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:31,380:INFO:Creating metrics dataframe
2023-09-05 16:15:31,391:INFO:Initializing create_model()
2023-09-05 16:15:31,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=RandomForestRegressor(n_jobs=-1, random_state=8397), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:31,391:INFO:Checking exceptions
2023-09-05 16:15:31,392:INFO:Importing libraries
2023-09-05 16:15:31,392:INFO:Copying training dataset
2023-09-05 16:15:31,394:INFO:Defining folds
2023-09-05 16:15:31,394:INFO:Declaring metric variables
2023-09-05 16:15:31,395:INFO:Importing untrained model
2023-09-05 16:15:31,395:INFO:Declaring custom model
2023-09-05 16:15:31,395:INFO:Random Forest Regressor Imported successfully
2023-09-05 16:15:31,396:INFO:Cross validation set to False
2023-09-05 16:15:31,396:INFO:Fitting Model
2023-09-05 16:15:31,633:INFO:RandomForestRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:31,633:INFO:create_model() successfully completed......................................
2023-09-05 16:15:31,716:INFO:_master_model_container: 2
2023-09-05 16:15:31,716:INFO:_display_container: 2
2023-09-05 16:15:31,717:INFO:RandomForestRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:31,717:INFO:compare_models() successfully completed......................................
2023-09-05 16:15:36,896:INFO:Initializing compare_models()
2023-09-05 16:15:36,896:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=2, budget_time=0.5, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 2, 'budget_time': 0.5, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 16:15:36,896:INFO:Checking exceptions
2023-09-05 16:15:36,898:INFO:Preparing display monitor
2023-09-05 16:15:36,915:INFO:Time budget is 0.5 minutes
2023-09-05 16:15:36,915:INFO:Initializing Linear Regression
2023-09-05 16:15:36,915:INFO:Total runtime is 0.0 minutes
2023-09-05 16:15:36,917:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:36,918:INFO:Initializing create_model()
2023-09-05 16:15:36,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:36,918:INFO:Checking exceptions
2023-09-05 16:15:36,918:INFO:Importing libraries
2023-09-05 16:15:36,918:INFO:Copying training dataset
2023-09-05 16:15:36,920:INFO:Defining folds
2023-09-05 16:15:36,921:INFO:Declaring metric variables
2023-09-05 16:15:36,925:INFO:Importing untrained model
2023-09-05 16:15:36,931:INFO:Linear Regression Imported successfully
2023-09-05 16:15:36,936:INFO:Starting cross validation
2023-09-05 16:15:36,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:37,214:INFO:Calculating mean and std
2023-09-05 16:15:37,214:INFO:Creating metrics dataframe
2023-09-05 16:15:37,223:INFO:Uploading results into container
2023-09-05 16:15:37,224:INFO:Uploading model into container now
2023-09-05 16:15:37,224:INFO:_master_model_container: 3
2023-09-05 16:15:37,224:INFO:_display_container: 3
2023-09-05 16:15:37,224:INFO:LinearRegression(n_jobs=-1)
2023-09-05 16:15:37,224:INFO:create_model() successfully completed......................................
2023-09-05 16:15:37,294:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:37,294:INFO:Creating metrics dataframe
2023-09-05 16:15:37,299:INFO:Initializing Lasso Regression
2023-09-05 16:15:37,299:INFO:Total runtime is 0.006391680240631104 minutes
2023-09-05 16:15:37,301:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:37,301:INFO:Initializing create_model()
2023-09-05 16:15:37,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:37,302:INFO:Checking exceptions
2023-09-05 16:15:37,302:INFO:Importing libraries
2023-09-05 16:15:37,302:INFO:Copying training dataset
2023-09-05 16:15:37,305:INFO:Defining folds
2023-09-05 16:15:37,305:INFO:Declaring metric variables
2023-09-05 16:15:37,308:INFO:Importing untrained model
2023-09-05 16:15:37,312:INFO:Lasso Regression Imported successfully
2023-09-05 16:15:37,318:INFO:Starting cross validation
2023-09-05 16:15:37,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:37,557:INFO:Calculating mean and std
2023-09-05 16:15:37,557:INFO:Creating metrics dataframe
2023-09-05 16:15:37,565:INFO:Uploading results into container
2023-09-05 16:15:37,565:INFO:Uploading model into container now
2023-09-05 16:15:37,565:INFO:_master_model_container: 4
2023-09-05 16:15:37,565:INFO:_display_container: 3
2023-09-05 16:15:37,566:INFO:Lasso(random_state=8397)
2023-09-05 16:15:37,566:INFO:create_model() successfully completed......................................
2023-09-05 16:15:37,638:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:37,638:INFO:Creating metrics dataframe
2023-09-05 16:15:37,644:INFO:Initializing Ridge Regression
2023-09-05 16:15:37,644:INFO:Total runtime is 0.012135799725850424 minutes
2023-09-05 16:15:37,646:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:37,646:INFO:Initializing create_model()
2023-09-05 16:15:37,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:37,646:INFO:Checking exceptions
2023-09-05 16:15:37,647:INFO:Importing libraries
2023-09-05 16:15:37,647:INFO:Copying training dataset
2023-09-05 16:15:37,649:INFO:Defining folds
2023-09-05 16:15:37,649:INFO:Declaring metric variables
2023-09-05 16:15:37,651:INFO:Importing untrained model
2023-09-05 16:15:37,657:INFO:Ridge Regression Imported successfully
2023-09-05 16:15:37,663:INFO:Starting cross validation
2023-09-05 16:15:37,664:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:37,917:INFO:Calculating mean and std
2023-09-05 16:15:37,918:INFO:Creating metrics dataframe
2023-09-05 16:15:37,926:INFO:Uploading results into container
2023-09-05 16:15:37,927:INFO:Uploading model into container now
2023-09-05 16:15:37,927:INFO:_master_model_container: 5
2023-09-05 16:15:37,927:INFO:_display_container: 3
2023-09-05 16:15:37,927:INFO:Ridge(random_state=8397)
2023-09-05 16:15:37,927:INFO:create_model() successfully completed......................................
2023-09-05 16:15:38,001:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:38,001:INFO:Creating metrics dataframe
2023-09-05 16:15:38,007:INFO:Initializing Elastic Net
2023-09-05 16:15:38,007:INFO:Total runtime is 0.01819612979888916 minutes
2023-09-05 16:15:38,010:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:38,010:INFO:Initializing create_model()
2023-09-05 16:15:38,010:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:38,010:INFO:Checking exceptions
2023-09-05 16:15:38,010:INFO:Importing libraries
2023-09-05 16:15:38,010:INFO:Copying training dataset
2023-09-05 16:15:38,014:INFO:Defining folds
2023-09-05 16:15:38,015:INFO:Declaring metric variables
2023-09-05 16:15:38,017:INFO:Importing untrained model
2023-09-05 16:15:38,019:INFO:Elastic Net Imported successfully
2023-09-05 16:15:38,025:INFO:Starting cross validation
2023-09-05 16:15:38,026:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:38,279:INFO:Calculating mean and std
2023-09-05 16:15:38,279:INFO:Creating metrics dataframe
2023-09-05 16:15:38,287:INFO:Uploading results into container
2023-09-05 16:15:38,288:INFO:Uploading model into container now
2023-09-05 16:15:38,288:INFO:_master_model_container: 6
2023-09-05 16:15:38,288:INFO:_display_container: 3
2023-09-05 16:15:38,288:INFO:ElasticNet(random_state=8397)
2023-09-05 16:15:38,288:INFO:create_model() successfully completed......................................
2023-09-05 16:15:38,364:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:38,364:INFO:Creating metrics dataframe
2023-09-05 16:15:38,370:INFO:Initializing Least Angle Regression
2023-09-05 16:15:38,370:INFO:Total runtime is 0.02424214283625285 minutes
2023-09-05 16:15:38,372:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:38,373:INFO:Initializing create_model()
2023-09-05 16:15:38,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:38,373:INFO:Checking exceptions
2023-09-05 16:15:38,373:INFO:Importing libraries
2023-09-05 16:15:38,373:INFO:Copying training dataset
2023-09-05 16:15:38,376:INFO:Defining folds
2023-09-05 16:15:38,376:INFO:Declaring metric variables
2023-09-05 16:15:38,379:INFO:Importing untrained model
2023-09-05 16:15:38,381:INFO:Least Angle Regression Imported successfully
2023-09-05 16:15:38,385:INFO:Starting cross validation
2023-09-05 16:15:38,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:38,641:INFO:Calculating mean and std
2023-09-05 16:15:38,642:INFO:Creating metrics dataframe
2023-09-05 16:15:38,652:INFO:Uploading results into container
2023-09-05 16:15:38,653:INFO:Uploading model into container now
2023-09-05 16:15:38,653:INFO:_master_model_container: 7
2023-09-05 16:15:38,653:INFO:_display_container: 3
2023-09-05 16:15:38,654:INFO:Lars(random_state=8397)
2023-09-05 16:15:38,654:INFO:create_model() successfully completed......................................
2023-09-05 16:15:38,732:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:38,732:INFO:Creating metrics dataframe
2023-09-05 16:15:38,740:INFO:Initializing Lasso Least Angle Regression
2023-09-05 16:15:38,740:INFO:Total runtime is 0.030405433972676595 minutes
2023-09-05 16:15:38,742:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:38,742:INFO:Initializing create_model()
2023-09-05 16:15:38,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:38,743:INFO:Checking exceptions
2023-09-05 16:15:38,743:INFO:Importing libraries
2023-09-05 16:15:38,743:INFO:Copying training dataset
2023-09-05 16:15:38,746:INFO:Defining folds
2023-09-05 16:15:38,746:INFO:Declaring metric variables
2023-09-05 16:15:38,749:INFO:Importing untrained model
2023-09-05 16:15:38,751:INFO:Lasso Least Angle Regression Imported successfully
2023-09-05 16:15:38,756:INFO:Starting cross validation
2023-09-05 16:15:38,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:39,030:INFO:Calculating mean and std
2023-09-05 16:15:39,031:INFO:Creating metrics dataframe
2023-09-05 16:15:39,044:INFO:Uploading results into container
2023-09-05 16:15:39,045:INFO:Uploading model into container now
2023-09-05 16:15:39,046:INFO:_master_model_container: 8
2023-09-05 16:15:39,046:INFO:_display_container: 3
2023-09-05 16:15:39,046:INFO:LassoLars(random_state=8397)
2023-09-05 16:15:39,046:INFO:create_model() successfully completed......................................
2023-09-05 16:15:39,121:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:39,121:INFO:Creating metrics dataframe
2023-09-05 16:15:39,127:INFO:Initializing Orthogonal Matching Pursuit
2023-09-05 16:15:39,127:INFO:Total runtime is 0.036856373151143394 minutes
2023-09-05 16:15:39,130:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:39,130:INFO:Initializing create_model()
2023-09-05 16:15:39,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:39,130:INFO:Checking exceptions
2023-09-05 16:15:39,130:INFO:Importing libraries
2023-09-05 16:15:39,130:INFO:Copying training dataset
2023-09-05 16:15:39,133:INFO:Defining folds
2023-09-05 16:15:39,133:INFO:Declaring metric variables
2023-09-05 16:15:39,135:INFO:Importing untrained model
2023-09-05 16:15:39,138:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-05 16:15:39,146:INFO:Starting cross validation
2023-09-05 16:15:39,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:39,402:INFO:Calculating mean and std
2023-09-05 16:15:39,403:INFO:Creating metrics dataframe
2023-09-05 16:15:39,411:INFO:Uploading results into container
2023-09-05 16:15:39,411:INFO:Uploading model into container now
2023-09-05 16:15:39,412:INFO:_master_model_container: 9
2023-09-05 16:15:39,412:INFO:_display_container: 3
2023-09-05 16:15:39,412:INFO:OrthogonalMatchingPursuit()
2023-09-05 16:15:39,412:INFO:create_model() successfully completed......................................
2023-09-05 16:15:39,484:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:39,484:INFO:Creating metrics dataframe
2023-09-05 16:15:39,490:INFO:Initializing Bayesian Ridge
2023-09-05 16:15:39,490:INFO:Total runtime is 0.04290488958358765 minutes
2023-09-05 16:15:39,493:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:39,493:INFO:Initializing create_model()
2023-09-05 16:15:39,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:39,493:INFO:Checking exceptions
2023-09-05 16:15:39,494:INFO:Importing libraries
2023-09-05 16:15:39,494:INFO:Copying training dataset
2023-09-05 16:15:39,496:INFO:Defining folds
2023-09-05 16:15:39,496:INFO:Declaring metric variables
2023-09-05 16:15:39,498:INFO:Importing untrained model
2023-09-05 16:15:39,500:INFO:Bayesian Ridge Imported successfully
2023-09-05 16:15:39,505:INFO:Starting cross validation
2023-09-05 16:15:39,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:39,747:INFO:Calculating mean and std
2023-09-05 16:15:39,748:INFO:Creating metrics dataframe
2023-09-05 16:15:39,756:INFO:Uploading results into container
2023-09-05 16:15:39,756:INFO:Uploading model into container now
2023-09-05 16:15:39,756:INFO:_master_model_container: 10
2023-09-05 16:15:39,756:INFO:_display_container: 3
2023-09-05 16:15:39,757:INFO:BayesianRidge()
2023-09-05 16:15:39,757:INFO:create_model() successfully completed......................................
2023-09-05 16:15:39,830:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:39,830:INFO:Creating metrics dataframe
2023-09-05 16:15:39,836:INFO:Initializing Passive Aggressive Regressor
2023-09-05 16:15:39,837:INFO:Total runtime is 0.04867813189824423 minutes
2023-09-05 16:15:39,839:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:39,839:INFO:Initializing create_model()
2023-09-05 16:15:39,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:39,839:INFO:Checking exceptions
2023-09-05 16:15:39,839:INFO:Importing libraries
2023-09-05 16:15:39,839:INFO:Copying training dataset
2023-09-05 16:15:39,842:INFO:Defining folds
2023-09-05 16:15:39,842:INFO:Declaring metric variables
2023-09-05 16:15:39,844:INFO:Importing untrained model
2023-09-05 16:15:39,847:INFO:Passive Aggressive Regressor Imported successfully
2023-09-05 16:15:39,851:INFO:Starting cross validation
2023-09-05 16:15:39,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:40,092:INFO:Calculating mean and std
2023-09-05 16:15:40,093:INFO:Creating metrics dataframe
2023-09-05 16:15:40,103:INFO:Uploading results into container
2023-09-05 16:15:40,103:INFO:Uploading model into container now
2023-09-05 16:15:40,104:INFO:_master_model_container: 11
2023-09-05 16:15:40,104:INFO:_display_container: 3
2023-09-05 16:15:40,104:INFO:PassiveAggressiveRegressor(random_state=8397)
2023-09-05 16:15:40,104:INFO:create_model() successfully completed......................................
2023-09-05 16:15:40,174:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:40,175:INFO:Creating metrics dataframe
2023-09-05 16:15:40,181:INFO:Initializing Huber Regressor
2023-09-05 16:15:40,181:INFO:Total runtime is 0.054424818356831876 minutes
2023-09-05 16:15:40,183:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:40,183:INFO:Initializing create_model()
2023-09-05 16:15:40,183:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:40,183:INFO:Checking exceptions
2023-09-05 16:15:40,184:INFO:Importing libraries
2023-09-05 16:15:40,184:INFO:Copying training dataset
2023-09-05 16:15:40,186:INFO:Defining folds
2023-09-05 16:15:40,186:INFO:Declaring metric variables
2023-09-05 16:15:40,189:INFO:Importing untrained model
2023-09-05 16:15:40,193:INFO:Huber Regressor Imported successfully
2023-09-05 16:15:40,199:INFO:Starting cross validation
2023-09-05 16:15:40,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:40,324:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,342:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,353:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,361:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,365:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,370:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,372:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,387:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,392:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 16:15:40,471:INFO:Calculating mean and std
2023-09-05 16:15:40,471:INFO:Creating metrics dataframe
2023-09-05 16:15:40,481:INFO:Uploading results into container
2023-09-05 16:15:40,482:INFO:Uploading model into container now
2023-09-05 16:15:40,483:INFO:_master_model_container: 12
2023-09-05 16:15:40,483:INFO:_display_container: 3
2023-09-05 16:15:40,483:INFO:HuberRegressor()
2023-09-05 16:15:40,483:INFO:create_model() successfully completed......................................
2023-09-05 16:15:40,554:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:40,554:INFO:Creating metrics dataframe
2023-09-05 16:15:40,561:INFO:Initializing K Neighbors Regressor
2023-09-05 16:15:40,561:INFO:Total runtime is 0.06076442003250123 minutes
2023-09-05 16:15:40,563:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:40,563:INFO:Initializing create_model()
2023-09-05 16:15:40,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:40,563:INFO:Checking exceptions
2023-09-05 16:15:40,564:INFO:Importing libraries
2023-09-05 16:15:40,564:INFO:Copying training dataset
2023-09-05 16:15:40,566:INFO:Defining folds
2023-09-05 16:15:40,566:INFO:Declaring metric variables
2023-09-05 16:15:40,569:INFO:Importing untrained model
2023-09-05 16:15:40,571:INFO:K Neighbors Regressor Imported successfully
2023-09-05 16:15:40,576:INFO:Starting cross validation
2023-09-05 16:15:40,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:40,848:INFO:Calculating mean and std
2023-09-05 16:15:40,849:INFO:Creating metrics dataframe
2023-09-05 16:15:40,864:INFO:Uploading results into container
2023-09-05 16:15:40,865:INFO:Uploading model into container now
2023-09-05 16:15:40,865:INFO:_master_model_container: 13
2023-09-05 16:15:40,865:INFO:_display_container: 3
2023-09-05 16:15:40,865:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-05 16:15:40,865:INFO:create_model() successfully completed......................................
2023-09-05 16:15:40,939:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:40,939:INFO:Creating metrics dataframe
2023-09-05 16:15:40,946:INFO:Initializing Decision Tree Regressor
2023-09-05 16:15:40,947:INFO:Total runtime is 0.0671762784322103 minutes
2023-09-05 16:15:40,950:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:40,950:INFO:Initializing create_model()
2023-09-05 16:15:40,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:40,950:INFO:Checking exceptions
2023-09-05 16:15:40,950:INFO:Importing libraries
2023-09-05 16:15:40,950:INFO:Copying training dataset
2023-09-05 16:15:40,954:INFO:Defining folds
2023-09-05 16:15:40,954:INFO:Declaring metric variables
2023-09-05 16:15:40,956:INFO:Importing untrained model
2023-09-05 16:15:40,958:INFO:Decision Tree Regressor Imported successfully
2023-09-05 16:15:40,965:INFO:Starting cross validation
2023-09-05 16:15:40,966:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:41,224:INFO:Calculating mean and std
2023-09-05 16:15:41,225:INFO:Creating metrics dataframe
2023-09-05 16:15:41,233:INFO:Uploading results into container
2023-09-05 16:15:41,234:INFO:Uploading model into container now
2023-09-05 16:15:41,234:INFO:_master_model_container: 14
2023-09-05 16:15:41,234:INFO:_display_container: 3
2023-09-05 16:15:41,234:INFO:DecisionTreeRegressor(random_state=8397)
2023-09-05 16:15:41,234:INFO:create_model() successfully completed......................................
2023-09-05 16:15:41,308:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:41,308:INFO:Creating metrics dataframe
2023-09-05 16:15:41,315:INFO:Initializing Random Forest Regressor
2023-09-05 16:15:41,315:INFO:Total runtime is 0.07333229780197145 minutes
2023-09-05 16:15:41,317:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:41,317:INFO:Initializing create_model()
2023-09-05 16:15:41,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:41,317:INFO:Checking exceptions
2023-09-05 16:15:41,317:INFO:Importing libraries
2023-09-05 16:15:41,317:INFO:Copying training dataset
2023-09-05 16:15:41,320:INFO:Defining folds
2023-09-05 16:15:41,320:INFO:Declaring metric variables
2023-09-05 16:15:41,322:INFO:Importing untrained model
2023-09-05 16:15:41,324:INFO:Random Forest Regressor Imported successfully
2023-09-05 16:15:41,330:INFO:Starting cross validation
2023-09-05 16:15:41,331:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:41,708:INFO:Calculating mean and std
2023-09-05 16:15:41,708:INFO:Creating metrics dataframe
2023-09-05 16:15:41,716:INFO:Uploading results into container
2023-09-05 16:15:41,717:INFO:Uploading model into container now
2023-09-05 16:15:41,717:INFO:_master_model_container: 15
2023-09-05 16:15:41,717:INFO:_display_container: 3
2023-09-05 16:15:41,717:INFO:RandomForestRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:41,717:INFO:create_model() successfully completed......................................
2023-09-05 16:15:41,790:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:41,790:INFO:Creating metrics dataframe
2023-09-05 16:15:41,798:INFO:Initializing Extra Trees Regressor
2023-09-05 16:15:41,798:INFO:Total runtime is 0.08136907021204633 minutes
2023-09-05 16:15:41,801:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:41,801:INFO:Initializing create_model()
2023-09-05 16:15:41,801:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:41,801:INFO:Checking exceptions
2023-09-05 16:15:41,801:INFO:Importing libraries
2023-09-05 16:15:41,801:INFO:Copying training dataset
2023-09-05 16:15:41,804:INFO:Defining folds
2023-09-05 16:15:41,804:INFO:Declaring metric variables
2023-09-05 16:15:41,807:INFO:Importing untrained model
2023-09-05 16:15:41,809:INFO:Extra Trees Regressor Imported successfully
2023-09-05 16:15:41,813:INFO:Starting cross validation
2023-09-05 16:15:41,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:42,489:INFO:Calculating mean and std
2023-09-05 16:15:42,490:INFO:Creating metrics dataframe
2023-09-05 16:15:42,510:INFO:Uploading results into container
2023-09-05 16:15:42,511:INFO:Uploading model into container now
2023-09-05 16:15:42,512:INFO:_master_model_container: 16
2023-09-05 16:15:42,512:INFO:_display_container: 3
2023-09-05 16:15:42,512:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:42,512:INFO:create_model() successfully completed......................................
2023-09-05 16:15:42,587:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:42,587:INFO:Creating metrics dataframe
2023-09-05 16:15:42,595:INFO:Initializing AdaBoost Regressor
2023-09-05 16:15:42,595:INFO:Total runtime is 0.09466137886047366 minutes
2023-09-05 16:15:42,597:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:42,597:INFO:Initializing create_model()
2023-09-05 16:15:42,597:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:42,597:INFO:Checking exceptions
2023-09-05 16:15:42,597:INFO:Importing libraries
2023-09-05 16:15:42,598:INFO:Copying training dataset
2023-09-05 16:15:42,601:INFO:Defining folds
2023-09-05 16:15:42,601:INFO:Declaring metric variables
2023-09-05 16:15:42,603:INFO:Importing untrained model
2023-09-05 16:15:42,605:INFO:AdaBoost Regressor Imported successfully
2023-09-05 16:15:42,609:INFO:Starting cross validation
2023-09-05 16:15:42,610:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:42,911:INFO:Calculating mean and std
2023-09-05 16:15:42,912:INFO:Creating metrics dataframe
2023-09-05 16:15:42,925:INFO:Uploading results into container
2023-09-05 16:15:42,925:INFO:Uploading model into container now
2023-09-05 16:15:42,925:INFO:_master_model_container: 17
2023-09-05 16:15:42,925:INFO:_display_container: 3
2023-09-05 16:15:42,926:INFO:AdaBoostRegressor(random_state=8397)
2023-09-05 16:15:42,926:INFO:create_model() successfully completed......................................
2023-09-05 16:15:43,001:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:43,002:INFO:Creating metrics dataframe
2023-09-05 16:15:43,009:INFO:Initializing Gradient Boosting Regressor
2023-09-05 16:15:43,009:INFO:Total runtime is 0.10155891974767052 minutes
2023-09-05 16:15:43,011:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:43,011:INFO:Initializing create_model()
2023-09-05 16:15:43,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:43,012:INFO:Checking exceptions
2023-09-05 16:15:43,012:INFO:Importing libraries
2023-09-05 16:15:43,012:INFO:Copying training dataset
2023-09-05 16:15:43,014:INFO:Defining folds
2023-09-05 16:15:43,014:INFO:Declaring metric variables
2023-09-05 16:15:43,017:INFO:Importing untrained model
2023-09-05 16:15:43,019:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 16:15:43,024:INFO:Starting cross validation
2023-09-05 16:15:43,025:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:43,526:INFO:Calculating mean and std
2023-09-05 16:15:43,527:INFO:Creating metrics dataframe
2023-09-05 16:15:43,542:INFO:Uploading results into container
2023-09-05 16:15:43,543:INFO:Uploading model into container now
2023-09-05 16:15:43,543:INFO:_master_model_container: 18
2023-09-05 16:15:43,543:INFO:_display_container: 3
2023-09-05 16:15:43,543:INFO:GradientBoostingRegressor(random_state=8397)
2023-09-05 16:15:43,543:INFO:create_model() successfully completed......................................
2023-09-05 16:15:43,618:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:43,618:INFO:Creating metrics dataframe
2023-09-05 16:15:43,625:INFO:Initializing Extreme Gradient Boosting
2023-09-05 16:15:43,625:INFO:Total runtime is 0.11182144880294803 minutes
2023-09-05 16:15:43,628:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:43,628:INFO:Initializing create_model()
2023-09-05 16:15:43,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:43,628:INFO:Checking exceptions
2023-09-05 16:15:43,628:INFO:Importing libraries
2023-09-05 16:15:43,628:INFO:Copying training dataset
2023-09-05 16:15:43,631:INFO:Defining folds
2023-09-05 16:15:43,631:INFO:Declaring metric variables
2023-09-05 16:15:43,633:INFO:Importing untrained model
2023-09-05 16:15:43,636:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 16:15:43,641:INFO:Starting cross validation
2023-09-05 16:15:43,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:44,061:INFO:Calculating mean and std
2023-09-05 16:15:44,062:INFO:Creating metrics dataframe
2023-09-05 16:15:44,075:INFO:Uploading results into container
2023-09-05 16:15:44,076:INFO:Uploading model into container now
2023-09-05 16:15:44,076:INFO:_master_model_container: 19
2023-09-05 16:15:44,076:INFO:_display_container: 3
2023-09-05 16:15:44,077:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=8397, ...)
2023-09-05 16:15:44,077:INFO:create_model() successfully completed......................................
2023-09-05 16:15:44,151:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:44,151:INFO:Creating metrics dataframe
2023-09-05 16:15:44,159:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 16:15:44,159:INFO:Total runtime is 0.1207272291183472 minutes
2023-09-05 16:15:44,161:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:44,161:INFO:Initializing create_model()
2023-09-05 16:15:44,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:44,161:INFO:Checking exceptions
2023-09-05 16:15:44,161:INFO:Importing libraries
2023-09-05 16:15:44,162:INFO:Copying training dataset
2023-09-05 16:15:44,165:INFO:Defining folds
2023-09-05 16:15:44,165:INFO:Declaring metric variables
2023-09-05 16:15:44,167:INFO:Importing untrained model
2023-09-05 16:15:44,169:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 16:15:44,174:INFO:Starting cross validation
2023-09-05 16:15:44,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:45,029:INFO:Calculating mean and std
2023-09-05 16:15:45,031:INFO:Creating metrics dataframe
2023-09-05 16:15:45,061:INFO:Uploading results into container
2023-09-05 16:15:45,062:INFO:Uploading model into container now
2023-09-05 16:15:45,062:INFO:_master_model_container: 20
2023-09-05 16:15:45,062:INFO:_display_container: 3
2023-09-05 16:15:45,063:INFO:LGBMRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:45,063:INFO:create_model() successfully completed......................................
2023-09-05 16:15:45,159:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:45,159:INFO:Creating metrics dataframe
2023-09-05 16:15:45,169:INFO:Initializing CatBoost Regressor
2023-09-05 16:15:45,169:INFO:Total runtime is 0.137564222017924 minutes
2023-09-05 16:15:45,171:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:45,172:INFO:Initializing create_model()
2023-09-05 16:15:45,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:45,172:INFO:Checking exceptions
2023-09-05 16:15:45,172:INFO:Importing libraries
2023-09-05 16:15:45,172:INFO:Copying training dataset
2023-09-05 16:15:45,175:INFO:Defining folds
2023-09-05 16:15:45,175:INFO:Declaring metric variables
2023-09-05 16:15:45,178:INFO:Importing untrained model
2023-09-05 16:15:45,181:INFO:CatBoost Regressor Imported successfully
2023-09-05 16:15:45,188:INFO:Starting cross validation
2023-09-05 16:15:45,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:47,971:INFO:Calculating mean and std
2023-09-05 16:15:47,972:INFO:Creating metrics dataframe
2023-09-05 16:15:47,997:INFO:Uploading results into container
2023-09-05 16:15:47,997:INFO:Uploading model into container now
2023-09-05 16:15:47,998:INFO:_master_model_container: 21
2023-09-05 16:15:47,998:INFO:_display_container: 3
2023-09-05 16:15:47,998:INFO:<catboost.core.CatBoostRegressor object at 0x000001622EFFDA30>
2023-09-05 16:15:47,998:INFO:create_model() successfully completed......................................
2023-09-05 16:15:48,071:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:48,071:INFO:Creating metrics dataframe
2023-09-05 16:15:48,079:INFO:Initializing Dummy Regressor
2023-09-05 16:15:48,079:INFO:Total runtime is 0.18605376879374189 minutes
2023-09-05 16:15:48,081:INFO:SubProcess create_model() called ==================================
2023-09-05 16:15:48,081:INFO:Initializing create_model()
2023-09-05 16:15:48,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622B080430>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:48,082:INFO:Checking exceptions
2023-09-05 16:15:48,082:INFO:Importing libraries
2023-09-05 16:15:48,082:INFO:Copying training dataset
2023-09-05 16:15:48,084:INFO:Defining folds
2023-09-05 16:15:48,084:INFO:Declaring metric variables
2023-09-05 16:15:48,087:INFO:Importing untrained model
2023-09-05 16:15:48,089:INFO:Dummy Regressor Imported successfully
2023-09-05 16:15:48,093:INFO:Starting cross validation
2023-09-05 16:15:48,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:15:48,424:INFO:Calculating mean and std
2023-09-05 16:15:48,425:INFO:Creating metrics dataframe
2023-09-05 16:15:48,450:INFO:Uploading results into container
2023-09-05 16:15:48,450:INFO:Uploading model into container now
2023-09-05 16:15:48,451:INFO:_master_model_container: 22
2023-09-05 16:15:48,451:INFO:_display_container: 3
2023-09-05 16:15:48,451:INFO:DummyRegressor()
2023-09-05 16:15:48,451:INFO:create_model() successfully completed......................................
2023-09-05 16:15:48,523:INFO:SubProcess create_model() end ==================================
2023-09-05 16:15:48,523:INFO:Creating metrics dataframe
2023-09-05 16:15:48,538:INFO:Initializing create_model()
2023-09-05 16:15:48,538:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=GradientBoostingRegressor(random_state=8397), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:48,538:INFO:Checking exceptions
2023-09-05 16:15:48,539:INFO:Importing libraries
2023-09-05 16:15:48,539:INFO:Copying training dataset
2023-09-05 16:15:48,541:INFO:Defining folds
2023-09-05 16:15:48,541:INFO:Declaring metric variables
2023-09-05 16:15:48,541:INFO:Importing untrained model
2023-09-05 16:15:48,541:INFO:Declaring custom model
2023-09-05 16:15:48,541:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 16:15:48,541:INFO:Cross validation set to False
2023-09-05 16:15:48,541:INFO:Fitting Model
2023-09-05 16:15:48,681:INFO:GradientBoostingRegressor(random_state=8397)
2023-09-05 16:15:48,681:INFO:create_model() successfully completed......................................
2023-09-05 16:15:48,756:INFO:Initializing create_model()
2023-09-05 16:15:48,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=8397), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 16:15:48,756:INFO:Checking exceptions
2023-09-05 16:15:48,757:INFO:Importing libraries
2023-09-05 16:15:48,757:INFO:Copying training dataset
2023-09-05 16:15:48,759:INFO:Defining folds
2023-09-05 16:15:48,759:INFO:Declaring metric variables
2023-09-05 16:15:48,760:INFO:Importing untrained model
2023-09-05 16:15:48,760:INFO:Declaring custom model
2023-09-05 16:15:48,760:INFO:Extra Trees Regressor Imported successfully
2023-09-05 16:15:48,761:INFO:Cross validation set to False
2023-09-05 16:15:48,761:INFO:Fitting Model
2023-09-05 16:15:48,919:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8397)
2023-09-05 16:15:48,919:INFO:create_model() successfully completed......................................
2023-09-05 16:15:49,016:INFO:_master_model_container: 22
2023-09-05 16:15:49,016:INFO:_display_container: 3
2023-09-05 16:15:49,017:INFO:[GradientBoostingRegressor(random_state=8397), ExtraTreesRegressor(n_jobs=-1, random_state=8397)]
2023-09-05 16:15:49,017:INFO:compare_models() successfully completed......................................
2023-09-05 16:45:14,374:INFO:Initializing create_model()
2023-09-05 16:45:14,374:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001622B22F250>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'max_depth': 5})
2023-09-05 16:45:14,374:INFO:Checking exceptions
2023-09-05 16:45:14,384:INFO:Importing libraries
2023-09-05 16:45:14,384:INFO:Copying training dataset
2023-09-05 16:45:14,389:INFO:Defining folds
2023-09-05 16:45:14,389:INFO:Declaring metric variables
2023-09-05 16:45:14,391:INFO:Importing untrained model
2023-09-05 16:45:14,395:INFO:Decision Tree Regressor Imported successfully
2023-09-05 16:45:14,399:INFO:Starting cross validation
2023-09-05 16:45:14,400:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 16:45:17,711:INFO:Calculating mean and std
2023-09-05 16:45:17,712:INFO:Creating metrics dataframe
2023-09-05 16:45:17,716:INFO:Finalizing model
2023-09-05 16:45:17,807:INFO:Uploading results into container
2023-09-05 16:45:17,808:INFO:Uploading model into container now
2023-09-05 16:45:17,814:INFO:_master_model_container: 23
2023-09-05 16:45:17,814:INFO:_display_container: 4
2023-09-05 16:45:17,814:INFO:DecisionTreeRegressor(max_depth=5, random_state=8397)
2023-09-05 16:45:17,814:INFO:create_model() successfully completed......................................
2023-09-05 17:23:42,787:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_3d2d26eabc004c1192e57568712fd153_6739b454791f4bc8add74c8c796522c3
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,788:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_4730b8f46cc44aaaa1cbca1e55a1e5ff
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,788:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_25e5bb6ffe104e4297df265dc79e66da_a19eb51d0da949f385b05e9a862afd7c
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,788:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_fac905dbb35f4dc8af3e0ff569d06a46
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,788:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_038f9604595749e8a1f09423f1c87268_a3016685aea34e49945f003165dc5ad5
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,788:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_2da6b4c6b4ca4247b3d1f44760fbbdf2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_64995625435e46588bfef77b67a96c85_ed001926a0b84d46badf9bfcb3488a83
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_5a37d33a97cd42f8b6d89ff44b02cc6e
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_1105c8efa1dd4eaa9a1bc2fc5e2a3584_21fa441c81434e5cb4ccc7186db8ec12
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_cc7cc515eec9495b91e4bc502d40a0dd
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_eb48cdf617f245a495b36b7bd5ed5d3a_6fe661e7501a45388b5fec2c5d644dc1
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,789:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_0ffda8767a0b47a187b5cc48356cecd9
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_6e434fb88efc43348882ed808b790fc5_dbe3b21a38144a7292b27e384024ac31
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_e4850651ae574f7e9056965c275c96ad
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_a2d68622de6e45d98cfa2b6f928f4486_8125b37b05f84914ba6effbb5efcde11
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_f3d79fbc38af428aae57b310a2ffbb4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_cea8d2333c38493d8aa1076e42f68b23_cfada7869fca4ca8ad0e88b34e93a2f2
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_fc4b448aa85443caab4b8ca82572bd81
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:42,790:WARNING:C:\AI\pythonProject\venv\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\asiae\AppData\Local\Temp\joblib_memmapping_folder_2604_0e76a482b7634169b5b77a5a509dab3a_71c7b068eb10490e85ff4bc7de0a014d
  warnings.warn("Failed to delete temporary folder: {}"

2023-09-05 17:23:48,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:23:48,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:23:48,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:23:48,882:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:25:13,033:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:25:13,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:25:13,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:25:13,034:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-09-05 17:25:13,255:INFO:PyCaret ClassificationExperiment
2023-09-05 17:25:13,255:INFO:Logging name: clf-default-name
2023-09-05 17:25:13,255:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-09-05 17:25:13,255:INFO:version 3.0.4
2023-09-05 17:25:13,255:INFO:Initializing setup()
2023-09-05 17:25:13,255:INFO:self.USI: 3c58
2023-09-05 17:25:13,255:INFO:self._variable_keys: {'exp_id', 'exp_name_log', 'y_test', 'gpu_n_jobs_param', 'is_multiclass', 'y', 'logging_param', 'fold_generator', 'pipeline', 'USI', 'n_jobs_param', 'X_train', 'X_test', 'log_plots_param', 'fold_groups_param', 'idx', 'y_train', 'seed', 'memory', 'X', 'html_param', 'data', 'target_param', 'fold_shuffle_param', '_available_plots', '_ml_usecase', 'fix_imbalance', 'gpu_param'}
2023-09-05 17:25:13,255:INFO:Checking environment
2023-09-05 17:25:13,255:INFO:python_version: 3.8.8
2023-09-05 17:25:13,255:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 17:25:13,255:INFO:machine: AMD64
2023-09-05 17:25:13,255:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 17:25:13,259:INFO:Memory: svmem(total=16822788096, available=6400139264, percent=62.0, used=10422648832, free=6400139264)
2023-09-05 17:25:13,259:INFO:Physical Core: 8
2023-09-05 17:25:13,259:INFO:Logical Core: 16
2023-09-05 17:25:13,259:INFO:Checking libraries
2023-09-05 17:25:13,259:INFO:System:
2023-09-05 17:25:13,259:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 17:25:13,259:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 17:25:13,259:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 17:25:13,259:INFO:PyCaret required dependencies:
2023-09-05 17:25:13,261:INFO:                 pip: 22.3.1
2023-09-05 17:25:13,261:INFO:          setuptools: 65.5.1
2023-09-05 17:25:13,261:INFO:             pycaret: 3.0.4
2023-09-05 17:25:13,261:INFO:             IPython: 8.12.2
2023-09-05 17:25:13,261:INFO:          ipywidgets: 8.0.7
2023-09-05 17:25:13,261:INFO:                tqdm: 4.66.1
2023-09-05 17:25:13,261:INFO:               numpy: 1.23.5
2023-09-05 17:25:13,261:INFO:              pandas: 1.5.3
2023-09-05 17:25:13,261:INFO:              jinja2: 3.1.2
2023-09-05 17:25:13,262:INFO:               scipy: 1.10.1
2023-09-05 17:25:13,262:INFO:              joblib: 1.3.2
2023-09-05 17:25:13,262:INFO:             sklearn: 1.2.2
2023-09-05 17:25:13,262:INFO:                pyod: 1.1.0
2023-09-05 17:25:13,262:INFO:            imblearn: 0.11.0
2023-09-05 17:25:13,262:INFO:   category_encoders: 2.6.2
2023-09-05 17:25:13,262:INFO:            lightgbm: 4.0.0
2023-09-05 17:25:13,262:INFO:               numba: 0.57.1
2023-09-05 17:25:13,262:INFO:            requests: 2.31.0
2023-09-05 17:25:13,262:INFO:          matplotlib: 3.7.2
2023-09-05 17:25:13,262:INFO:          scikitplot: 0.3.7
2023-09-05 17:25:13,262:INFO:         yellowbrick: 1.5
2023-09-05 17:25:13,262:INFO:              plotly: 5.15.0
2023-09-05 17:25:13,262:INFO:    plotly-resampler: Not installed
2023-09-05 17:25:13,262:INFO:             kaleido: 0.2.1
2023-09-05 17:25:13,262:INFO:           schemdraw: 0.15
2023-09-05 17:25:13,262:INFO:         statsmodels: 0.14.0
2023-09-05 17:25:13,262:INFO:              sktime: 0.22.0
2023-09-05 17:25:13,262:INFO:               tbats: 1.1.3
2023-09-05 17:25:13,262:INFO:            pmdarima: 2.0.3
2023-09-05 17:25:13,262:INFO:              psutil: 5.9.5
2023-09-05 17:25:13,262:INFO:          markupsafe: 2.1.3
2023-09-05 17:25:13,262:INFO:             pickle5: Not installed
2023-09-05 17:25:13,262:INFO:         cloudpickle: 2.2.1
2023-09-05 17:25:13,262:INFO:         deprecation: 2.1.0
2023-09-05 17:25:13,262:INFO:              xxhash: 3.3.0
2023-09-05 17:25:13,262:INFO:           wurlitzer: Not installed
2023-09-05 17:25:13,262:INFO:PyCaret optional dependencies:
2023-09-05 17:25:14,478:INFO:                shap: Not installed
2023-09-05 17:25:14,478:INFO:           interpret: Not installed
2023-09-05 17:25:14,479:INFO:                umap: Not installed
2023-09-05 17:25:14,479:INFO:    pandas_profiling: Not installed
2023-09-05 17:25:14,479:INFO:  explainerdashboard: Not installed
2023-09-05 17:25:14,479:INFO:             autoviz: Not installed
2023-09-05 17:25:14,479:INFO:           fairlearn: Not installed
2023-09-05 17:25:14,479:INFO:          deepchecks: Not installed
2023-09-05 17:25:14,479:INFO:             xgboost: 1.7.6
2023-09-05 17:25:14,479:INFO:            catboost: 1.2.1
2023-09-05 17:25:14,479:INFO:              kmodes: Not installed
2023-09-05 17:25:14,479:INFO:             mlxtend: Not installed
2023-09-05 17:25:14,479:INFO:       statsforecast: Not installed
2023-09-05 17:25:14,479:INFO:        tune_sklearn: 0.4.6
2023-09-05 17:25:14,479:INFO:                 ray: 2.6.3
2023-09-05 17:25:14,479:INFO:            hyperopt: Not installed
2023-09-05 17:25:14,479:INFO:              optuna: 3.3.0
2023-09-05 17:25:14,479:INFO:               skopt: 0.9.0
2023-09-05 17:25:14,479:INFO:              mlflow: Not installed
2023-09-05 17:25:14,479:INFO:              gradio: 3.42.0
2023-09-05 17:25:14,479:INFO:             fastapi: 0.103.1
2023-09-05 17:25:14,479:INFO:             uvicorn: 0.23.2
2023-09-05 17:25:14,479:INFO:              m2cgen: Not installed
2023-09-05 17:25:14,479:INFO:           evidently: Not installed
2023-09-05 17:25:14,479:INFO:               fugue: Not installed
2023-09-05 17:25:14,479:INFO:           streamlit: Not installed
2023-09-05 17:25:14,479:INFO:             prophet: Not installed
2023-09-05 17:25:14,479:INFO:None
2023-09-05 17:25:14,479:INFO:Set up data.
2023-09-05 17:25:14,483:INFO:Set up train/test split.
2023-09-05 17:25:14,486:INFO:Set up index.
2023-09-05 17:25:14,486:INFO:Set up folding strategy.
2023-09-05 17:25:14,486:INFO:Assigning column types.
2023-09-05 17:25:14,487:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 17:25:14,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,520:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,545:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,547:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,603:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,623:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,625:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,625:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 17:25:14,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,676:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,677:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,707:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-09-05 17:25:14,727:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,728:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,728:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-09-05 17:25:14,777:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,779:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,831:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,832:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:14,834:INFO:Preparing preprocessing pipeline...
2023-09-05 17:25:14,835:INFO:Set up simple imputation.
2023-09-05 17:25:14,848:INFO:Finished creating preprocessing pipeline.
2023-09-05 17:25:14,850:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['pclass', 'sex', 'age', 'fare',
                                             'name_title', 'family',
                                             'fare_per_family', 'cabin2',
                                             'etc'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-09-05 17:25:14,850:INFO:Creating final display dataframe.
2023-09-05 17:25:14,888:INFO:Setup _display_container:                     Description             Value
0                    Session id              1212
1                        Target          survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 10)
5   Transformed train set shape         (712, 10)
6    Transformed test set shape         (179, 10)
7              Numeric features                 9
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                 3
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3c58
2023-09-05 17:25:14,948:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:14,950:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,001:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:15,003:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,004:INFO:setup() successfully completed in 1.77s...............
2023-09-05 17:25:15,017:INFO:gpu_param set to False
2023-09-05 17:25:15,074:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:15,076:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,132:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:15,134:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,156:INFO:gpu_param set to False
2023-09-05 17:25:15,211:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:15,213:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,265:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:25:15,267:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:25:15,313:INFO:Initializing compare_models()
2023-09-05 17:25:15,313:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, include=None, fold=None, round=4, cross_validation=True, sort=F1, n_select=4, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, 'include': None, 'exclude': ['catboost'], 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'F1', 'n_select': 4, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=['catboost'])
2023-09-05 17:25:15,313:INFO:Checking exceptions
2023-09-05 17:25:15,317:INFO:Preparing display monitor
2023-09-05 17:25:15,341:INFO:Initializing Logistic Regression
2023-09-05 17:25:15,341:INFO:Total runtime is 0.0 minutes
2023-09-05 17:25:15,343:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:15,344:INFO:Initializing create_model()
2023-09-05 17:25:15,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=lr, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:15,344:INFO:Checking exceptions
2023-09-05 17:25:15,344:INFO:Importing libraries
2023-09-05 17:25:15,344:INFO:Copying training dataset
2023-09-05 17:25:15,347:INFO:Defining folds
2023-09-05 17:25:15,347:INFO:Declaring metric variables
2023-09-05 17:25:15,349:INFO:Importing untrained model
2023-09-05 17:25:15,351:INFO:Logistic Regression Imported successfully
2023-09-05 17:25:15,355:INFO:Starting cross validation
2023-09-05 17:25:15,356:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:17,714:INFO:Calculating mean and std
2023-09-05 17:25:17,715:INFO:Creating metrics dataframe
2023-09-05 17:25:17,740:INFO:Uploading results into container
2023-09-05 17:25:17,740:INFO:Uploading model into container now
2023-09-05 17:25:17,741:INFO:_master_model_container: 1
2023-09-05 17:25:17,741:INFO:_display_container: 2
2023-09-05 17:25:17,741:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1212, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-09-05 17:25:17,741:INFO:create_model() successfully completed......................................
2023-09-05 17:25:17,811:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:17,811:INFO:Creating metrics dataframe
2023-09-05 17:25:17,817:INFO:Initializing K Neighbors Classifier
2023-09-05 17:25:17,817:INFO:Total runtime is 0.04126493136088053 minutes
2023-09-05 17:25:17,820:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:17,820:INFO:Initializing create_model()
2023-09-05 17:25:17,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=knn, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:17,820:INFO:Checking exceptions
2023-09-05 17:25:17,820:INFO:Importing libraries
2023-09-05 17:25:17,820:INFO:Copying training dataset
2023-09-05 17:25:17,823:INFO:Defining folds
2023-09-05 17:25:17,823:INFO:Declaring metric variables
2023-09-05 17:25:17,825:INFO:Importing untrained model
2023-09-05 17:25:17,827:INFO:K Neighbors Classifier Imported successfully
2023-09-05 17:25:17,832:INFO:Starting cross validation
2023-09-05 17:25:17,832:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:19,587:INFO:Calculating mean and std
2023-09-05 17:25:19,589:INFO:Creating metrics dataframe
2023-09-05 17:25:19,619:INFO:Uploading results into container
2023-09-05 17:25:19,619:INFO:Uploading model into container now
2023-09-05 17:25:19,620:INFO:_master_model_container: 2
2023-09-05 17:25:19,620:INFO:_display_container: 2
2023-09-05 17:25:19,620:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-09-05 17:25:19,620:INFO:create_model() successfully completed......................................
2023-09-05 17:25:19,694:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:19,695:INFO:Creating metrics dataframe
2023-09-05 17:25:19,702:INFO:Initializing Naive Bayes
2023-09-05 17:25:19,702:INFO:Total runtime is 0.07267318566640218 minutes
2023-09-05 17:25:19,703:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:19,703:INFO:Initializing create_model()
2023-09-05 17:25:19,703:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=nb, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:19,703:INFO:Checking exceptions
2023-09-05 17:25:19,703:INFO:Importing libraries
2023-09-05 17:25:19,703:INFO:Copying training dataset
2023-09-05 17:25:19,706:INFO:Defining folds
2023-09-05 17:25:19,706:INFO:Declaring metric variables
2023-09-05 17:25:19,709:INFO:Importing untrained model
2023-09-05 17:25:19,711:INFO:Naive Bayes Imported successfully
2023-09-05 17:25:19,720:INFO:Starting cross validation
2023-09-05 17:25:19,721:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:21,530:INFO:Calculating mean and std
2023-09-05 17:25:21,533:INFO:Creating metrics dataframe
2023-09-05 17:25:21,558:INFO:Uploading results into container
2023-09-05 17:25:21,559:INFO:Uploading model into container now
2023-09-05 17:25:21,559:INFO:_master_model_container: 3
2023-09-05 17:25:21,559:INFO:_display_container: 2
2023-09-05 17:25:21,559:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-09-05 17:25:21,559:INFO:create_model() successfully completed......................................
2023-09-05 17:25:21,639:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:21,639:INFO:Creating metrics dataframe
2023-09-05 17:25:21,645:INFO:Initializing Decision Tree Classifier
2023-09-05 17:25:21,645:INFO:Total runtime is 0.10506125688552856 minutes
2023-09-05 17:25:21,648:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:21,648:INFO:Initializing create_model()
2023-09-05 17:25:21,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=dt, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:21,648:INFO:Checking exceptions
2023-09-05 17:25:21,648:INFO:Importing libraries
2023-09-05 17:25:21,648:INFO:Copying training dataset
2023-09-05 17:25:21,651:INFO:Defining folds
2023-09-05 17:25:21,651:INFO:Declaring metric variables
2023-09-05 17:25:21,653:INFO:Importing untrained model
2023-09-05 17:25:21,656:INFO:Decision Tree Classifier Imported successfully
2023-09-05 17:25:21,660:INFO:Starting cross validation
2023-09-05 17:25:21,660:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:23,431:INFO:Calculating mean and std
2023-09-05 17:25:23,432:INFO:Creating metrics dataframe
2023-09-05 17:25:23,463:INFO:Uploading results into container
2023-09-05 17:25:23,463:INFO:Uploading model into container now
2023-09-05 17:25:23,464:INFO:_master_model_container: 4
2023-09-05 17:25:23,464:INFO:_display_container: 2
2023-09-05 17:25:23,464:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1212, splitter='best')
2023-09-05 17:25:23,464:INFO:create_model() successfully completed......................................
2023-09-05 17:25:23,531:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:23,531:INFO:Creating metrics dataframe
2023-09-05 17:25:23,537:INFO:Initializing SVM - Linear Kernel
2023-09-05 17:25:23,537:INFO:Total runtime is 0.1365934650103251 minutes
2023-09-05 17:25:23,539:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:23,540:INFO:Initializing create_model()
2023-09-05 17:25:23,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=svm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:23,540:INFO:Checking exceptions
2023-09-05 17:25:23,540:INFO:Importing libraries
2023-09-05 17:25:23,540:INFO:Copying training dataset
2023-09-05 17:25:23,544:INFO:Defining folds
2023-09-05 17:25:23,544:INFO:Declaring metric variables
2023-09-05 17:25:23,548:INFO:Importing untrained model
2023-09-05 17:25:23,552:INFO:SVM - Linear Kernel Imported successfully
2023-09-05 17:25:23,557:INFO:Starting cross validation
2023-09-05 17:25:23,558:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:25,307:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 17:25:25,307:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 17:25:25,308:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-09-05 17:25:25,362:INFO:Calculating mean and std
2023-09-05 17:25:25,363:INFO:Creating metrics dataframe
2023-09-05 17:25:25,390:INFO:Uploading results into container
2023-09-05 17:25:25,390:INFO:Uploading model into container now
2023-09-05 17:25:25,391:INFO:_master_model_container: 5
2023-09-05 17:25:25,391:INFO:_display_container: 2
2023-09-05 17:25:25,391:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1212, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-09-05 17:25:25,391:INFO:create_model() successfully completed......................................
2023-09-05 17:25:25,457:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:25,457:INFO:Creating metrics dataframe
2023-09-05 17:25:25,467:INFO:Initializing Ridge Classifier
2023-09-05 17:25:25,467:INFO:Total runtime is 0.16876017252604164 minutes
2023-09-05 17:25:25,469:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:25,469:INFO:Initializing create_model()
2023-09-05 17:25:25,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=ridge, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:25,469:INFO:Checking exceptions
2023-09-05 17:25:25,470:INFO:Importing libraries
2023-09-05 17:25:25,470:INFO:Copying training dataset
2023-09-05 17:25:25,472:INFO:Defining folds
2023-09-05 17:25:25,472:INFO:Declaring metric variables
2023-09-05 17:25:25,479:INFO:Importing untrained model
2023-09-05 17:25:25,485:INFO:Ridge Classifier Imported successfully
2023-09-05 17:25:25,494:INFO:Starting cross validation
2023-09-05 17:25:25,496:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:25,543:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:25:25,551:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:25:27,067:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-09-05 17:25:27,082:INFO:Calculating mean and std
2023-09-05 17:25:27,083:INFO:Creating metrics dataframe
2023-09-05 17:25:27,110:INFO:Uploading results into container
2023-09-05 17:25:27,111:INFO:Uploading model into container now
2023-09-05 17:25:27,111:INFO:_master_model_container: 6
2023-09-05 17:25:27,111:INFO:_display_container: 2
2023-09-05 17:25:27,112:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1212, solver='auto',
                tol=0.0001)
2023-09-05 17:25:27,112:INFO:create_model() successfully completed......................................
2023-09-05 17:25:27,194:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:27,194:INFO:Creating metrics dataframe
2023-09-05 17:25:27,202:INFO:Initializing Random Forest Classifier
2023-09-05 17:25:27,202:INFO:Total runtime is 0.1976849277814229 minutes
2023-09-05 17:25:27,204:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:27,204:INFO:Initializing create_model()
2023-09-05 17:25:27,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=rf, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:27,204:INFO:Checking exceptions
2023-09-05 17:25:27,204:INFO:Importing libraries
2023-09-05 17:25:27,204:INFO:Copying training dataset
2023-09-05 17:25:27,207:INFO:Defining folds
2023-09-05 17:25:27,207:INFO:Declaring metric variables
2023-09-05 17:25:27,210:INFO:Importing untrained model
2023-09-05 17:25:27,212:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:27,217:INFO:Starting cross validation
2023-09-05 17:25:27,217:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:27,443:INFO:Calculating mean and std
2023-09-05 17:25:27,444:INFO:Creating metrics dataframe
2023-09-05 17:25:27,468:INFO:Uploading results into container
2023-09-05 17:25:27,468:INFO:Uploading model into container now
2023-09-05 17:25:27,468:INFO:_master_model_container: 7
2023-09-05 17:25:27,468:INFO:_display_container: 2
2023-09-05 17:25:27,469:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:27,469:INFO:create_model() successfully completed......................................
2023-09-05 17:25:27,543:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:27,543:INFO:Creating metrics dataframe
2023-09-05 17:25:27,550:INFO:Initializing Quadratic Discriminant Analysis
2023-09-05 17:25:27,551:INFO:Total runtime is 0.2035037040710449 minutes
2023-09-05 17:25:27,553:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:27,554:INFO:Initializing create_model()
2023-09-05 17:25:27,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=qda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:27,554:INFO:Checking exceptions
2023-09-05 17:25:27,554:INFO:Importing libraries
2023-09-05 17:25:27,554:INFO:Copying training dataset
2023-09-05 17:25:27,558:INFO:Defining folds
2023-09-05 17:25:27,558:INFO:Declaring metric variables
2023-09-05 17:25:27,561:INFO:Importing untrained model
2023-09-05 17:25:27,564:INFO:Quadratic Discriminant Analysis Imported successfully
2023-09-05 17:25:27,568:INFO:Starting cross validation
2023-09-05 17:25:27,569:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:27,664:INFO:Calculating mean and std
2023-09-05 17:25:27,665:INFO:Creating metrics dataframe
2023-09-05 17:25:27,690:INFO:Uploading results into container
2023-09-05 17:25:27,691:INFO:Uploading model into container now
2023-09-05 17:25:27,691:INFO:_master_model_container: 8
2023-09-05 17:25:27,691:INFO:_display_container: 2
2023-09-05 17:25:27,691:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-09-05 17:25:27,691:INFO:create_model() successfully completed......................................
2023-09-05 17:25:27,765:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:27,765:INFO:Creating metrics dataframe
2023-09-05 17:25:27,772:INFO:Initializing Ada Boost Classifier
2023-09-05 17:25:27,772:INFO:Total runtime is 0.2071801662445068 minutes
2023-09-05 17:25:27,774:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:27,775:INFO:Initializing create_model()
2023-09-05 17:25:27,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=ada, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:27,775:INFO:Checking exceptions
2023-09-05 17:25:27,775:INFO:Importing libraries
2023-09-05 17:25:27,775:INFO:Copying training dataset
2023-09-05 17:25:27,779:INFO:Defining folds
2023-09-05 17:25:27,780:INFO:Declaring metric variables
2023-09-05 17:25:27,782:INFO:Importing untrained model
2023-09-05 17:25:27,785:INFO:Ada Boost Classifier Imported successfully
2023-09-05 17:25:27,789:INFO:Starting cross validation
2023-09-05 17:25:27,789:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:27,964:INFO:Calculating mean and std
2023-09-05 17:25:27,965:INFO:Creating metrics dataframe
2023-09-05 17:25:27,987:INFO:Uploading results into container
2023-09-05 17:25:27,987:INFO:Uploading model into container now
2023-09-05 17:25:27,987:INFO:_master_model_container: 9
2023-09-05 17:25:27,987:INFO:_display_container: 2
2023-09-05 17:25:27,988:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=1212)
2023-09-05 17:25:27,988:INFO:create_model() successfully completed......................................
2023-09-05 17:25:28,067:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:28,067:INFO:Creating metrics dataframe
2023-09-05 17:25:28,075:INFO:Initializing Gradient Boosting Classifier
2023-09-05 17:25:28,075:INFO:Total runtime is 0.21223269701004024 minutes
2023-09-05 17:25:28,079:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:28,079:INFO:Initializing create_model()
2023-09-05 17:25:28,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=gbc, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:28,079:INFO:Checking exceptions
2023-09-05 17:25:28,079:INFO:Importing libraries
2023-09-05 17:25:28,080:INFO:Copying training dataset
2023-09-05 17:25:28,089:INFO:Defining folds
2023-09-05 17:25:28,089:INFO:Declaring metric variables
2023-09-05 17:25:28,093:INFO:Importing untrained model
2023-09-05 17:25:28,097:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 17:25:28,104:INFO:Starting cross validation
2023-09-05 17:25:28,105:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:28,390:INFO:Calculating mean and std
2023-09-05 17:25:28,391:INFO:Creating metrics dataframe
2023-09-05 17:25:28,413:INFO:Uploading results into container
2023-09-05 17:25:28,414:INFO:Uploading model into container now
2023-09-05 17:25:28,414:INFO:_master_model_container: 10
2023-09-05 17:25:28,414:INFO:_display_container: 2
2023-09-05 17:25:28,414:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 17:25:28,414:INFO:create_model() successfully completed......................................
2023-09-05 17:25:28,485:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:28,485:INFO:Creating metrics dataframe
2023-09-05 17:25:28,493:INFO:Initializing Linear Discriminant Analysis
2023-09-05 17:25:28,493:INFO:Total runtime is 0.21919200023015337 minutes
2023-09-05 17:25:28,495:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:28,495:INFO:Initializing create_model()
2023-09-05 17:25:28,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=lda, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:28,495:INFO:Checking exceptions
2023-09-05 17:25:28,495:INFO:Importing libraries
2023-09-05 17:25:28,495:INFO:Copying training dataset
2023-09-05 17:25:28,498:INFO:Defining folds
2023-09-05 17:25:28,498:INFO:Declaring metric variables
2023-09-05 17:25:28,503:INFO:Importing untrained model
2023-09-05 17:25:28,509:INFO:Linear Discriminant Analysis Imported successfully
2023-09-05 17:25:28,514:INFO:Starting cross validation
2023-09-05 17:25:28,515:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:28,610:INFO:Calculating mean and std
2023-09-05 17:25:28,611:INFO:Creating metrics dataframe
2023-09-05 17:25:28,638:INFO:Uploading results into container
2023-09-05 17:25:28,638:INFO:Uploading model into container now
2023-09-05 17:25:28,639:INFO:_master_model_container: 11
2023-09-05 17:25:28,639:INFO:_display_container: 2
2023-09-05 17:25:28,639:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-09-05 17:25:28,639:INFO:create_model() successfully completed......................................
2023-09-05 17:25:28,710:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:28,710:INFO:Creating metrics dataframe
2023-09-05 17:25:28,718:INFO:Initializing Extra Trees Classifier
2023-09-05 17:25:28,718:INFO:Total runtime is 0.22294866243998207 minutes
2023-09-05 17:25:28,721:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:28,721:INFO:Initializing create_model()
2023-09-05 17:25:28,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=et, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:28,721:INFO:Checking exceptions
2023-09-05 17:25:28,721:INFO:Importing libraries
2023-09-05 17:25:28,721:INFO:Copying training dataset
2023-09-05 17:25:28,728:INFO:Defining folds
2023-09-05 17:25:28,728:INFO:Declaring metric variables
2023-09-05 17:25:28,731:INFO:Importing untrained model
2023-09-05 17:25:28,734:INFO:Extra Trees Classifier Imported successfully
2023-09-05 17:25:28,740:INFO:Starting cross validation
2023-09-05 17:25:28,742:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:29,021:INFO:Calculating mean and std
2023-09-05 17:25:29,022:INFO:Creating metrics dataframe
2023-09-05 17:25:29,051:INFO:Uploading results into container
2023-09-05 17:25:29,051:INFO:Uploading model into container now
2023-09-05 17:25:29,052:INFO:_master_model_container: 12
2023-09-05 17:25:29,052:INFO:_display_container: 2
2023-09-05 17:25:29,052:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:29,052:INFO:create_model() successfully completed......................................
2023-09-05 17:25:29,126:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:29,126:INFO:Creating metrics dataframe
2023-09-05 17:25:29,134:INFO:Initializing Extreme Gradient Boosting
2023-09-05 17:25:29,134:INFO:Total runtime is 0.22988147338231402 minutes
2023-09-05 17:25:29,137:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:29,138:INFO:Initializing create_model()
2023-09-05 17:25:29,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=xgboost, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:29,138:INFO:Checking exceptions
2023-09-05 17:25:29,138:INFO:Importing libraries
2023-09-05 17:25:29,138:INFO:Copying training dataset
2023-09-05 17:25:29,142:INFO:Defining folds
2023-09-05 17:25:29,142:INFO:Declaring metric variables
2023-09-05 17:25:29,145:INFO:Importing untrained model
2023-09-05 17:25:29,148:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:25:29,153:INFO:Starting cross validation
2023-09-05 17:25:29,153:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:29,305:INFO:Calculating mean and std
2023-09-05 17:25:29,306:INFO:Creating metrics dataframe
2023-09-05 17:25:29,332:INFO:Uploading results into container
2023-09-05 17:25:29,332:INFO:Uploading model into container now
2023-09-05 17:25:29,332:INFO:_master_model_container: 13
2023-09-05 17:25:29,332:INFO:_display_container: 2
2023-09-05 17:25:29,333:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 17:25:29,333:INFO:create_model() successfully completed......................................
2023-09-05 17:25:29,406:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:29,406:INFO:Creating metrics dataframe
2023-09-05 17:25:29,414:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 17:25:29,414:INFO:Total runtime is 0.2345494190851847 minutes
2023-09-05 17:25:29,416:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:29,416:INFO:Initializing create_model()
2023-09-05 17:25:29,416:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:29,416:INFO:Checking exceptions
2023-09-05 17:25:29,416:INFO:Importing libraries
2023-09-05 17:25:29,416:INFO:Copying training dataset
2023-09-05 17:25:29,419:INFO:Defining folds
2023-09-05 17:25:29,419:INFO:Declaring metric variables
2023-09-05 17:25:29,421:INFO:Importing untrained model
2023-09-05 17:25:29,427:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:25:29,433:INFO:Starting cross validation
2023-09-05 17:25:29,433:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:29,570:INFO:Calculating mean and std
2023-09-05 17:25:29,571:INFO:Creating metrics dataframe
2023-09-05 17:25:29,603:INFO:Uploading results into container
2023-09-05 17:25:29,604:INFO:Uploading model into container now
2023-09-05 17:25:29,605:INFO:_master_model_container: 14
2023-09-05 17:25:29,605:INFO:_display_container: 2
2023-09-05 17:25:29,605:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 17:25:29,605:INFO:create_model() successfully completed......................................
2023-09-05 17:25:29,681:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:29,681:INFO:Creating metrics dataframe
2023-09-05 17:25:29,689:INFO:Initializing Dummy Classifier
2023-09-05 17:25:29,689:INFO:Total runtime is 0.23913471301396685 minutes
2023-09-05 17:25:29,691:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:29,691:INFO:Initializing create_model()
2023-09-05 17:25:29,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=dummy, fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138F926D0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:29,691:INFO:Checking exceptions
2023-09-05 17:25:29,691:INFO:Importing libraries
2023-09-05 17:25:29,691:INFO:Copying training dataset
2023-09-05 17:25:29,694:INFO:Defining folds
2023-09-05 17:25:29,695:INFO:Declaring metric variables
2023-09-05 17:25:29,697:INFO:Importing untrained model
2023-09-05 17:25:29,699:INFO:Dummy Classifier Imported successfully
2023-09-05 17:25:29,704:INFO:Starting cross validation
2023-09-05 17:25:29,704:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:29,742:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:25:29,744:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:25:29,747:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-09-05 17:25:29,791:INFO:Calculating mean and std
2023-09-05 17:25:29,791:INFO:Creating metrics dataframe
2023-09-05 17:25:29,819:INFO:Uploading results into container
2023-09-05 17:25:29,819:INFO:Uploading model into container now
2023-09-05 17:25:29,819:INFO:_master_model_container: 15
2023-09-05 17:25:29,820:INFO:_display_container: 2
2023-09-05 17:25:29,820:INFO:DummyClassifier(constant=None, random_state=1212, strategy='prior')
2023-09-05 17:25:29,820:INFO:create_model() successfully completed......................................
2023-09-05 17:25:29,886:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:29,886:INFO:Creating metrics dataframe
2023-09-05 17:25:29,902:INFO:Initializing create_model()
2023-09-05 17:25:29,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:29,902:INFO:Checking exceptions
2023-09-05 17:25:29,903:INFO:Importing libraries
2023-09-05 17:25:29,903:INFO:Copying training dataset
2023-09-05 17:25:29,906:INFO:Defining folds
2023-09-05 17:25:29,906:INFO:Declaring metric variables
2023-09-05 17:25:29,906:INFO:Importing untrained model
2023-09-05 17:25:29,906:INFO:Declaring custom model
2023-09-05 17:25:29,907:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:25:29,907:INFO:Cross validation set to False
2023-09-05 17:25:29,907:INFO:Fitting Model
2023-09-05 17:25:29,921:INFO:[LightGBM] [Info] Number of positive: 273, number of negative: 439
2023-09-05 17:25:29,921:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.
2023-09-05 17:25:29,921:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-09-05 17:25:29,921:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-09-05 17:25:29,921:INFO:[LightGBM] [Info] Total Bins 274
2023-09-05 17:25:29,922:INFO:[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 9
2023-09-05 17:25:29,922:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383427 -> initscore=-0.475028
2023-09-05 17:25:29,922:INFO:[LightGBM] [Info] Start training from score -0.475028
2023-09-05 17:25:29,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-09-05 17:25:29,979:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-09-05 17:25:29,980:INFO:create_model() successfully completed......................................
2023-09-05 17:25:30,073:INFO:Initializing create_model()
2023-09-05 17:25:30,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:30,073:INFO:Checking exceptions
2023-09-05 17:25:30,074:INFO:Importing libraries
2023-09-05 17:25:30,074:INFO:Copying training dataset
2023-09-05 17:25:30,077:INFO:Defining folds
2023-09-05 17:25:30,077:INFO:Declaring metric variables
2023-09-05 17:25:30,077:INFO:Importing untrained model
2023-09-05 17:25:30,077:INFO:Declaring custom model
2023-09-05 17:25:30,077:INFO:Gradient Boosting Classifier Imported successfully
2023-09-05 17:25:30,078:INFO:Cross validation set to False
2023-09-05 17:25:30,078:INFO:Fitting Model
2023-09-05 17:25:30,182:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-09-05 17:25:30,182:INFO:create_model() successfully completed......................................
2023-09-05 17:25:30,263:INFO:Initializing create_model()
2023-09-05 17:25:30,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:30,264:INFO:Checking exceptions
2023-09-05 17:25:30,265:INFO:Importing libraries
2023-09-05 17:25:30,265:INFO:Copying training dataset
2023-09-05 17:25:30,268:INFO:Defining folds
2023-09-05 17:25:30,268:INFO:Declaring metric variables
2023-09-05 17:25:30,268:INFO:Importing untrained model
2023-09-05 17:25:30,268:INFO:Declaring custom model
2023-09-05 17:25:30,270:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:25:30,271:INFO:Cross validation set to False
2023-09-05 17:25:30,271:INFO:Fitting Model
2023-09-05 17:25:30,348:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-09-05 17:25:30,348:INFO:create_model() successfully completed......................................
2023-09-05 17:25:30,448:INFO:Initializing create_model()
2023-09-05 17:25:30,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:30,448:INFO:Checking exceptions
2023-09-05 17:25:30,449:INFO:Importing libraries
2023-09-05 17:25:30,449:INFO:Copying training dataset
2023-09-05 17:25:30,451:INFO:Defining folds
2023-09-05 17:25:30,451:INFO:Declaring metric variables
2023-09-05 17:25:30,451:INFO:Importing untrained model
2023-09-05 17:25:30,451:INFO:Declaring custom model
2023-09-05 17:25:30,452:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:30,452:INFO:Cross validation set to False
2023-09-05 17:25:30,452:INFO:Fitting Model
2023-09-05 17:25:30,675:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:30,675:INFO:create_model() successfully completed......................................
2023-09-05 17:25:30,772:INFO:_master_model_container: 15
2023-09-05 17:25:30,772:INFO:_display_container: 2
2023-09-05 17:25:30,773:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1212, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1212, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)]
2023-09-05 17:25:30,773:INFO:compare_models() successfully completed......................................
2023-09-05 17:25:30,806:INFO:Initializing create_model()
2023-09-05 17:25:30,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'n_estimators': 300, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2})
2023-09-05 17:25:30,806:INFO:Checking exceptions
2023-09-05 17:25:30,816:INFO:Importing libraries
2023-09-05 17:25:30,816:INFO:Copying training dataset
2023-09-05 17:25:30,819:INFO:Defining folds
2023-09-05 17:25:30,819:INFO:Declaring metric variables
2023-09-05 17:25:30,824:INFO:Importing untrained model
2023-09-05 17:25:30,830:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:30,840:INFO:Starting cross validation
2023-09-05 17:25:30,841:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:31,787:INFO:Calculating mean and std
2023-09-05 17:25:31,787:INFO:Creating metrics dataframe
2023-09-05 17:25:31,792:INFO:Finalizing model
2023-09-05 17:25:32,317:INFO:Uploading results into container
2023-09-05 17:25:32,318:INFO:Uploading model into container now
2023-09-05 17:25:32,323:INFO:_master_model_container: 16
2023-09-05 17:25:32,324:INFO:_display_container: 3
2023-09-05 17:25:32,324:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:32,324:INFO:create_model() successfully completed......................................
2023-09-05 17:25:32,407:INFO:Initializing tune_model()
2023-09-05 17:25:32,407:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid={'n_estimators': [100, 300], 'max_depth': [10, 20], 'min_samples_split': [1, 2], 'min_samples_leaf': [1, 2]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>)
2023-09-05 17:25:32,407:INFO:Checking exceptions
2023-09-05 17:25:32,420:INFO:Copying training dataset
2023-09-05 17:25:32,422:INFO:Checking base model
2023-09-05 17:25:32,422:INFO:Base model : Random Forest Classifier
2023-09-05 17:25:32,426:INFO:Declaring metric variables
2023-09-05 17:25:32,431:INFO:Defining Hyperparameters
2023-09-05 17:25:32,511:INFO:custom_grid: {'actual_estimator__n_estimators': [100, 300], 'actual_estimator__max_depth': [10, 20], 'actual_estimator__min_samples_split': [1, 2], 'actual_estimator__min_samples_leaf': [1, 2]}
2023-09-05 17:25:32,511:INFO:Tuning with n_jobs=-1
2023-09-05 17:25:32,511:INFO:Initializing RandomizedSearchCV
2023-09-05 17:25:33,872:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 10}
2023-09-05 17:25:33,873:INFO:Hyperparameter search completed
2023-09-05 17:25:33,873:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:33,873:INFO:Initializing create_model()
2023-09-05 17:25:33,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020138FB0850>, model_only=True, return_train_score=False, kwargs={'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10})
2023-09-05 17:25:33,874:INFO:Checking exceptions
2023-09-05 17:25:33,874:INFO:Importing libraries
2023-09-05 17:25:33,874:INFO:Copying training dataset
2023-09-05 17:25:33,876:INFO:Defining folds
2023-09-05 17:25:33,876:INFO:Declaring metric variables
2023-09-05 17:25:33,879:INFO:Importing untrained model
2023-09-05 17:25:33,879:INFO:Declaring custom model
2023-09-05 17:25:33,881:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:33,885:INFO:Starting cross validation
2023-09-05 17:25:33,886:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:34,110:INFO:Calculating mean and std
2023-09-05 17:25:34,111:INFO:Creating metrics dataframe
2023-09-05 17:25:34,116:INFO:Finalizing model
2023-09-05 17:25:34,355:INFO:Uploading results into container
2023-09-05 17:25:34,356:INFO:Uploading model into container now
2023-09-05 17:25:34,356:INFO:_master_model_container: 17
2023-09-05 17:25:34,356:INFO:_display_container: 4
2023-09-05 17:25:34,356:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:34,356:INFO:create_model() successfully completed......................................
2023-09-05 17:25:34,426:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:34,426:INFO:choose_better activated
2023-09-05 17:25:34,429:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:34,429:INFO:Initializing create_model()
2023-09-05 17:25:34,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:34,429:INFO:Checking exceptions
2023-09-05 17:25:34,430:INFO:Importing libraries
2023-09-05 17:25:34,430:INFO:Copying training dataset
2023-09-05 17:25:34,432:INFO:Defining folds
2023-09-05 17:25:34,432:INFO:Declaring metric variables
2023-09-05 17:25:34,432:INFO:Importing untrained model
2023-09-05 17:25:34,432:INFO:Declaring custom model
2023-09-05 17:25:34,433:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:34,433:INFO:Starting cross validation
2023-09-05 17:25:34,434:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:34,863:INFO:Calculating mean and std
2023-09-05 17:25:34,863:INFO:Creating metrics dataframe
2023-09-05 17:25:34,865:INFO:Finalizing model
2023-09-05 17:25:34,970:INFO:Uploading results into container
2023-09-05 17:25:34,970:INFO:Uploading model into container now
2023-09-05 17:25:34,971:INFO:_master_model_container: 18
2023-09-05 17:25:34,971:INFO:_display_container: 5
2023-09-05 17:25:34,971:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:34,971:INFO:create_model() successfully completed......................................
2023-09-05 17:25:35,049:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:35,050:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 17:25:35,050:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8146
2023-09-05 17:25:35,051:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 17:25:35,051:INFO:choose_better completed
2023-09-05 17:25:35,051:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 17:25:35,057:INFO:_master_model_container: 18
2023-09-05 17:25:35,057:INFO:_display_container: 4
2023-09-05 17:25:35,057:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:35,057:INFO:tune_model() successfully completed......................................
2023-09-05 17:25:35,181:INFO:Initializing tune_model()
2023-09-05 17:25:35,181:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-optimize, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>)
2023-09-05 17:25:35,181:INFO:Checking exceptions
2023-09-05 17:25:35,181:INFO:Soft dependency imported: skopt: 0.9.0
2023-09-05 17:25:35,207:INFO:Copying training dataset
2023-09-05 17:25:35,208:INFO:Checking base model
2023-09-05 17:25:35,209:INFO:Base model : Random Forest Classifier
2023-09-05 17:25:35,212:INFO:Declaring metric variables
2023-09-05 17:25:35,214:INFO:Defining Hyperparameters
2023-09-05 17:25:35,282:INFO:Tuning with n_jobs=-1
2023-09-05 17:25:35,286:INFO:Initializing skopt.BayesSearchCV
2023-09-05 17:25:41,015:INFO:best_params: OrderedDict([('actual_estimator__bootstrap', False), ('actual_estimator__class_weight', 'balanced'), ('actual_estimator__criterion', 'entropy'), ('actual_estimator__max_depth', 9), ('actual_estimator__max_features', 0.6572967088396628), ('actual_estimator__min_impurity_decrease', 0.0001578347418897214), ('actual_estimator__min_samples_leaf', 3), ('actual_estimator__min_samples_split', 5), ('actual_estimator__n_estimators', 67)])
2023-09-05 17:25:41,016:INFO:Hyperparameter search completed
2023-09-05 17:25:41,016:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:41,016:INFO:Initializing create_model()
2023-09-05 17:25:41,016:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020136DA3D90>, model_only=True, return_train_score=False, kwargs={'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 0.6572967088396628, 'min_impurity_decrease': 0.0001578347418897214, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 67})
2023-09-05 17:25:41,016:INFO:Checking exceptions
2023-09-05 17:25:41,016:INFO:Importing libraries
2023-09-05 17:25:41,016:INFO:Copying training dataset
2023-09-05 17:25:41,018:INFO:Defining folds
2023-09-05 17:25:41,019:INFO:Declaring metric variables
2023-09-05 17:25:41,021:INFO:Importing untrained model
2023-09-05 17:25:41,021:INFO:Declaring custom model
2023-09-05 17:25:41,024:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:41,032:INFO:Starting cross validation
2023-09-05 17:25:41,033:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:41,325:INFO:Calculating mean and std
2023-09-05 17:25:41,326:INFO:Creating metrics dataframe
2023-09-05 17:25:41,330:INFO:Finalizing model
2023-09-05 17:25:41,457:INFO:Uploading results into container
2023-09-05 17:25:41,457:INFO:Uploading model into container now
2023-09-05 17:25:41,458:INFO:_master_model_container: 19
2023-09-05 17:25:41,458:INFO:_display_container: 5
2023-09-05 17:25:41,459:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False)
2023-09-05 17:25:41,459:INFO:create_model() successfully completed......................................
2023-09-05 17:25:41,536:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:41,536:INFO:choose_better activated
2023-09-05 17:25:41,539:INFO:SubProcess create_model() called ==================================
2023-09-05 17:25:41,539:INFO:Initializing create_model()
2023-09-05 17:25:41,539:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002013367DFA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:25:41,539:INFO:Checking exceptions
2023-09-05 17:25:41,540:INFO:Importing libraries
2023-09-05 17:25:41,540:INFO:Copying training dataset
2023-09-05 17:25:41,542:INFO:Defining folds
2023-09-05 17:25:41,542:INFO:Declaring metric variables
2023-09-05 17:25:41,542:INFO:Importing untrained model
2023-09-05 17:25:41,543:INFO:Declaring custom model
2023-09-05 17:25:41,543:INFO:Random Forest Classifier Imported successfully
2023-09-05 17:25:41,543:INFO:Starting cross validation
2023-09-05 17:25:41,544:INFO:Cross validating with StratifiedKFold(n_splits=3, random_state=1212, shuffle=True), n_jobs=-1
2023-09-05 17:25:41,998:INFO:Calculating mean and std
2023-09-05 17:25:41,998:INFO:Creating metrics dataframe
2023-09-05 17:25:42,000:INFO:Finalizing model
2023-09-05 17:25:42,102:INFO:Uploading results into container
2023-09-05 17:25:42,103:INFO:Uploading model into container now
2023-09-05 17:25:42,103:INFO:_master_model_container: 20
2023-09-05 17:25:42,103:INFO:_display_container: 6
2023-09-05 17:25:42,104:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:42,104:INFO:create_model() successfully completed......................................
2023-09-05 17:25:42,174:INFO:SubProcess create_model() end ==================================
2023-09-05 17:25:42,174:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) result for Accuracy is 0.8258
2023-09-05 17:25:42,175:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                       criterion='entropy', max_depth=9,
                       max_features=0.6572967088396628, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=0.0001578347418897214,
                       min_samples_leaf=3, min_samples_split=5,
                       min_weight_fraction_leaf=0.0, n_estimators=67, n_jobs=-1,
                       oob_score=False, random_state=1212, verbose=0,
                       warm_start=False) result for Accuracy is 0.8244
2023-09-05 17:25:42,175:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False) is best model
2023-09-05 17:25:42,175:INFO:choose_better completed
2023-09-05 17:25:42,175:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-09-05 17:25:42,181:INFO:_master_model_container: 20
2023-09-05 17:25:42,181:INFO:_display_container: 5
2023-09-05 17:25:42,181:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=10, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=-1, oob_score=False,
                       random_state=1212, verbose=0, warm_start=False)
2023-09-05 17:25:42,181:INFO:tune_model() successfully completed......................................
2023-09-05 17:26:25,655:INFO:PyCaret RegressionExperiment
2023-09-05 17:26:25,655:INFO:Logging name: reg-default-name
2023-09-05 17:26:25,655:INFO:ML Usecase: MLUsecase.REGRESSION
2023-09-05 17:26:25,655:INFO:version 3.0.4
2023-09-05 17:26:25,655:INFO:Initializing setup()
2023-09-05 17:26:25,656:INFO:self.USI: c3da
2023-09-05 17:26:25,656:INFO:self._variable_keys: {'fold_groups_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'exp_id', 'n_jobs_param', 'pipeline', 'fold_generator', 'logging_param', 'fold_shuffle_param', '_ml_usecase', 'memory', 'seed', 'data', 'exp_name_log', 'y_test', 'log_plots_param', 'y', 'gpu_param', 'target_param', 'X_test', '_available_plots', 'html_param', 'idx', 'X', 'transform_target_param', 'X_train'}
2023-09-05 17:26:25,656:INFO:Checking environment
2023-09-05 17:26:25,656:INFO:python_version: 3.8.8
2023-09-05 17:26:25,656:INFO:python_build: ('tags/v3.8.8:024d805', 'Feb 19 2021 13:18:16')
2023-09-05 17:26:25,656:INFO:machine: AMD64
2023-09-05 17:26:25,656:INFO:platform: Windows-10-10.0.19041-SP0
2023-09-05 17:26:25,662:INFO:Memory: svmem(total=16822788096, available=4419256320, percent=73.7, used=12403531776, free=4419256320)
2023-09-05 17:26:25,662:INFO:Physical Core: 8
2023-09-05 17:26:25,662:INFO:Logical Core: 16
2023-09-05 17:26:25,662:INFO:Checking libraries
2023-09-05 17:26:25,662:INFO:System:
2023-09-05 17:26:25,662:INFO:    python: 3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]
2023-09-05 17:26:25,662:INFO:executable: C:\AI\pythonProject\venv\Scripts\python.exe
2023-09-05 17:26:25,662:INFO:   machine: Windows-10-10.0.19041-SP0
2023-09-05 17:26:25,662:INFO:PyCaret required dependencies:
2023-09-05 17:26:25,708:INFO:                 pip: 22.3.1
2023-09-05 17:26:25,708:INFO:          setuptools: 65.5.1
2023-09-05 17:26:25,708:INFO:             pycaret: 3.0.4
2023-09-05 17:26:25,708:INFO:             IPython: 8.12.2
2023-09-05 17:26:25,708:INFO:          ipywidgets: 8.0.7
2023-09-05 17:26:25,708:INFO:                tqdm: 4.66.1
2023-09-05 17:26:25,708:INFO:               numpy: 1.23.5
2023-09-05 17:26:25,708:INFO:              pandas: 1.5.3
2023-09-05 17:26:25,708:INFO:              jinja2: 3.1.2
2023-09-05 17:26:25,708:INFO:               scipy: 1.10.1
2023-09-05 17:26:25,708:INFO:              joblib: 1.3.2
2023-09-05 17:26:25,708:INFO:             sklearn: 1.2.2
2023-09-05 17:26:25,708:INFO:                pyod: 1.1.0
2023-09-05 17:26:25,708:INFO:            imblearn: 0.11.0
2023-09-05 17:26:25,708:INFO:   category_encoders: 2.6.2
2023-09-05 17:26:25,708:INFO:            lightgbm: 4.0.0
2023-09-05 17:26:25,708:INFO:               numba: 0.57.1
2023-09-05 17:26:25,708:INFO:            requests: 2.31.0
2023-09-05 17:26:25,708:INFO:          matplotlib: 3.7.2
2023-09-05 17:26:25,708:INFO:          scikitplot: 0.3.7
2023-09-05 17:26:25,708:INFO:         yellowbrick: 1.5
2023-09-05 17:26:25,708:INFO:              plotly: 5.15.0
2023-09-05 17:26:25,708:INFO:    plotly-resampler: Not installed
2023-09-05 17:26:25,708:INFO:             kaleido: 0.2.1
2023-09-05 17:26:25,708:INFO:           schemdraw: 0.15
2023-09-05 17:26:25,708:INFO:         statsmodels: 0.14.0
2023-09-05 17:26:25,708:INFO:              sktime: 0.22.0
2023-09-05 17:26:25,708:INFO:               tbats: 1.1.3
2023-09-05 17:26:25,708:INFO:            pmdarima: 2.0.3
2023-09-05 17:26:25,708:INFO:              psutil: 5.9.5
2023-09-05 17:26:25,708:INFO:          markupsafe: 2.1.3
2023-09-05 17:26:25,708:INFO:             pickle5: Not installed
2023-09-05 17:26:25,708:INFO:         cloudpickle: 2.2.1
2023-09-05 17:26:25,708:INFO:         deprecation: 2.1.0
2023-09-05 17:26:25,708:INFO:              xxhash: 3.3.0
2023-09-05 17:26:25,708:INFO:           wurlitzer: Not installed
2023-09-05 17:26:25,708:INFO:PyCaret optional dependencies:
2023-09-05 17:26:26,939:INFO:                shap: Not installed
2023-09-05 17:26:26,939:INFO:           interpret: Not installed
2023-09-05 17:26:26,939:INFO:                umap: Not installed
2023-09-05 17:26:26,939:INFO:    pandas_profiling: Not installed
2023-09-05 17:26:26,939:INFO:  explainerdashboard: Not installed
2023-09-05 17:26:26,939:INFO:             autoviz: Not installed
2023-09-05 17:26:26,939:INFO:           fairlearn: Not installed
2023-09-05 17:26:26,939:INFO:          deepchecks: Not installed
2023-09-05 17:26:26,939:INFO:             xgboost: 1.7.6
2023-09-05 17:26:26,939:INFO:            catboost: 1.2.1
2023-09-05 17:26:26,939:INFO:              kmodes: Not installed
2023-09-05 17:26:26,940:INFO:             mlxtend: Not installed
2023-09-05 17:26:26,940:INFO:       statsforecast: Not installed
2023-09-05 17:26:26,940:INFO:        tune_sklearn: 0.4.6
2023-09-05 17:26:26,940:INFO:                 ray: 2.6.3
2023-09-05 17:26:26,940:INFO:            hyperopt: Not installed
2023-09-05 17:26:26,940:INFO:              optuna: 3.3.0
2023-09-05 17:26:26,940:INFO:               skopt: 0.9.0
2023-09-05 17:26:26,940:INFO:              mlflow: Not installed
2023-09-05 17:26:26,940:INFO:              gradio: 3.42.0
2023-09-05 17:26:26,940:INFO:             fastapi: 0.103.1
2023-09-05 17:26:26,940:INFO:             uvicorn: 0.23.2
2023-09-05 17:26:26,940:INFO:              m2cgen: Not installed
2023-09-05 17:26:26,940:INFO:           evidently: Not installed
2023-09-05 17:26:26,940:INFO:               fugue: Not installed
2023-09-05 17:26:26,940:INFO:           streamlit: Not installed
2023-09-05 17:26:26,940:INFO:             prophet: Not installed
2023-09-05 17:26:26,940:INFO:None
2023-09-05 17:26:26,940:INFO:Set up data.
2023-09-05 17:26:26,944:INFO:Set up train/test split.
2023-09-05 17:26:26,946:INFO:Set up index.
2023-09-05 17:26:26,947:INFO:Set up folding strategy.
2023-09-05 17:26:26,947:INFO:Assigning column types.
2023-09-05 17:26:26,949:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-09-05 17:26:26,949:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 17:26:26,953:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 17:26:26,956:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:26,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,023:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,023:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,041:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,060:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,063:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,067:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,133:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,135:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,135:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-09-05 17:26:27,138:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,176:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,207:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,208:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,211:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,215:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,250:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,278:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,279:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,281:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,281:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-09-05 17:26:27,287:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,352:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,352:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,354:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,360:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,426:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,427:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,428:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-09-05 17:26:27,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,499:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,499:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,501:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,545:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,575:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,577:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,577:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-09-05 17:26:27,621:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,652:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,654:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,699:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-09-05 17:26:27,730:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,732:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,732:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-09-05 17:26:27,805:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,807:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,879:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:27,881:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:27,883:INFO:Preparing preprocessing pipeline...
2023-09-05 17:26:27,883:INFO:Set up simple imputation.
2023-09-05 17:26:27,886:INFO:Set up encoding of ordinal features.
2023-09-05 17:26:27,888:INFO:Set up encoding of categorical features.
2023-09-05 17:26:27,935:INFO:Finished creating preprocessing pipeline.
2023-09-05 17:26:27,961:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\asiae\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['age', 'bmi', 'children'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['sex', 'smoker', 'region'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 TransformerW...
                                                                     'smoker'],
                                                               handle_missing='return_nan',
                                                               mapping=[{'col': 'sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64},
                                                                        {'col': 'smoker',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['region'],
                                    transformer=OneHotEncoder(cols=['region'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2023-09-05 17:26:27,961:INFO:Creating final display dataframe.
2023-09-05 17:26:28,082:INFO:Setup _display_container:                     Description             Value
0                    Session id              3494
1                        Target           charges
2                   Target type        Regression
3           Original data shape         (1338, 7)
4        Transformed data shape        (1338, 10)
5   Transformed train set shape         (936, 10)
6    Transformed test set shape         (402, 10)
7              Ordinal features                 2
8              Numeric features                 3
9          Categorical features                 3
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              c3da
2023-09-05 17:26:28,087:ERROR:Data Failed with exception:
 No module named 'pandas_profiling'
No output to show, continue with modeling.
2023-09-05 17:26:28,163:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,164:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,239:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,241:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,241:INFO:setup() successfully completed in 2.62s...............
2023-09-05 17:26:28,247:INFO:gpu_param set to False
2023-09-05 17:26:28,327:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,329:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,403:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,405:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,420:INFO:gpu_param set to False
2023-09-05 17:26:28,502:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,504:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,579:INFO:Soft dependency imported: xgboost: 1.7.6
2023-09-05 17:26:28,581:INFO:Soft dependency imported: catboost: 1.2.1
2023-09-05 17:26:28,636:INFO:Initializing compare_models()
2023-09-05 17:26:28,636:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, include=['lr', 'rf'], fold=None, round=4, cross_validation=True, sort=MAE, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, 'include': ['lr', 'rf'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 17:26:28,636:INFO:Checking exceptions
2023-09-05 17:26:28,638:INFO:Preparing display monitor
2023-09-05 17:26:28,658:INFO:Initializing Linear Regression
2023-09-05 17:26:28,658:INFO:Total runtime is 0.0 minutes
2023-09-05 17:26:28,663:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:28,663:INFO:Initializing create_model()
2023-09-05 17:26:28,663:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD77AA7880>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:28,663:INFO:Checking exceptions
2023-09-05 17:26:28,664:INFO:Importing libraries
2023-09-05 17:26:28,664:INFO:Copying training dataset
2023-09-05 17:26:28,668:INFO:Defining folds
2023-09-05 17:26:28,668:INFO:Declaring metric variables
2023-09-05 17:26:28,670:INFO:Importing untrained model
2023-09-05 17:26:28,674:INFO:Linear Regression Imported successfully
2023-09-05 17:26:28,679:INFO:Starting cross validation
2023-09-05 17:26:28,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:32,389:INFO:Calculating mean and std
2023-09-05 17:26:32,390:INFO:Creating metrics dataframe
2023-09-05 17:26:32,430:INFO:Uploading results into container
2023-09-05 17:26:32,430:INFO:Uploading model into container now
2023-09-05 17:26:32,430:INFO:_master_model_container: 1
2023-09-05 17:26:32,430:INFO:_display_container: 2
2023-09-05 17:26:32,430:INFO:LinearRegression(n_jobs=-1)
2023-09-05 17:26:32,431:INFO:create_model() successfully completed......................................
2023-09-05 17:26:32,504:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:32,504:INFO:Creating metrics dataframe
2023-09-05 17:26:32,509:INFO:Initializing Random Forest Regressor
2023-09-05 17:26:32,509:INFO:Total runtime is 0.0641975998878479 minutes
2023-09-05 17:26:32,511:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:32,511:INFO:Initializing create_model()
2023-09-05 17:26:32,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD77AA7880>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:32,511:INFO:Checking exceptions
2023-09-05 17:26:32,511:INFO:Importing libraries
2023-09-05 17:26:32,511:INFO:Copying training dataset
2023-09-05 17:26:32,516:INFO:Defining folds
2023-09-05 17:26:32,517:INFO:Declaring metric variables
2023-09-05 17:26:32,519:INFO:Importing untrained model
2023-09-05 17:26:32,522:INFO:Random Forest Regressor Imported successfully
2023-09-05 17:26:32,526:INFO:Starting cross validation
2023-09-05 17:26:32,527:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:35,459:INFO:Calculating mean and std
2023-09-05 17:26:35,460:INFO:Creating metrics dataframe
2023-09-05 17:26:35,505:INFO:Uploading results into container
2023-09-05 17:26:35,506:INFO:Uploading model into container now
2023-09-05 17:26:35,506:INFO:_master_model_container: 2
2023-09-05 17:26:35,506:INFO:_display_container: 2
2023-09-05 17:26:35,506:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:35,506:INFO:create_model() successfully completed......................................
2023-09-05 17:26:35,578:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:35,578:INFO:Creating metrics dataframe
2023-09-05 17:26:35,590:INFO:Initializing create_model()
2023-09-05 17:26:35,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3494), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:35,590:INFO:Checking exceptions
2023-09-05 17:26:35,591:INFO:Importing libraries
2023-09-05 17:26:35,591:INFO:Copying training dataset
2023-09-05 17:26:35,593:INFO:Defining folds
2023-09-05 17:26:35,593:INFO:Declaring metric variables
2023-09-05 17:26:35,593:INFO:Importing untrained model
2023-09-05 17:26:35,593:INFO:Declaring custom model
2023-09-05 17:26:35,594:INFO:Random Forest Regressor Imported successfully
2023-09-05 17:26:35,594:INFO:Cross validation set to False
2023-09-05 17:26:35,594:INFO:Fitting Model
2023-09-05 17:26:35,853:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:35,853:INFO:create_model() successfully completed......................................
2023-09-05 17:26:35,932:INFO:_master_model_container: 2
2023-09-05 17:26:35,933:INFO:_display_container: 2
2023-09-05 17:26:35,933:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:35,933:INFO:compare_models() successfully completed......................................
2023-09-05 17:26:35,974:INFO:Initializing compare_models()
2023-09-05 17:26:35,974:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, include=None, fold=None, round=4, cross_validation=True, sort=MAE, n_select=2, budget_time=0.5, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'MAE', 'n_select': 2, 'budget_time': 0.5, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-09-05 17:26:35,974:INFO:Checking exceptions
2023-09-05 17:26:35,975:INFO:Preparing display monitor
2023-09-05 17:26:35,993:INFO:Time budget is 0.5 minutes
2023-09-05 17:26:35,993:INFO:Initializing Linear Regression
2023-09-05 17:26:35,993:INFO:Total runtime is 0.0 minutes
2023-09-05 17:26:35,995:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:35,995:INFO:Initializing create_model()
2023-09-05 17:26:35,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:35,995:INFO:Checking exceptions
2023-09-05 17:26:35,995:INFO:Importing libraries
2023-09-05 17:26:35,996:INFO:Copying training dataset
2023-09-05 17:26:36,000:INFO:Defining folds
2023-09-05 17:26:36,000:INFO:Declaring metric variables
2023-09-05 17:26:36,002:INFO:Importing untrained model
2023-09-05 17:26:36,004:INFO:Linear Regression Imported successfully
2023-09-05 17:26:36,008:INFO:Starting cross validation
2023-09-05 17:26:36,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:36,524:INFO:Calculating mean and std
2023-09-05 17:26:36,524:INFO:Creating metrics dataframe
2023-09-05 17:26:36,570:INFO:Uploading results into container
2023-09-05 17:26:36,571:INFO:Uploading model into container now
2023-09-05 17:26:36,571:INFO:_master_model_container: 3
2023-09-05 17:26:36,571:INFO:_display_container: 3
2023-09-05 17:26:36,571:INFO:LinearRegression(n_jobs=-1)
2023-09-05 17:26:36,571:INFO:create_model() successfully completed......................................
2023-09-05 17:26:36,650:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:36,650:INFO:Creating metrics dataframe
2023-09-05 17:26:36,656:INFO:Initializing Lasso Regression
2023-09-05 17:26:36,656:INFO:Total runtime is 0.011055413881937664 minutes
2023-09-05 17:26:36,658:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:36,658:INFO:Initializing create_model()
2023-09-05 17:26:36,658:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:36,658:INFO:Checking exceptions
2023-09-05 17:26:36,658:INFO:Importing libraries
2023-09-05 17:26:36,658:INFO:Copying training dataset
2023-09-05 17:26:36,660:INFO:Defining folds
2023-09-05 17:26:36,660:INFO:Declaring metric variables
2023-09-05 17:26:36,663:INFO:Importing untrained model
2023-09-05 17:26:36,665:INFO:Lasso Regression Imported successfully
2023-09-05 17:26:36,672:INFO:Starting cross validation
2023-09-05 17:26:36,673:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:37,181:INFO:Calculating mean and std
2023-09-05 17:26:37,182:INFO:Creating metrics dataframe
2023-09-05 17:26:37,226:INFO:Uploading results into container
2023-09-05 17:26:37,227:INFO:Uploading model into container now
2023-09-05 17:26:37,227:INFO:_master_model_container: 4
2023-09-05 17:26:37,227:INFO:_display_container: 3
2023-09-05 17:26:37,227:INFO:Lasso(random_state=3494)
2023-09-05 17:26:37,227:INFO:create_model() successfully completed......................................
2023-09-05 17:26:37,298:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:37,298:INFO:Creating metrics dataframe
2023-09-05 17:26:37,303:INFO:Initializing Ridge Regression
2023-09-05 17:26:37,303:INFO:Total runtime is 0.021846505006154378 minutes
2023-09-05 17:26:37,305:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:37,305:INFO:Initializing create_model()
2023-09-05 17:26:37,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:37,305:INFO:Checking exceptions
2023-09-05 17:26:37,305:INFO:Importing libraries
2023-09-05 17:26:37,305:INFO:Copying training dataset
2023-09-05 17:26:37,309:INFO:Defining folds
2023-09-05 17:26:37,310:INFO:Declaring metric variables
2023-09-05 17:26:37,313:INFO:Importing untrained model
2023-09-05 17:26:37,316:INFO:Ridge Regression Imported successfully
2023-09-05 17:26:37,321:INFO:Starting cross validation
2023-09-05 17:26:37,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:37,823:INFO:Calculating mean and std
2023-09-05 17:26:37,824:INFO:Creating metrics dataframe
2023-09-05 17:26:37,868:INFO:Uploading results into container
2023-09-05 17:26:37,868:INFO:Uploading model into container now
2023-09-05 17:26:37,868:INFO:_master_model_container: 5
2023-09-05 17:26:37,869:INFO:_display_container: 3
2023-09-05 17:26:37,869:INFO:Ridge(random_state=3494)
2023-09-05 17:26:37,869:INFO:create_model() successfully completed......................................
2023-09-05 17:26:37,941:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:37,941:INFO:Creating metrics dataframe
2023-09-05 17:26:37,947:INFO:Initializing Elastic Net
2023-09-05 17:26:37,947:INFO:Total runtime is 0.032570719718933105 minutes
2023-09-05 17:26:37,949:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:37,949:INFO:Initializing create_model()
2023-09-05 17:26:37,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:37,949:INFO:Checking exceptions
2023-09-05 17:26:37,949:INFO:Importing libraries
2023-09-05 17:26:37,949:INFO:Copying training dataset
2023-09-05 17:26:37,953:INFO:Defining folds
2023-09-05 17:26:37,953:INFO:Declaring metric variables
2023-09-05 17:26:37,955:INFO:Importing untrained model
2023-09-05 17:26:37,958:INFO:Elastic Net Imported successfully
2023-09-05 17:26:37,963:INFO:Starting cross validation
2023-09-05 17:26:37,965:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:38,471:INFO:Calculating mean and std
2023-09-05 17:26:38,472:INFO:Creating metrics dataframe
2023-09-05 17:26:38,513:INFO:Uploading results into container
2023-09-05 17:26:38,514:INFO:Uploading model into container now
2023-09-05 17:26:38,514:INFO:_master_model_container: 6
2023-09-05 17:26:38,514:INFO:_display_container: 3
2023-09-05 17:26:38,514:INFO:ElasticNet(random_state=3494)
2023-09-05 17:26:38,514:INFO:create_model() successfully completed......................................
2023-09-05 17:26:38,588:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:38,588:INFO:Creating metrics dataframe
2023-09-05 17:26:38,594:INFO:Initializing Least Angle Regression
2023-09-05 17:26:38,594:INFO:Total runtime is 0.043359275658925375 minutes
2023-09-05 17:26:38,596:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:38,596:INFO:Initializing create_model()
2023-09-05 17:26:38,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:38,596:INFO:Checking exceptions
2023-09-05 17:26:38,596:INFO:Importing libraries
2023-09-05 17:26:38,597:INFO:Copying training dataset
2023-09-05 17:26:38,600:INFO:Defining folds
2023-09-05 17:26:38,600:INFO:Declaring metric variables
2023-09-05 17:26:38,602:INFO:Importing untrained model
2023-09-05 17:26:38,604:INFO:Least Angle Regression Imported successfully
2023-09-05 17:26:38,610:INFO:Starting cross validation
2023-09-05 17:26:38,612:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:39,102:INFO:Calculating mean and std
2023-09-05 17:26:39,103:INFO:Creating metrics dataframe
2023-09-05 17:26:39,149:INFO:Uploading results into container
2023-09-05 17:26:39,150:INFO:Uploading model into container now
2023-09-05 17:26:39,150:INFO:_master_model_container: 7
2023-09-05 17:26:39,150:INFO:_display_container: 3
2023-09-05 17:26:39,150:INFO:Lars(random_state=3494)
2023-09-05 17:26:39,150:INFO:create_model() successfully completed......................................
2023-09-05 17:26:39,220:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:39,220:INFO:Creating metrics dataframe
2023-09-05 17:26:39,226:INFO:Initializing Lasso Least Angle Regression
2023-09-05 17:26:39,227:INFO:Total runtime is 0.05390704075495402 minutes
2023-09-05 17:26:39,230:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:39,230:INFO:Initializing create_model()
2023-09-05 17:26:39,231:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:39,231:INFO:Checking exceptions
2023-09-05 17:26:39,231:INFO:Importing libraries
2023-09-05 17:26:39,231:INFO:Copying training dataset
2023-09-05 17:26:39,236:INFO:Defining folds
2023-09-05 17:26:39,236:INFO:Declaring metric variables
2023-09-05 17:26:39,239:INFO:Importing untrained model
2023-09-05 17:26:39,242:INFO:Lasso Least Angle Regression Imported successfully
2023-09-05 17:26:39,249:INFO:Starting cross validation
2023-09-05 17:26:39,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:39,728:INFO:Calculating mean and std
2023-09-05 17:26:39,729:INFO:Creating metrics dataframe
2023-09-05 17:26:39,773:INFO:Uploading results into container
2023-09-05 17:26:39,774:INFO:Uploading model into container now
2023-09-05 17:26:39,774:INFO:_master_model_container: 8
2023-09-05 17:26:39,774:INFO:_display_container: 3
2023-09-05 17:26:39,774:INFO:LassoLars(random_state=3494)
2023-09-05 17:26:39,774:INFO:create_model() successfully completed......................................
2023-09-05 17:26:39,843:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:39,843:INFO:Creating metrics dataframe
2023-09-05 17:26:39,849:INFO:Initializing Orthogonal Matching Pursuit
2023-09-05 17:26:39,849:INFO:Total runtime is 0.06426630020141602 minutes
2023-09-05 17:26:39,851:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:39,851:INFO:Initializing create_model()
2023-09-05 17:26:39,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:39,851:INFO:Checking exceptions
2023-09-05 17:26:39,851:INFO:Importing libraries
2023-09-05 17:26:39,851:INFO:Copying training dataset
2023-09-05 17:26:39,855:INFO:Defining folds
2023-09-05 17:26:39,856:INFO:Declaring metric variables
2023-09-05 17:26:39,860:INFO:Importing untrained model
2023-09-05 17:26:39,863:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-05 17:26:39,868:INFO:Starting cross validation
2023-09-05 17:26:39,870:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:40,355:INFO:Calculating mean and std
2023-09-05 17:26:40,356:INFO:Creating metrics dataframe
2023-09-05 17:26:40,399:INFO:Uploading results into container
2023-09-05 17:26:40,399:INFO:Uploading model into container now
2023-09-05 17:26:40,400:INFO:_master_model_container: 9
2023-09-05 17:26:40,400:INFO:_display_container: 3
2023-09-05 17:26:40,400:INFO:OrthogonalMatchingPursuit()
2023-09-05 17:26:40,400:INFO:create_model() successfully completed......................................
2023-09-05 17:26:40,473:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:40,474:INFO:Creating metrics dataframe
2023-09-05 17:26:40,480:INFO:Initializing Bayesian Ridge
2023-09-05 17:26:40,480:INFO:Total runtime is 0.07478912274042766 minutes
2023-09-05 17:26:40,482:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:40,483:INFO:Initializing create_model()
2023-09-05 17:26:40,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:40,483:INFO:Checking exceptions
2023-09-05 17:26:40,483:INFO:Importing libraries
2023-09-05 17:26:40,483:INFO:Copying training dataset
2023-09-05 17:26:40,486:INFO:Defining folds
2023-09-05 17:26:40,486:INFO:Declaring metric variables
2023-09-05 17:26:40,489:INFO:Importing untrained model
2023-09-05 17:26:40,491:INFO:Bayesian Ridge Imported successfully
2023-09-05 17:26:40,496:INFO:Starting cross validation
2023-09-05 17:26:40,497:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:40,984:INFO:Calculating mean and std
2023-09-05 17:26:40,985:INFO:Creating metrics dataframe
2023-09-05 17:26:41,031:INFO:Uploading results into container
2023-09-05 17:26:41,031:INFO:Uploading model into container now
2023-09-05 17:26:41,031:INFO:_master_model_container: 10
2023-09-05 17:26:41,031:INFO:_display_container: 3
2023-09-05 17:26:41,032:INFO:BayesianRidge()
2023-09-05 17:26:41,032:INFO:create_model() successfully completed......................................
2023-09-05 17:26:41,099:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:41,099:INFO:Creating metrics dataframe
2023-09-05 17:26:41,105:INFO:Initializing Passive Aggressive Regressor
2023-09-05 17:26:41,105:INFO:Total runtime is 0.08521130084991456 minutes
2023-09-05 17:26:41,107:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:41,107:INFO:Initializing create_model()
2023-09-05 17:26:41,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:41,107:INFO:Checking exceptions
2023-09-05 17:26:41,107:INFO:Importing libraries
2023-09-05 17:26:41,107:INFO:Copying training dataset
2023-09-05 17:26:41,110:INFO:Defining folds
2023-09-05 17:26:41,110:INFO:Declaring metric variables
2023-09-05 17:26:41,113:INFO:Importing untrained model
2023-09-05 17:26:41,116:INFO:Passive Aggressive Regressor Imported successfully
2023-09-05 17:26:41,120:INFO:Starting cross validation
2023-09-05 17:26:41,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:41,652:INFO:Calculating mean and std
2023-09-05 17:26:41,653:INFO:Creating metrics dataframe
2023-09-05 17:26:41,697:INFO:Uploading results into container
2023-09-05 17:26:41,698:INFO:Uploading model into container now
2023-09-05 17:26:41,698:INFO:_master_model_container: 11
2023-09-05 17:26:41,698:INFO:_display_container: 3
2023-09-05 17:26:41,698:INFO:PassiveAggressiveRegressor(random_state=3494)
2023-09-05 17:26:41,698:INFO:create_model() successfully completed......................................
2023-09-05 17:26:41,770:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:41,770:INFO:Creating metrics dataframe
2023-09-05 17:26:41,777:INFO:Initializing Huber Regressor
2023-09-05 17:26:41,777:INFO:Total runtime is 0.09640363057454428 minutes
2023-09-05 17:26:41,779:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:41,779:INFO:Initializing create_model()
2023-09-05 17:26:41,779:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:41,780:INFO:Checking exceptions
2023-09-05 17:26:41,780:INFO:Importing libraries
2023-09-05 17:26:41,780:INFO:Copying training dataset
2023-09-05 17:26:41,783:INFO:Defining folds
2023-09-05 17:26:41,783:INFO:Declaring metric variables
2023-09-05 17:26:41,785:INFO:Importing untrained model
2023-09-05 17:26:41,787:INFO:Huber Regressor Imported successfully
2023-09-05 17:26:41,792:INFO:Starting cross validation
2023-09-05 17:26:41,794:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:41,923:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,927:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,937:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,937:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,959:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,980:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,981:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,985:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:41,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:26:42,307:INFO:Calculating mean and std
2023-09-05 17:26:42,308:INFO:Creating metrics dataframe
2023-09-05 17:26:42,353:INFO:Uploading results into container
2023-09-05 17:26:42,353:INFO:Uploading model into container now
2023-09-05 17:26:42,354:INFO:_master_model_container: 12
2023-09-05 17:26:42,354:INFO:_display_container: 3
2023-09-05 17:26:42,354:INFO:HuberRegressor()
2023-09-05 17:26:42,354:INFO:create_model() successfully completed......................................
2023-09-05 17:26:42,433:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:42,433:INFO:Creating metrics dataframe
2023-09-05 17:26:42,440:INFO:Initializing K Neighbors Regressor
2023-09-05 17:26:42,440:INFO:Total runtime is 0.10745745499928792 minutes
2023-09-05 17:26:42,442:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:42,442:INFO:Initializing create_model()
2023-09-05 17:26:42,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:42,442:INFO:Checking exceptions
2023-09-05 17:26:42,442:INFO:Importing libraries
2023-09-05 17:26:42,442:INFO:Copying training dataset
2023-09-05 17:26:42,445:INFO:Defining folds
2023-09-05 17:26:42,446:INFO:Declaring metric variables
2023-09-05 17:26:42,448:INFO:Importing untrained model
2023-09-05 17:26:42,450:INFO:K Neighbors Regressor Imported successfully
2023-09-05 17:26:42,455:INFO:Starting cross validation
2023-09-05 17:26:42,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:42,979:INFO:Calculating mean and std
2023-09-05 17:26:42,980:INFO:Creating metrics dataframe
2023-09-05 17:26:43,026:INFO:Uploading results into container
2023-09-05 17:26:43,026:INFO:Uploading model into container now
2023-09-05 17:26:43,026:INFO:_master_model_container: 13
2023-09-05 17:26:43,026:INFO:_display_container: 3
2023-09-05 17:26:43,026:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-05 17:26:43,027:INFO:create_model() successfully completed......................................
2023-09-05 17:26:43,098:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:43,098:INFO:Creating metrics dataframe
2023-09-05 17:26:43,105:INFO:Initializing Decision Tree Regressor
2023-09-05 17:26:43,105:INFO:Total runtime is 0.11853154102961222 minutes
2023-09-05 17:26:43,107:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:43,107:INFO:Initializing create_model()
2023-09-05 17:26:43,107:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:43,108:INFO:Checking exceptions
2023-09-05 17:26:43,108:INFO:Importing libraries
2023-09-05 17:26:43,108:INFO:Copying training dataset
2023-09-05 17:26:43,110:INFO:Defining folds
2023-09-05 17:26:43,111:INFO:Declaring metric variables
2023-09-05 17:26:43,113:INFO:Importing untrained model
2023-09-05 17:26:43,115:INFO:Decision Tree Regressor Imported successfully
2023-09-05 17:26:43,120:INFO:Starting cross validation
2023-09-05 17:26:43,121:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:43,620:INFO:Calculating mean and std
2023-09-05 17:26:43,621:INFO:Creating metrics dataframe
2023-09-05 17:26:43,665:INFO:Uploading results into container
2023-09-05 17:26:43,665:INFO:Uploading model into container now
2023-09-05 17:26:43,665:INFO:_master_model_container: 14
2023-09-05 17:26:43,665:INFO:_display_container: 3
2023-09-05 17:26:43,666:INFO:DecisionTreeRegressor(random_state=3494)
2023-09-05 17:26:43,666:INFO:create_model() successfully completed......................................
2023-09-05 17:26:43,737:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:43,737:INFO:Creating metrics dataframe
2023-09-05 17:26:43,744:INFO:Initializing Random Forest Regressor
2023-09-05 17:26:43,744:INFO:Total runtime is 0.12919241984685262 minutes
2023-09-05 17:26:43,747:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:43,747:INFO:Initializing create_model()
2023-09-05 17:26:43,747:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:43,747:INFO:Checking exceptions
2023-09-05 17:26:43,747:INFO:Importing libraries
2023-09-05 17:26:43,747:INFO:Copying training dataset
2023-09-05 17:26:43,750:INFO:Defining folds
2023-09-05 17:26:43,750:INFO:Declaring metric variables
2023-09-05 17:26:43,753:INFO:Importing untrained model
2023-09-05 17:26:43,755:INFO:Random Forest Regressor Imported successfully
2023-09-05 17:26:43,763:INFO:Starting cross validation
2023-09-05 17:26:43,765:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:44,366:INFO:Calculating mean and std
2023-09-05 17:26:44,367:INFO:Creating metrics dataframe
2023-09-05 17:26:44,415:INFO:Uploading results into container
2023-09-05 17:26:44,415:INFO:Uploading model into container now
2023-09-05 17:26:44,416:INFO:_master_model_container: 15
2023-09-05 17:26:44,416:INFO:_display_container: 3
2023-09-05 17:26:44,416:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:44,416:INFO:create_model() successfully completed......................................
2023-09-05 17:26:44,489:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:44,489:INFO:Creating metrics dataframe
2023-09-05 17:26:44,497:INFO:Initializing Extra Trees Regressor
2023-09-05 17:26:44,497:INFO:Total runtime is 0.1417316436767578 minutes
2023-09-05 17:26:44,499:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:44,499:INFO:Initializing create_model()
2023-09-05 17:26:44,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:44,499:INFO:Checking exceptions
2023-09-05 17:26:44,499:INFO:Importing libraries
2023-09-05 17:26:44,499:INFO:Copying training dataset
2023-09-05 17:26:44,502:INFO:Defining folds
2023-09-05 17:26:44,502:INFO:Declaring metric variables
2023-09-05 17:26:44,505:INFO:Importing untrained model
2023-09-05 17:26:44,507:INFO:Extra Trees Regressor Imported successfully
2023-09-05 17:26:44,512:INFO:Starting cross validation
2023-09-05 17:26:44,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:45,436:INFO:Calculating mean and std
2023-09-05 17:26:45,437:INFO:Creating metrics dataframe
2023-09-05 17:26:45,486:INFO:Uploading results into container
2023-09-05 17:26:45,487:INFO:Uploading model into container now
2023-09-05 17:26:45,488:INFO:_master_model_container: 16
2023-09-05 17:26:45,488:INFO:_display_container: 3
2023-09-05 17:26:45,488:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:45,488:INFO:create_model() successfully completed......................................
2023-09-05 17:26:45,564:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:45,564:INFO:Creating metrics dataframe
2023-09-05 17:26:45,572:INFO:Initializing AdaBoost Regressor
2023-09-05 17:26:45,572:INFO:Total runtime is 0.15965073506037394 minutes
2023-09-05 17:26:45,574:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:45,574:INFO:Initializing create_model()
2023-09-05 17:26:45,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:45,574:INFO:Checking exceptions
2023-09-05 17:26:45,574:INFO:Importing libraries
2023-09-05 17:26:45,574:INFO:Copying training dataset
2023-09-05 17:26:45,579:INFO:Defining folds
2023-09-05 17:26:45,579:INFO:Declaring metric variables
2023-09-05 17:26:45,583:INFO:Importing untrained model
2023-09-05 17:26:45,586:INFO:AdaBoost Regressor Imported successfully
2023-09-05 17:26:45,591:INFO:Starting cross validation
2023-09-05 17:26:45,592:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:46,185:INFO:Calculating mean and std
2023-09-05 17:26:46,186:INFO:Creating metrics dataframe
2023-09-05 17:26:46,232:INFO:Uploading results into container
2023-09-05 17:26:46,232:INFO:Uploading model into container now
2023-09-05 17:26:46,233:INFO:_master_model_container: 17
2023-09-05 17:26:46,233:INFO:_display_container: 3
2023-09-05 17:26:46,234:INFO:AdaBoostRegressor(random_state=3494)
2023-09-05 17:26:46,234:INFO:create_model() successfully completed......................................
2023-09-05 17:26:46,303:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:46,303:INFO:Creating metrics dataframe
2023-09-05 17:26:46,310:INFO:Initializing Gradient Boosting Regressor
2023-09-05 17:26:46,310:INFO:Total runtime is 0.1719512144724528 minutes
2023-09-05 17:26:46,313:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:46,313:INFO:Initializing create_model()
2023-09-05 17:26:46,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:46,313:INFO:Checking exceptions
2023-09-05 17:26:46,313:INFO:Importing libraries
2023-09-05 17:26:46,313:INFO:Copying training dataset
2023-09-05 17:26:46,318:INFO:Defining folds
2023-09-05 17:26:46,318:INFO:Declaring metric variables
2023-09-05 17:26:46,321:INFO:Importing untrained model
2023-09-05 17:26:46,323:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 17:26:46,328:INFO:Starting cross validation
2023-09-05 17:26:46,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:47,153:INFO:Calculating mean and std
2023-09-05 17:26:47,154:INFO:Creating metrics dataframe
2023-09-05 17:26:47,203:INFO:Uploading results into container
2023-09-05 17:26:47,204:INFO:Uploading model into container now
2023-09-05 17:26:47,204:INFO:_master_model_container: 18
2023-09-05 17:26:47,204:INFO:_display_container: 3
2023-09-05 17:26:47,204:INFO:GradientBoostingRegressor(random_state=3494)
2023-09-05 17:26:47,204:INFO:create_model() successfully completed......................................
2023-09-05 17:26:47,272:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:47,272:INFO:Creating metrics dataframe
2023-09-05 17:26:47,281:INFO:Initializing Extreme Gradient Boosting
2023-09-05 17:26:47,281:INFO:Total runtime is 0.18814441760381062 minutes
2023-09-05 17:26:47,283:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:47,283:INFO:Initializing create_model()
2023-09-05 17:26:47,283:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:47,283:INFO:Checking exceptions
2023-09-05 17:26:47,283:INFO:Importing libraries
2023-09-05 17:26:47,283:INFO:Copying training dataset
2023-09-05 17:26:47,287:INFO:Defining folds
2023-09-05 17:26:47,287:INFO:Declaring metric variables
2023-09-05 17:26:47,289:INFO:Importing untrained model
2023-09-05 17:26:47,291:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:26:47,297:INFO:Starting cross validation
2023-09-05 17:26:47,298:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:47,954:INFO:Calculating mean and std
2023-09-05 17:26:47,955:INFO:Creating metrics dataframe
2023-09-05 17:26:48,006:INFO:Uploading results into container
2023-09-05 17:26:48,007:INFO:Uploading model into container now
2023-09-05 17:26:48,007:INFO:_master_model_container: 19
2023-09-05 17:26:48,007:INFO:_display_container: 3
2023-09-05 17:26:48,007:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3494, ...)
2023-09-05 17:26:48,007:INFO:create_model() successfully completed......................................
2023-09-05 17:26:48,077:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:48,077:INFO:Creating metrics dataframe
2023-09-05 17:26:48,086:INFO:Initializing Light Gradient Boosting Machine
2023-09-05 17:26:48,086:INFO:Total runtime is 0.20155026117960612 minutes
2023-09-05 17:26:48,087:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:48,087:INFO:Initializing create_model()
2023-09-05 17:26:48,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:48,087:INFO:Checking exceptions
2023-09-05 17:26:48,088:INFO:Importing libraries
2023-09-05 17:26:48,088:INFO:Copying training dataset
2023-09-05 17:26:48,090:INFO:Defining folds
2023-09-05 17:26:48,091:INFO:Declaring metric variables
2023-09-05 17:26:48,093:INFO:Importing untrained model
2023-09-05 17:26:48,096:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:26:48,103:INFO:Starting cross validation
2023-09-05 17:26:48,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:49,196:INFO:Calculating mean and std
2023-09-05 17:26:49,197:INFO:Creating metrics dataframe
2023-09-05 17:26:49,251:INFO:Uploading results into container
2023-09-05 17:26:49,252:INFO:Uploading model into container now
2023-09-05 17:26:49,252:INFO:_master_model_container: 20
2023-09-05 17:26:49,252:INFO:_display_container: 3
2023-09-05 17:26:49,252:INFO:LGBMRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:49,252:INFO:create_model() successfully completed......................................
2023-09-05 17:26:49,319:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:49,319:INFO:Creating metrics dataframe
2023-09-05 17:26:49,329:INFO:Initializing CatBoost Regressor
2023-09-05 17:26:49,329:INFO:Total runtime is 0.2222684860229492 minutes
2023-09-05 17:26:49,332:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:49,332:INFO:Initializing create_model()
2023-09-05 17:26:49,332:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=catboost, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:49,333:INFO:Checking exceptions
2023-09-05 17:26:49,333:INFO:Importing libraries
2023-09-05 17:26:49,333:INFO:Copying training dataset
2023-09-05 17:26:49,336:INFO:Defining folds
2023-09-05 17:26:49,336:INFO:Declaring metric variables
2023-09-05 17:26:49,338:INFO:Importing untrained model
2023-09-05 17:26:49,340:INFO:CatBoost Regressor Imported successfully
2023-09-05 17:26:49,345:INFO:Starting cross validation
2023-09-05 17:26:49,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:52,674:INFO:Calculating mean and std
2023-09-05 17:26:52,675:INFO:Creating metrics dataframe
2023-09-05 17:26:52,733:INFO:Uploading results into container
2023-09-05 17:26:52,733:INFO:Uploading model into container now
2023-09-05 17:26:52,733:INFO:_master_model_container: 21
2023-09-05 17:26:52,734:INFO:_display_container: 3
2023-09-05 17:26:52,734:INFO:<catboost.core.CatBoostRegressor object at 0x000001DD76E35610>
2023-09-05 17:26:52,734:INFO:create_model() successfully completed......................................
2023-09-05 17:26:52,805:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:52,805:INFO:Creating metrics dataframe
2023-09-05 17:26:52,812:INFO:Initializing Dummy Regressor
2023-09-05 17:26:52,812:INFO:Total runtime is 0.28032232125600176 minutes
2023-09-05 17:26:52,815:INFO:SubProcess create_model() called ==================================
2023-09-05 17:26:52,815:INFO:Initializing create_model()
2023-09-05 17:26:52,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD774ABBE0>, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:52,815:INFO:Checking exceptions
2023-09-05 17:26:52,815:INFO:Importing libraries
2023-09-05 17:26:52,815:INFO:Copying training dataset
2023-09-05 17:26:52,818:INFO:Defining folds
2023-09-05 17:26:52,818:INFO:Declaring metric variables
2023-09-05 17:26:52,820:INFO:Importing untrained model
2023-09-05 17:26:52,823:INFO:Dummy Regressor Imported successfully
2023-09-05 17:26:52,827:INFO:Starting cross validation
2023-09-05 17:26:52,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:53,443:INFO:Calculating mean and std
2023-09-05 17:26:53,444:INFO:Creating metrics dataframe
2023-09-05 17:26:53,502:INFO:Uploading results into container
2023-09-05 17:26:53,502:INFO:Uploading model into container now
2023-09-05 17:26:53,503:INFO:_master_model_container: 22
2023-09-05 17:26:53,503:INFO:_display_container: 3
2023-09-05 17:26:53,503:INFO:DummyRegressor()
2023-09-05 17:26:53,503:INFO:create_model() successfully completed......................................
2023-09-05 17:26:53,579:INFO:SubProcess create_model() end ==================================
2023-09-05 17:26:53,579:INFO:Creating metrics dataframe
2023-09-05 17:26:53,598:INFO:Initializing create_model()
2023-09-05 17:26:53,598:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=GradientBoostingRegressor(random_state=3494), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:53,598:INFO:Checking exceptions
2023-09-05 17:26:53,599:INFO:Importing libraries
2023-09-05 17:26:53,599:INFO:Copying training dataset
2023-09-05 17:26:53,601:INFO:Defining folds
2023-09-05 17:26:53,601:INFO:Declaring metric variables
2023-09-05 17:26:53,602:INFO:Importing untrained model
2023-09-05 17:26:53,602:INFO:Declaring custom model
2023-09-05 17:26:53,602:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 17:26:53,603:INFO:Cross validation set to False
2023-09-05 17:26:53,603:INFO:Fitting Model
2023-09-05 17:26:53,801:INFO:GradientBoostingRegressor(random_state=3494)
2023-09-05 17:26:53,801:INFO:create_model() successfully completed......................................
2023-09-05 17:26:53,889:INFO:Initializing create_model()
2023-09-05 17:26:53,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3494), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:53,889:INFO:Checking exceptions
2023-09-05 17:26:53,890:INFO:Importing libraries
2023-09-05 17:26:53,890:INFO:Copying training dataset
2023-09-05 17:26:53,892:INFO:Defining folds
2023-09-05 17:26:53,892:INFO:Declaring metric variables
2023-09-05 17:26:53,892:INFO:Importing untrained model
2023-09-05 17:26:53,892:INFO:Declaring custom model
2023-09-05 17:26:53,893:INFO:Extra Trees Regressor Imported successfully
2023-09-05 17:26:53,894:INFO:Cross validation set to False
2023-09-05 17:26:53,894:INFO:Fitting Model
2023-09-05 17:26:54,081:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:54,081:INFO:create_model() successfully completed......................................
2023-09-05 17:26:54,175:INFO:_master_model_container: 22
2023-09-05 17:26:54,175:INFO:_display_container: 3
2023-09-05 17:26:54,176:INFO:[GradientBoostingRegressor(random_state=3494), ExtraTreesRegressor(n_jobs=-1, random_state=3494)]
2023-09-05 17:26:54,176:INFO:compare_models() successfully completed......................................
2023-09-05 17:26:54,201:INFO:Initializing create_model()
2023-09-05 17:26:54,202:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=dt, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={'max_depth': 5})
2023-09-05 17:26:54,202:INFO:Checking exceptions
2023-09-05 17:26:54,214:INFO:Importing libraries
2023-09-05 17:26:54,214:INFO:Copying training dataset
2023-09-05 17:26:54,218:INFO:Defining folds
2023-09-05 17:26:54,218:INFO:Declaring metric variables
2023-09-05 17:26:54,220:INFO:Importing untrained model
2023-09-05 17:26:54,223:INFO:Decision Tree Regressor Imported successfully
2023-09-05 17:26:54,232:INFO:Starting cross validation
2023-09-05 17:26:54,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:54,832:INFO:Calculating mean and std
2023-09-05 17:26:54,832:INFO:Creating metrics dataframe
2023-09-05 17:26:54,836:INFO:Finalizing model
2023-09-05 17:26:54,948:INFO:Uploading results into container
2023-09-05 17:26:54,949:INFO:Uploading model into container now
2023-09-05 17:26:54,956:INFO:_master_model_container: 23
2023-09-05 17:26:54,956:INFO:_display_container: 4
2023-09-05 17:26:54,957:INFO:DecisionTreeRegressor(max_depth=5, random_state=3494)
2023-09-05 17:26:54,957:INFO:create_model() successfully completed......................................
2023-09-05 17:26:55,138:INFO:Initializing create_model()
2023-09-05 17:26:55,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:55,139:INFO:Checking exceptions
2023-09-05 17:26:55,140:INFO:Importing libraries
2023-09-05 17:26:55,140:INFO:Copying training dataset
2023-09-05 17:26:55,142:INFO:Defining folds
2023-09-05 17:26:55,142:INFO:Declaring metric variables
2023-09-05 17:26:55,143:INFO:Importing untrained model
2023-09-05 17:26:55,143:INFO:Declaring custom model
2023-09-05 17:26:55,143:INFO:Linear Regression Imported successfully
2023-09-05 17:26:55,143:INFO:Starting cross validation
2023-09-05 17:26:55,144:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:55,342:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,344:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,347:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,349:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,352:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,365:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,367:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,369:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,369:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,369:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,370:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,372:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,373:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,375:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,377:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,381:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,381:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:55,383:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,384:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:55,800:INFO:Calculating mean and std
2023-09-05 17:26:55,800:INFO:Creating metrics dataframe
2023-09-05 17:26:55,802:INFO:Finalizing model
2023-09-05 17:26:55,915:INFO:Uploading results into container
2023-09-05 17:26:55,917:INFO:_master_model_container: 23
2023-09-05 17:26:55,917:INFO:_display_container: 5
2023-09-05 17:26:55,917:INFO:LinearRegression(n_jobs=-1)
2023-09-05 17:26:55,917:INFO:create_model() successfully completed......................................
2023-09-05 17:26:55,996:INFO:Initializing create_model()
2023-09-05 17:26:55,996:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:55,996:INFO:Checking exceptions
2023-09-05 17:26:55,997:INFO:Importing libraries
2023-09-05 17:26:55,997:INFO:Copying training dataset
2023-09-05 17:26:56,000:INFO:Defining folds
2023-09-05 17:26:56,000:INFO:Declaring metric variables
2023-09-05 17:26:56,000:INFO:Importing untrained model
2023-09-05 17:26:56,000:INFO:Declaring custom model
2023-09-05 17:26:56,000:INFO:Random Forest Regressor Imported successfully
2023-09-05 17:26:56,000:INFO:Starting cross validation
2023-09-05 17:26:56,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:56,260:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,260:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,260:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,263:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,263:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,275:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,275:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,279:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,279:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,308:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,308:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,311:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,311:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,311:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,315:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,324:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,326:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,337:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:56,339:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:56,727:INFO:Calculating mean and std
2023-09-05 17:26:56,727:INFO:Creating metrics dataframe
2023-09-05 17:26:56,730:INFO:Finalizing model
2023-09-05 17:26:56,882:INFO:Uploading results into container
2023-09-05 17:26:56,883:INFO:_master_model_container: 23
2023-09-05 17:26:56,883:INFO:_display_container: 6
2023-09-05 17:26:56,883:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:26:56,883:INFO:create_model() successfully completed......................................
2023-09-05 17:26:56,966:INFO:Initializing create_model()
2023-09-05 17:26:56,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=LinearRegression(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:56,966:INFO:Checking exceptions
2023-09-05 17:26:56,968:INFO:Importing libraries
2023-09-05 17:26:56,968:INFO:Copying training dataset
2023-09-05 17:26:56,970:INFO:Defining folds
2023-09-05 17:26:56,970:INFO:Declaring metric variables
2023-09-05 17:26:56,970:INFO:Importing untrained model
2023-09-05 17:26:56,970:INFO:Declaring custom model
2023-09-05 17:26:56,971:INFO:Linear Regression Imported successfully
2023-09-05 17:26:56,971:INFO:Starting cross validation
2023-09-05 17:26:56,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:57,135:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,137:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,145:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,148:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,153:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,156:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,156:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,156:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,157:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,158:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,159:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,179:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,181:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,191:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,192:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,194:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,194:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,196:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,198:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,604:INFO:Calculating mean and std
2023-09-05 17:26:57,604:INFO:Creating metrics dataframe
2023-09-05 17:26:57,606:INFO:Finalizing model
2023-09-05 17:26:57,713:INFO:Uploading results into container
2023-09-05 17:26:57,714:INFO:_master_model_container: 23
2023-09-05 17:26:57,714:INFO:_display_container: 7
2023-09-05 17:26:57,714:INFO:LinearRegression(n_jobs=-1)
2023-09-05 17:26:57,714:INFO:create_model() successfully completed......................................
2023-09-05 17:26:57,797:INFO:Initializing create_model()
2023-09-05 17:26:57,797:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=Lasso(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:57,797:INFO:Checking exceptions
2023-09-05 17:26:57,798:INFO:Importing libraries
2023-09-05 17:26:57,799:INFO:Copying training dataset
2023-09-05 17:26:57,801:INFO:Defining folds
2023-09-05 17:26:57,802:INFO:Declaring metric variables
2023-09-05 17:26:57,802:INFO:Importing untrained model
2023-09-05 17:26:57,802:INFO:Declaring custom model
2023-09-05 17:26:57,802:INFO:Lasso Regression Imported successfully
2023-09-05 17:26:57,802:INFO:Starting cross validation
2023-09-05 17:26:57,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:57,972:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,974:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,983:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,988:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:57,991:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:57,999:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,001:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,007:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,008:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,019:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,022:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,043:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,048:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,048:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,050:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,057:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,058:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,430:INFO:Calculating mean and std
2023-09-05 17:26:58,430:INFO:Creating metrics dataframe
2023-09-05 17:26:58,433:INFO:Finalizing model
2023-09-05 17:26:58,555:INFO:Uploading results into container
2023-09-05 17:26:58,556:INFO:_master_model_container: 23
2023-09-05 17:26:58,556:INFO:_display_container: 8
2023-09-05 17:26:58,557:INFO:Lasso(random_state=3494)
2023-09-05 17:26:58,557:INFO:create_model() successfully completed......................................
2023-09-05 17:26:58,633:INFO:Initializing create_model()
2023-09-05 17:26:58,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=Ridge(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:58,634:INFO:Checking exceptions
2023-09-05 17:26:58,635:INFO:Importing libraries
2023-09-05 17:26:58,635:INFO:Copying training dataset
2023-09-05 17:26:58,638:INFO:Defining folds
2023-09-05 17:26:58,638:INFO:Declaring metric variables
2023-09-05 17:26:58,638:INFO:Importing untrained model
2023-09-05 17:26:58,638:INFO:Declaring custom model
2023-09-05 17:26:58,638:INFO:Ridge Regression Imported successfully
2023-09-05 17:26:58,638:INFO:Starting cross validation
2023-09-05 17:26:58,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:58,802:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,803:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,812:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,814:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,823:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,824:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,825:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,826:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,840:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,842:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,843:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,844:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,845:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,847:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,859:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,860:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,870:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,871:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:58,875:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:58,876:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,263:INFO:Calculating mean and std
2023-09-05 17:26:59,264:INFO:Creating metrics dataframe
2023-09-05 17:26:59,266:INFO:Finalizing model
2023-09-05 17:26:59,377:INFO:Uploading results into container
2023-09-05 17:26:59,378:INFO:_master_model_container: 23
2023-09-05 17:26:59,378:INFO:_display_container: 9
2023-09-05 17:26:59,378:INFO:Ridge(random_state=3494)
2023-09-05 17:26:59,378:INFO:create_model() successfully completed......................................
2023-09-05 17:26:59,453:INFO:Initializing create_model()
2023-09-05 17:26:59,453:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=ElasticNet(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:26:59,453:INFO:Checking exceptions
2023-09-05 17:26:59,454:INFO:Importing libraries
2023-09-05 17:26:59,454:INFO:Copying training dataset
2023-09-05 17:26:59,457:INFO:Defining folds
2023-09-05 17:26:59,457:INFO:Declaring metric variables
2023-09-05 17:26:59,457:INFO:Importing untrained model
2023-09-05 17:26:59,457:INFO:Declaring custom model
2023-09-05 17:26:59,458:INFO:Elastic Net Imported successfully
2023-09-05 17:26:59,458:INFO:Starting cross validation
2023-09-05 17:26:59,459:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:26:59,616:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,617:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,635:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,637:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,642:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,645:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,647:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,651:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,656:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,659:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,660:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,662:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,666:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,668:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,668:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,669:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,678:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,679:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:26:59,688:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:26:59,690:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,063:INFO:Calculating mean and std
2023-09-05 17:27:00,063:INFO:Creating metrics dataframe
2023-09-05 17:27:00,065:INFO:Finalizing model
2023-09-05 17:27:00,177:INFO:Uploading results into container
2023-09-05 17:27:00,178:INFO:_master_model_container: 23
2023-09-05 17:27:00,178:INFO:_display_container: 10
2023-09-05 17:27:00,178:INFO:ElasticNet(random_state=3494)
2023-09-05 17:27:00,178:INFO:create_model() successfully completed......................................
2023-09-05 17:27:00,250:INFO:Initializing create_model()
2023-09-05 17:27:00,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=Lars(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:00,250:INFO:Checking exceptions
2023-09-05 17:27:00,252:INFO:Importing libraries
2023-09-05 17:27:00,252:INFO:Copying training dataset
2023-09-05 17:27:00,254:INFO:Defining folds
2023-09-05 17:27:00,254:INFO:Declaring metric variables
2023-09-05 17:27:00,255:INFO:Importing untrained model
2023-09-05 17:27:00,255:INFO:Declaring custom model
2023-09-05 17:27:00,255:INFO:Least Angle Regression Imported successfully
2023-09-05 17:27:00,255:INFO:Starting cross validation
2023-09-05 17:27:00,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:00,405:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,406:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,407:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,408:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,431:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,434:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,440:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,442:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,447:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,449:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,449:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,452:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,461:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,463:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,469:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,470:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,471:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,472:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,479:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:00,481:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:00,860:INFO:Calculating mean and std
2023-09-05 17:27:00,860:INFO:Creating metrics dataframe
2023-09-05 17:27:00,862:INFO:Finalizing model
2023-09-05 17:27:00,975:INFO:Uploading results into container
2023-09-05 17:27:00,976:INFO:_master_model_container: 23
2023-09-05 17:27:00,976:INFO:_display_container: 11
2023-09-05 17:27:00,976:INFO:Lars(random_state=3494)
2023-09-05 17:27:00,976:INFO:create_model() successfully completed......................................
2023-09-05 17:27:01,054:INFO:Initializing create_model()
2023-09-05 17:27:01,054:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=LassoLars(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:01,054:INFO:Checking exceptions
2023-09-05 17:27:01,055:INFO:Importing libraries
2023-09-05 17:27:01,055:INFO:Copying training dataset
2023-09-05 17:27:01,057:INFO:Defining folds
2023-09-05 17:27:01,058:INFO:Declaring metric variables
2023-09-05 17:27:01,058:INFO:Importing untrained model
2023-09-05 17:27:01,058:INFO:Declaring custom model
2023-09-05 17:27:01,058:INFO:Lasso Least Angle Regression Imported successfully
2023-09-05 17:27:01,058:INFO:Starting cross validation
2023-09-05 17:27:01,059:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:01,228:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,228:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,232:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,232:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,242:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,243:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,243:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,245:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,250:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,252:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,253:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,255:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,257:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,259:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,268:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,268:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,270:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,271:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,272:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:01,275:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:01,678:INFO:Calculating mean and std
2023-09-05 17:27:01,678:INFO:Creating metrics dataframe
2023-09-05 17:27:01,680:INFO:Finalizing model
2023-09-05 17:27:01,788:INFO:Uploading results into container
2023-09-05 17:27:01,789:INFO:_master_model_container: 23
2023-09-05 17:27:01,789:INFO:_display_container: 12
2023-09-05 17:27:01,789:INFO:LassoLars(random_state=3494)
2023-09-05 17:27:01,789:INFO:create_model() successfully completed......................................
2023-09-05 17:27:01,859:INFO:Initializing create_model()
2023-09-05 17:27:01,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=OrthogonalMatchingPursuit(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:01,859:INFO:Checking exceptions
2023-09-05 17:27:01,860:INFO:Importing libraries
2023-09-05 17:27:01,861:INFO:Copying training dataset
2023-09-05 17:27:01,863:INFO:Defining folds
2023-09-05 17:27:01,864:INFO:Declaring metric variables
2023-09-05 17:27:01,864:INFO:Importing untrained model
2023-09-05 17:27:01,864:INFO:Declaring custom model
2023-09-05 17:27:01,864:INFO:Orthogonal Matching Pursuit Imported successfully
2023-09-05 17:27:01,864:INFO:Starting cross validation
2023-09-05 17:27:01,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:02,018:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,019:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,020:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,022:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,023:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,026:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,043:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,044:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,045:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,046:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,064:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,067:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,071:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,073:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,075:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,077:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,079:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,079:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,080:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,463:INFO:Calculating mean and std
2023-09-05 17:27:02,463:INFO:Creating metrics dataframe
2023-09-05 17:27:02,465:INFO:Finalizing model
2023-09-05 17:27:02,569:INFO:Uploading results into container
2023-09-05 17:27:02,570:INFO:_master_model_container: 23
2023-09-05 17:27:02,570:INFO:_display_container: 13
2023-09-05 17:27:02,570:INFO:OrthogonalMatchingPursuit()
2023-09-05 17:27:02,570:INFO:create_model() successfully completed......................................
2023-09-05 17:27:02,647:INFO:Initializing create_model()
2023-09-05 17:27:02,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:02,648:INFO:Checking exceptions
2023-09-05 17:27:02,649:INFO:Importing libraries
2023-09-05 17:27:02,649:INFO:Copying training dataset
2023-09-05 17:27:02,652:INFO:Defining folds
2023-09-05 17:27:02,652:INFO:Declaring metric variables
2023-09-05 17:27:02,652:INFO:Importing untrained model
2023-09-05 17:27:02,652:INFO:Declaring custom model
2023-09-05 17:27:02,652:INFO:Bayesian Ridge Imported successfully
2023-09-05 17:27:02,653:INFO:Starting cross validation
2023-09-05 17:27:02,654:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:02,814:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,817:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,837:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,837:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,840:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,841:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,844:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,844:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,847:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,847:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,853:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,855:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,860:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,863:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,865:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,866:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,868:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,870:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:02,877:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:02,879:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,260:INFO:Calculating mean and std
2023-09-05 17:27:03,260:INFO:Creating metrics dataframe
2023-09-05 17:27:03,262:INFO:Finalizing model
2023-09-05 17:27:03,393:INFO:Uploading results into container
2023-09-05 17:27:03,394:INFO:_master_model_container: 23
2023-09-05 17:27:03,394:INFO:_display_container: 14
2023-09-05 17:27:03,394:INFO:BayesianRidge()
2023-09-05 17:27:03,394:INFO:create_model() successfully completed......................................
2023-09-05 17:27:03,480:INFO:Initializing create_model()
2023-09-05 17:27:03,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=PassiveAggressiveRegressor(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:03,480:INFO:Checking exceptions
2023-09-05 17:27:03,482:INFO:Importing libraries
2023-09-05 17:27:03,482:INFO:Copying training dataset
2023-09-05 17:27:03,485:INFO:Defining folds
2023-09-05 17:27:03,485:INFO:Declaring metric variables
2023-09-05 17:27:03,485:INFO:Importing untrained model
2023-09-05 17:27:03,485:INFO:Declaring custom model
2023-09-05 17:27:03,485:INFO:Passive Aggressive Regressor Imported successfully
2023-09-05 17:27:03,485:INFO:Starting cross validation
2023-09-05 17:27:03,486:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:03,639:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,641:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,661:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,663:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,664:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,666:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,667:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,669:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,678:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,680:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,687:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,690:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,690:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,692:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,696:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,698:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,703:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,705:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:03,716:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:03,718:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,111:INFO:Calculating mean and std
2023-09-05 17:27:04,112:INFO:Creating metrics dataframe
2023-09-05 17:27:04,114:INFO:Finalizing model
2023-09-05 17:27:04,225:INFO:Uploading results into container
2023-09-05 17:27:04,226:INFO:_master_model_container: 23
2023-09-05 17:27:04,226:INFO:_display_container: 15
2023-09-05 17:27:04,226:INFO:PassiveAggressiveRegressor(random_state=3494)
2023-09-05 17:27:04,226:INFO:create_model() successfully completed......................................
2023-09-05 17:27:04,301:INFO:Initializing create_model()
2023-09-05 17:27:04,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=HuberRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:04,301:INFO:Checking exceptions
2023-09-05 17:27:04,303:INFO:Importing libraries
2023-09-05 17:27:04,303:INFO:Copying training dataset
2023-09-05 17:27:04,305:INFO:Defining folds
2023-09-05 17:27:04,305:INFO:Declaring metric variables
2023-09-05 17:27:04,305:INFO:Importing untrained model
2023-09-05 17:27:04,305:INFO:Declaring custom model
2023-09-05 17:27:04,305:INFO:Huber Regressor Imported successfully
2023-09-05 17:27:04,305:INFO:Starting cross validation
2023-09-05 17:27:04,306:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:04,446:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,450:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,450:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,458:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,461:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,462:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,473:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,480:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,490:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,499:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,499:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,500:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,506:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,507:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,508:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,509:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,511:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,513:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,516:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,518:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,525:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:04,529:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,531:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,540:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,542:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,553:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,555:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,573:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:04,574:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:04,961:INFO:Calculating mean and std
2023-09-05 17:27:04,961:INFO:Creating metrics dataframe
2023-09-05 17:27:04,962:INFO:Finalizing model
2023-09-05 17:27:05,041:WARNING:C:\AI\pythonProject\venv\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-09-05 17:27:05,090:INFO:Uploading results into container
2023-09-05 17:27:05,091:INFO:_master_model_container: 23
2023-09-05 17:27:05,091:INFO:_display_container: 16
2023-09-05 17:27:05,091:INFO:HuberRegressor()
2023-09-05 17:27:05,091:INFO:create_model() successfully completed......................................
2023-09-05 17:27:05,170:INFO:Initializing create_model()
2023-09-05 17:27:05,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=KNeighborsRegressor(n_jobs=-1), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:05,170:INFO:Checking exceptions
2023-09-05 17:27:05,172:INFO:Importing libraries
2023-09-05 17:27:05,172:INFO:Copying training dataset
2023-09-05 17:27:05,174:INFO:Defining folds
2023-09-05 17:27:05,174:INFO:Declaring metric variables
2023-09-05 17:27:05,174:INFO:Importing untrained model
2023-09-05 17:27:05,174:INFO:Declaring custom model
2023-09-05 17:27:05,174:INFO:K Neighbors Regressor Imported successfully
2023-09-05 17:27:05,174:INFO:Starting cross validation
2023-09-05 17:27:05,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:05,358:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,359:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,360:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,362:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,373:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,373:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,375:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,375:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,387:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,388:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,404:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,405:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,406:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,407:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,418:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,419:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,420:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,420:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,434:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:05,436:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:05,809:INFO:Calculating mean and std
2023-09-05 17:27:05,809:INFO:Creating metrics dataframe
2023-09-05 17:27:05,811:INFO:Finalizing model
2023-09-05 17:27:05,917:INFO:Uploading results into container
2023-09-05 17:27:05,918:INFO:_master_model_container: 23
2023-09-05 17:27:05,918:INFO:_display_container: 17
2023-09-05 17:27:05,918:INFO:KNeighborsRegressor(n_jobs=-1)
2023-09-05 17:27:05,918:INFO:create_model() successfully completed......................................
2023-09-05 17:27:05,993:INFO:Initializing create_model()
2023-09-05 17:27:05,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=DecisionTreeRegressor(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:05,993:INFO:Checking exceptions
2023-09-05 17:27:05,994:INFO:Importing libraries
2023-09-05 17:27:05,994:INFO:Copying training dataset
2023-09-05 17:27:05,997:INFO:Defining folds
2023-09-05 17:27:05,997:INFO:Declaring metric variables
2023-09-05 17:27:05,997:INFO:Importing untrained model
2023-09-05 17:27:05,997:INFO:Declaring custom model
2023-09-05 17:27:05,997:INFO:Decision Tree Regressor Imported successfully
2023-09-05 17:27:05,997:INFO:Starting cross validation
2023-09-05 17:27:05,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:06,155:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,158:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,170:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,171:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,176:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,177:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,183:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,185:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,194:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,196:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,197:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,198:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,204:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,206:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,215:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,218:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,218:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,218:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:06,219:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,219:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:06,606:INFO:Calculating mean and std
2023-09-05 17:27:06,606:INFO:Creating metrics dataframe
2023-09-05 17:27:06,608:INFO:Finalizing model
2023-09-05 17:27:06,718:INFO:Uploading results into container
2023-09-05 17:27:06,719:INFO:_master_model_container: 23
2023-09-05 17:27:06,719:INFO:_display_container: 18
2023-09-05 17:27:06,719:INFO:DecisionTreeRegressor(random_state=3494)
2023-09-05 17:27:06,719:INFO:create_model() successfully completed......................................
2023-09-05 17:27:06,790:INFO:Initializing create_model()
2023-09-05 17:27:06,791:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:06,791:INFO:Checking exceptions
2023-09-05 17:27:06,794:INFO:Importing libraries
2023-09-05 17:27:06,794:INFO:Copying training dataset
2023-09-05 17:27:06,797:INFO:Defining folds
2023-09-05 17:27:06,797:INFO:Declaring metric variables
2023-09-05 17:27:06,797:INFO:Importing untrained model
2023-09-05 17:27:06,797:INFO:Declaring custom model
2023-09-05 17:27:06,798:INFO:Random Forest Regressor Imported successfully
2023-09-05 17:27:06,798:INFO:Starting cross validation
2023-09-05 17:27:06,798:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:07,047:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,049:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,064:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,064:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,065:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,066:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,081:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,081:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,083:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,083:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,111:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,113:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,127:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,127:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,127:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:07,129:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,129:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:07,514:INFO:Calculating mean and std
2023-09-05 17:27:07,514:INFO:Creating metrics dataframe
2023-09-05 17:27:07,516:INFO:Finalizing model
2023-09-05 17:27:07,657:INFO:Uploading results into container
2023-09-05 17:27:07,658:INFO:_master_model_container: 23
2023-09-05 17:27:07,658:INFO:_display_container: 19
2023-09-05 17:27:07,658:INFO:RandomForestRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:27:07,658:INFO:create_model() successfully completed......................................
2023-09-05 17:27:07,736:INFO:Initializing create_model()
2023-09-05 17:27:07,736:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:07,736:INFO:Checking exceptions
2023-09-05 17:27:07,738:INFO:Importing libraries
2023-09-05 17:27:07,738:INFO:Copying training dataset
2023-09-05 17:27:07,740:INFO:Defining folds
2023-09-05 17:27:07,740:INFO:Declaring metric variables
2023-09-05 17:27:07,740:INFO:Importing untrained model
2023-09-05 17:27:07,740:INFO:Declaring custom model
2023-09-05 17:27:07,741:INFO:Extra Trees Regressor Imported successfully
2023-09-05 17:27:07,741:INFO:Starting cross validation
2023-09-05 17:27:07,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:08,000:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,002:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,018:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,019:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,021:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,021:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,033:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,035:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,050:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,053:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,063:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,064:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,065:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,065:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,065:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,065:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,468:INFO:Calculating mean and std
2023-09-05 17:27:08,468:INFO:Creating metrics dataframe
2023-09-05 17:27:08,470:INFO:Finalizing model
2023-09-05 17:27:08,670:INFO:Uploading results into container
2023-09-05 17:27:08,671:INFO:_master_model_container: 23
2023-09-05 17:27:08,671:INFO:_display_container: 20
2023-09-05 17:27:08,671:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:27:08,671:INFO:create_model() successfully completed......................................
2023-09-05 17:27:08,752:INFO:Initializing create_model()
2023-09-05 17:27:08,752:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=AdaBoostRegressor(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:08,752:INFO:Checking exceptions
2023-09-05 17:27:08,754:INFO:Importing libraries
2023-09-05 17:27:08,755:INFO:Copying training dataset
2023-09-05 17:27:08,757:INFO:Defining folds
2023-09-05 17:27:08,757:INFO:Declaring metric variables
2023-09-05 17:27:08,758:INFO:Importing untrained model
2023-09-05 17:27:08,758:INFO:Declaring custom model
2023-09-05 17:27:08,758:INFO:AdaBoost Regressor Imported successfully
2023-09-05 17:27:08,758:INFO:Starting cross validation
2023-09-05 17:27:08,759:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:08,943:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,946:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,962:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,963:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,964:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,965:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,965:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,967:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,986:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:08,988:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:08,998:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,001:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,002:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,005:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,008:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,010:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,017:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,019:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,024:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,025:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,411:INFO:Calculating mean and std
2023-09-05 17:27:09,411:INFO:Creating metrics dataframe
2023-09-05 17:27:09,413:INFO:Finalizing model
2023-09-05 17:27:09,544:INFO:Uploading results into container
2023-09-05 17:27:09,544:INFO:_master_model_container: 23
2023-09-05 17:27:09,544:INFO:_display_container: 21
2023-09-05 17:27:09,545:INFO:AdaBoostRegressor(random_state=3494)
2023-09-05 17:27:09,545:INFO:create_model() successfully completed......................................
2023-09-05 17:27:09,627:INFO:Initializing create_model()
2023-09-05 17:27:09,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=GradientBoostingRegressor(random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:09,627:INFO:Checking exceptions
2023-09-05 17:27:09,630:INFO:Importing libraries
2023-09-05 17:27:09,630:INFO:Copying training dataset
2023-09-05 17:27:09,634:INFO:Defining folds
2023-09-05 17:27:09,634:INFO:Declaring metric variables
2023-09-05 17:27:09,634:INFO:Importing untrained model
2023-09-05 17:27:09,634:INFO:Declaring custom model
2023-09-05 17:27:09,635:INFO:Gradient Boosting Regressor Imported successfully
2023-09-05 17:27:09,635:INFO:Starting cross validation
2023-09-05 17:27:09,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:09,856:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,858:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,860:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,862:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,880:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,880:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,882:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,893:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,895:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,906:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,908:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,908:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,910:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,915:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,917:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,919:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,919:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:09,920:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:09,920:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:10,319:INFO:Calculating mean and std
2023-09-05 17:27:10,320:INFO:Creating metrics dataframe
2023-09-05 17:27:10,322:INFO:Finalizing model
2023-09-05 17:27:10,513:INFO:Uploading results into container
2023-09-05 17:27:10,514:INFO:_master_model_container: 23
2023-09-05 17:27:10,514:INFO:_display_container: 22
2023-09-05 17:27:10,514:INFO:GradientBoostingRegressor(random_state=3494)
2023-09-05 17:27:10,515:INFO:create_model() successfully completed......................................
2023-09-05 17:27:10,602:INFO:Initializing create_model()
2023-09-05 17:27:10,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3494, ...), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:10,602:INFO:Checking exceptions
2023-09-05 17:27:10,603:INFO:Importing libraries
2023-09-05 17:27:10,603:INFO:Copying training dataset
2023-09-05 17:27:10,606:INFO:Defining folds
2023-09-05 17:27:10,606:INFO:Declaring metric variables
2023-09-05 17:27:10,606:INFO:Importing untrained model
2023-09-05 17:27:10,606:INFO:Declaring custom model
2023-09-05 17:27:10,607:INFO:Extreme Gradient Boosting Imported successfully
2023-09-05 17:27:10,607:INFO:Starting cross validation
2023-09-05 17:27:10,608:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:10,894:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:10,897:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:10,917:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:10,926:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:10,944:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:10,944:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:10,946:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:10,946:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,158:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,161:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,169:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,174:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,179:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,183:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,245:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,248:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,316:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,318:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,380:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:11,382:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:11,547:INFO:Calculating mean and std
2023-09-05 17:27:11,547:INFO:Creating metrics dataframe
2023-09-05 17:27:11,549:INFO:Finalizing model
2023-09-05 17:27:11,735:INFO:Uploading results into container
2023-09-05 17:27:11,736:INFO:_master_model_container: 23
2023-09-05 17:27:11,736:INFO:_display_container: 23
2023-09-05 17:27:11,737:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=3494, ...)
2023-09-05 17:27:11,737:INFO:create_model() successfully completed......................................
2023-09-05 17:27:11,827:INFO:Initializing create_model()
2023-09-05 17:27:11,828:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=LGBMRegressor(n_jobs=-1, random_state=3494), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:11,828:INFO:Checking exceptions
2023-09-05 17:27:11,829:INFO:Importing libraries
2023-09-05 17:27:11,830:INFO:Copying training dataset
2023-09-05 17:27:11,832:INFO:Defining folds
2023-09-05 17:27:11,832:INFO:Declaring metric variables
2023-09-05 17:27:11,833:INFO:Importing untrained model
2023-09-05 17:27:11,833:INFO:Declaring custom model
2023-09-05 17:27:11,833:INFO:Light Gradient Boosting Machine Imported successfully
2023-09-05 17:27:11,833:INFO:Starting cross validation
2023-09-05 17:27:11,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:12,082:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,112:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,114:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,140:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,154:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,172:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,180:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,190:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,195:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,196:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,205:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,232:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,266:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,282:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,290:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,314:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,424:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,427:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,449:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:12,451:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:12,754:INFO:Calculating mean and std
2023-09-05 17:27:12,754:INFO:Creating metrics dataframe
2023-09-05 17:27:12,756:INFO:Finalizing model
2023-09-05 17:27:12,817:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000212 seconds.
2023-09-05 17:27:12,817:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-09-05 17:27:12,817:INFO:[LightGBM] [Info] Total Bins 321
2023-09-05 17:27:12,818:INFO:[LightGBM] [Info] Number of data points in the train set: 936, number of used features: 9
2023-09-05 17:27:12,818:INFO:[LightGBM] [Info] Start training from score 13425.080148
2023-09-05 17:27:12,940:INFO:Uploading results into container
2023-09-05 17:27:12,941:INFO:_master_model_container: 23
2023-09-05 17:27:12,941:INFO:_display_container: 24
2023-09-05 17:27:12,942:INFO:LGBMRegressor(n_jobs=-1, random_state=3494)
2023-09-05 17:27:12,942:INFO:create_model() successfully completed......................................
2023-09-05 17:27:13,024:INFO:Initializing create_model()
2023-09-05 17:27:13,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=<catboost.core.CatBoostRegressor object at 0x000001DD7771FAF0>, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:13,024:INFO:Checking exceptions
2023-09-05 17:27:13,026:INFO:Importing libraries
2023-09-05 17:27:13,026:INFO:Copying training dataset
2023-09-05 17:27:13,028:INFO:Defining folds
2023-09-05 17:27:13,028:INFO:Declaring metric variables
2023-09-05 17:27:13,029:INFO:Importing untrained model
2023-09-05 17:27:13,029:INFO:Declaring custom model
2023-09-05 17:27:13,029:INFO:CatBoost Regressor Imported successfully
2023-09-05 17:27:13,029:INFO:Starting cross validation
2023-09-05 17:27:13,030:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:13,244:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,247:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,262:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,264:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,274:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,276:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,292:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,293:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,734:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,737:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,750:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,752:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,770:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,772:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,777:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,779:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,791:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,794:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:13,833:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:13,835:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:14,044:INFO:Calculating mean and std
2023-09-05 17:27:14,044:INFO:Creating metrics dataframe
2023-09-05 17:27:14,046:INFO:Finalizing model
2023-09-05 17:27:15,265:INFO:Uploading results into container
2023-09-05 17:27:15,265:INFO:_master_model_container: 23
2023-09-05 17:27:15,265:INFO:_display_container: 25
2023-09-05 17:27:15,265:INFO:<catboost.core.CatBoostRegressor object at 0x000001DD77026D30>
2023-09-05 17:27:15,265:INFO:create_model() successfully completed......................................
2023-09-05 17:27:15,339:INFO:Initializing create_model()
2023-09-05 17:27:15,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=DummyRegressor(), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:15,340:INFO:Checking exceptions
2023-09-05 17:27:15,341:INFO:Importing libraries
2023-09-05 17:27:15,341:INFO:Copying training dataset
2023-09-05 17:27:15,344:INFO:Defining folds
2023-09-05 17:27:15,344:INFO:Declaring metric variables
2023-09-05 17:27:15,344:INFO:Importing untrained model
2023-09-05 17:27:15,344:INFO:Declaring custom model
2023-09-05 17:27:15,344:INFO:Dummy Regressor Imported successfully
2023-09-05 17:27:15,344:INFO:Starting cross validation
2023-09-05 17:27:15,345:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:15,503:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,505:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,505:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,506:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,519:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,519:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,521:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,521:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,523:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,524:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,525:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,525:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,530:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,532:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,554:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,556:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,557:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,560:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:15,563:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:15,565:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:16,001:INFO:Calculating mean and std
2023-09-05 17:27:16,001:INFO:Creating metrics dataframe
2023-09-05 17:27:16,003:INFO:Finalizing model
2023-09-05 17:27:16,118:INFO:Uploading results into container
2023-09-05 17:27:16,118:INFO:_master_model_container: 23
2023-09-05 17:27:16,118:INFO:_display_container: 26
2023-09-05 17:27:16,119:INFO:DummyRegressor()
2023-09-05 17:27:16,119:INFO:create_model() successfully completed......................................
2023-09-05 17:27:16,794:INFO:Initializing tune_model()
2023-09-05 17:27:16,794:INFO:tune_model(estimator=DecisionTreeRegressor(max_depth=5, random_state=3494), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>)
2023-09-05 17:27:16,794:INFO:Checking exceptions
2023-09-05 17:27:16,807:INFO:Copying training dataset
2023-09-05 17:27:16,812:INFO:Checking base model
2023-09-05 17:27:16,812:INFO:Base model : Decision Tree Regressor
2023-09-05 17:27:16,816:INFO:Declaring metric variables
2023-09-05 17:27:16,818:INFO:Defining Hyperparameters
2023-09-05 17:27:16,895:INFO:Tuning with n_jobs=-1
2023-09-05 17:27:16,895:INFO:Initializing RandomizedSearchCV
2023-09-05 17:27:23,271:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.4, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 5, 'actual_estimator__criterion': 'squared_error'}
2023-09-05 17:27:23,271:INFO:Hyperparameter search completed
2023-09-05 17:27:23,271:INFO:SubProcess create_model() called ==================================
2023-09-05 17:27:23,272:INFO:Initializing create_model()
2023-09-05 17:27:23,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=DecisionTreeRegressor(max_depth=5, random_state=3494), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001DD776F7400>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.4, 'max_features': 1.0, 'max_depth': 5, 'criterion': 'squared_error'})
2023-09-05 17:27:23,272:INFO:Checking exceptions
2023-09-05 17:27:23,272:INFO:Importing libraries
2023-09-05 17:27:23,272:INFO:Copying training dataset
2023-09-05 17:27:23,274:INFO:Defining folds
2023-09-05 17:27:23,274:INFO:Declaring metric variables
2023-09-05 17:27:23,278:INFO:Importing untrained model
2023-09-05 17:27:23,278:INFO:Declaring custom model
2023-09-05 17:27:23,280:INFO:Decision Tree Regressor Imported successfully
2023-09-05 17:27:23,284:INFO:Starting cross validation
2023-09-05 17:27:23,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:23,443:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,445:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,445:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,448:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,449:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,453:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,470:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,471:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,475:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,476:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,481:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,483:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,484:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,485:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,494:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,496:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,496:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,498:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,513:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:23,515:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:23,920:INFO:Calculating mean and std
2023-09-05 17:27:23,921:INFO:Creating metrics dataframe
2023-09-05 17:27:23,927:INFO:Finalizing model
2023-09-05 17:27:24,062:INFO:Uploading results into container
2023-09-05 17:27:24,062:INFO:Uploading model into container now
2023-09-05 17:27:24,063:INFO:_master_model_container: 24
2023-09-05 17:27:24,063:INFO:_display_container: 27
2023-09-05 17:27:24,063:INFO:DecisionTreeRegressor(max_depth=5, max_features=1.0, min_impurity_decrease=0.4,
                      min_samples_leaf=4, min_samples_split=9,
                      random_state=3494)
2023-09-05 17:27:24,063:INFO:create_model() successfully completed......................................
2023-09-05 17:27:24,140:INFO:SubProcess create_model() end ==================================
2023-09-05 17:27:24,140:INFO:choose_better activated
2023-09-05 17:27:24,143:INFO:SubProcess create_model() called ==================================
2023-09-05 17:27:24,143:INFO:Initializing create_model()
2023-09-05 17:27:24,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001DD72EB07C0>, estimator=DecisionTreeRegressor(max_depth=5, random_state=3494), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-09-05 17:27:24,143:INFO:Checking exceptions
2023-09-05 17:27:24,144:INFO:Importing libraries
2023-09-05 17:27:24,144:INFO:Copying training dataset
2023-09-05 17:27:24,146:INFO:Defining folds
2023-09-05 17:27:24,146:INFO:Declaring metric variables
2023-09-05 17:27:24,146:INFO:Importing untrained model
2023-09-05 17:27:24,146:INFO:Declaring custom model
2023-09-05 17:27:24,147:INFO:Decision Tree Regressor Imported successfully
2023-09-05 17:27:24,147:INFO:Starting cross validation
2023-09-05 17:27:24,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-09-05 17:27:24,318:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,321:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (199     14901.516602
489     10461.979492
22       1137.010986
1112    24180.933594
922      5488.262207
            ...     
658     26392.259766
1233    11345.518555
492      2196.473145
202     13012.208984
1295     1964.780029
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,321:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,323:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (738     36189.101562
1272    14478.330078
628     11365.952148
144     20745.988281
695      3201.245117
            ...     
698     10976.246094
812     11013.711914
1134    19673.335938
1252    16232.846680
180     11735.878906
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,326:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,330:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (895     13063.882812
925     25333.332031
816      2842.760742
665     42560.429688
889     11945.132812
            ...     
159     19749.382812
72      11741.725586
1174     4433.916016
1031    44423.804688
679     10156.783203
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,339:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,339:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,340:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,340:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (304     12646.207031
341     13352.099609
490      1748.774048
125      3385.399170
1032     4137.522461
            ...     
427      7323.734863
524     38245.593750
1241    49577.664062
49      38709.175781
582      6356.270508
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,341:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (521      3994.177734
111     11881.358398
1034    12950.071289
1119     5693.430664
228      7358.175781
            ...     
721     11264.541016
510     11763.000977
248      1832.093994
136      1261.442017
1249    37607.527344
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,342:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (1227     7162.012207
595      8823.985352
141      3490.549072
494     17942.105469
1234     8515.758789
            ...     
10       2721.320801
7        7281.505371
977      2902.906494
551      3972.924805
301     24873.384766
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,351:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,353:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (632      3366.669678
423      2727.395020
710      1727.540039
518      5240.765137
783     24520.263672
            ...     
680      2585.269043
950     11534.873047
130     12815.445312
1110    11512.405273
651     10579.710938
Name: charges, Length: 94, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,367:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,370:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (192      2137.653564
641     32787.457031
1189    13126.677734
981      4500.339355
34      51194.558594
            ...     
673      6185.320801
676     12485.800781
296     16297.845703
1003    21232.181641
176      6455.862793
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,372:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,373:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (275      9715.840820
209      6610.109863
845     45008.957031
55      47496.496094
1271     3021.809082
            ...     
1178     2899.489258
365      9778.347656
448      5910.943848
736     40419.019531
223     34779.613281
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,381:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(roc_auc_score)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_ranking.py", line 580, in roc_auc_score
    return _average_binary_score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_base.py", line 72, in _average_binary_score
    raise ValueError("{0} format is not supported".format(y_type))
ValueError: continuous format is not supported

  warnings.warn(

2023-09-05 17:27:24,382:WARNING:C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py:192: FitFailedWarning: Metric 'make_scorer(log_loss, greater_is_better=False)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\AI\pythonProject\venv\lib\site-packages\pycaret\internal\metrics.py", line 184, in _score
    return super()._score(
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_scorer.py", line 282, in _score
    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\metrics\_classification.py", line 2598, in log_loss
    lb.fit(y_true)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\preprocessing\_label.py", line 311, in fit
    self.classes_ = unique_labels(y)
  File "C:\AI\pythonProject\venv\lib\site-packages\sklearn\utils\multiclass.py", line 107, in unique_labels
    raise ValueError("Unknown label type: %s" % repr(ys))
ValueError: Unknown label type: (649     12430.953125
1183     9447.382812
894     13555.004883
1312     4536.258789
1260     4544.234863
            ...     
251     47305.304688
420     46889.261719
733      9447.250000
796      4266.166016
653      8527.532227
Name: charges, Length: 93, dtype: float32,)

  warnings.warn(

2023-09-05 17:27:24,799:INFO:Calculating mean and std
2023-09-05 17:27:24,799:INFO:Creating metrics dataframe
2023-09-05 17:27:24,801:INFO:Finalizing model
2023-09-05 17:27:24,916:INFO:Uploading results into container
2023-09-05 17:27:24,917:INFO:Uploading model into container now
2023-09-05 17:27:24,917:INFO:_master_model_container: 25
2023-09-05 17:27:24,917:INFO:_display_container: 28
2023-09-05 17:27:24,917:INFO:DecisionTreeRegressor(max_depth=5, random_state=3494)
2023-09-05 17:27:24,917:INFO:create_model() successfully completed......................................
2023-09-05 17:27:24,991:INFO:SubProcess create_model() end ==================================
2023-09-05 17:27:24,992:INFO:DecisionTreeRegressor(max_depth=5, random_state=3494) result for R2 is 0.854
2023-09-05 17:27:24,992:INFO:DecisionTreeRegressor(max_depth=5, max_features=1.0, min_impurity_decrease=0.4,
                      min_samples_leaf=4, min_samples_split=9,
                      random_state=3494) result for R2 is 0.8573
2023-09-05 17:27:24,992:INFO:DecisionTreeRegressor(max_depth=5, max_features=1.0, min_impurity_decrease=0.4,
                      min_samples_leaf=4, min_samples_split=9,
                      random_state=3494) is best model
2023-09-05 17:27:24,992:INFO:choose_better completed
2023-09-05 17:27:24,999:INFO:_master_model_container: 25
2023-09-05 17:27:24,999:INFO:_display_container: 27
2023-09-05 17:27:24,999:INFO:DecisionTreeRegressor(max_depth=5, max_features=1.0, min_impurity_decrease=0.4,
                      min_samples_leaf=4, min_samples_split=9,
                      random_state=3494)
2023-09-05 17:27:24,999:INFO:tune_model() successfully completed......................................
